[
  {
    "objectID": "tutorial/05-content.html",
    "href": "tutorial/05-content.html",
    "title": "Tutorial 5: Visualization with ggplot2",
    "section": "",
    "text": "In this tutorial, we will explore data visualization using ggplot2, a powerful and flexible package in the Tidyverse for creating graphics. Understanding how to visualize data effectively is crucial for analyzing and presenting your findings. We will cover the basics of creating various types of plots and customizing them to suit your needs.\n\n\n\n\nThe Grammar of Graphics is a framework for data visualization that provides a structured and systematic approach to creating graphics. It was introduced by Leland Wilkinson in his book The Grammar of Graphics and serves as the foundation for ggplot2, a popular R package for data visualization. The key idea behind the Grammar of Graphics is that any statistical graphic can be built up from a few basic components, combined according to a set of rules. This approach allows for flexibility and consistency in creating complex visualizations.\n\n\n\nData: The dataset that you want to visualize. It typically consists of rows (observations) and columns (variables).\nAesthetics (aes): These are mappings between data variables and visual properties of the plot, such as position (x, y), color, size, shape, and more. For example, mapping a variable to the x-axis or mapping a variable to color.\nGeometries (geom): These are the visual elements that represent data on the plot, such as points, lines, bars, or shapes. For instance, geom_point() creates a scatter plot, geom_line() creates a line plot, and geom_bar() creates a bar chart.\nScales: Scales control how data values are mapped to aesthetic attributes like position, color, or size. For example, scale_x_continuous() controls the mapping of data values to positions along the x-axis.\nFacets: Faceting is a way to split the data into subsets and create multiple plots for each subset, allowing for comparisons across groups. For example, you can create separate plots for each level of a categorical variable.\nStatistics (stat): These are transformations of the data that are applied before plotting. For example, a histogram involves binning data and then counting the number of observations in each bin.\nCoordinates (coord): This component controls the coordinate system used for the plot. The most common coordinate system is Cartesian (x, y), but others include polar coordinates or log scales.\nThemes: Themes control the overall appearance of the plot, including non-data elements like font size, background color, grid lines, and axis labels. For example, theme_minimal() provides a clean, minimalistic style for the plot.\n\n\n\n\n\nggplot2 is an implementation of the Grammar of Graphics in R. It allows you to create complex visualizations by combining these basic components in a structured way. Here’s how ggplot2 uses the Grammar of Graphics:\n\nInitialization with ggplot():\n\nThe ggplot() function initializes a ggplot object and specifies the dataset you want to use. For example:\n\nggplot(data = students_df)\n\nThis function doesn’t produce a plot by itself; it sets up the plot object to which you can add layers.\n\nAesthetic Mapping with aes():\n\nInside the ggplot() function or within individual geometries, you define aesthetic mappings using the aes() function. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score))\n\nThis mapping connects the data to the visual properties of the plot, like mapping Age to the x-axis and Score to the y-axis.\n\nAdding Geometries with geom_*() Functions:\n\nGeometries are added to the plot to represent the data. Each geometry corresponds to a type of plot element, such as points, lines, or bars. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point()\n\nThis adds a layer of points to the plot, creating a scatter plot.\n\nCustomizing Scales and Axes:\n\nScales can be customized to control how data values map to visual attributes. For example, you can adjust the x-axis limits or change the color scale:\n\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point() +\n  scale_x_continuous(limits = c(18, 25))\n\n\nFaceting for Multi-Panel Plots:\n\nFaceting allows you to create multiple plots based on subsets of the data. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point() +\n  facet_wrap(~ Major)\n\nThis creates separate scatter plots for each Major.\n\nApplying Themes:\n\nThemes are used to control the appearance of non-data elements in the plot. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point() +\n  theme_minimal()\n\nThis applies a minimalistic style to the plot.\n\n\n\n\n\nMapping in ggplot2 refers to the connection between your data variables and the visual aspects of your plot. The aes() function is where this mapping happens. It tells ggplot2 how to map your data onto the plot. Here’s how mapping works:\n\nPosition Mapping (x and y):\n\nThe most common type of mapping is position mapping, where you map variables to the x-axis and y-axis. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score))\n\nThis maps the Age variable to the x-axis and the Score variable to the y-axis.\n\nColor Mapping:\n\nYou can map a variable to the color aesthetic to differentiate data points by a categorical or continuous variable. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score, color = Major))\n\nThis maps the Major variable to the color of the points, allowing different colors for different majors.\n\nSize Mapping:\n\nThe size of points or other elements can be mapped to a variable. For example:\n\nggplot(data = student_performance_df, aes(x = Homework_Score, y = Exam_Score, size = Study_Hours))\n\nThis maps the Study_Hours variable to the size of the points, with more study hours represented by larger points.\n\nShape Mapping:\n\nSimilarly, you can map a variable to the shape aesthetic to differentiate points by shape. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score, shape = Gender))\n\nThis maps the Gender variable to the shape of the points, using different shapes for male and female students.\n\n\n\n\n\nUnderstanding the Grammar of Graphics is essential because it gives you a powerful, flexible, and consistent way to create visualizations. By understanding how the different components work together, you can build complex and customized plots to meet your specific data visualization needs. It also makes it easier to debug and refine your plots since you know exactly how each part of the plot is constructed.\n\n\n\n\nggplot2 is based on the grammar of graphics, which provides a structured approach to building plots by layering components such as data, aesthetics, and geometries.\n\n\nBefore diving into ggplot2, it’s important to understand the difference between tibbles and data frames.\n\nTibbles are modern versions of data frames provided by the Tidyverse, which are more user-friendly for data analysis. They provide better printing methods and do not convert strings to factors by default.\nFor now, we will continue using data.frame to create datasets for simplicity. However, in future tutorials, we will introduce tibbles and their advantages.\n\n\n\n\nIf you haven’t already installed the Tidyverse, you can install ggplot2 individually or load it as part of the Tidyverse.\n\n# Install ggplot2 (if not already installed)\ninstall.packages(\"ggplot2\")\n\n# Load ggplot2\nlibrary(ggplot2)\n\nExplanation: - install.packages() installs ggplot2 if it’s not already installed. - library() loads the package, making its functions available for use.\n\n\n\nThe basic structure of a ggplot2 plot consists of the following components: - Data: The dataset being used. - Aesthetics (aes): Mappings between variables and visual properties such as x and y positions, colors, sizes, etc. - Geometries (geom): The type of plot or geometric objects used to represent the data (e.g., points, lines, bars).\nHere’s an example of a simple scatter plot:\n\n# Example data frame\nstudents_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"),\n  Score = c(85, 90, 78, 88, 92),\n  Age = c(20, 21, 19, 22, 20)\n)\n\n# Creating a scatter plot of Score vs. Age\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point()\n\n\n\n\n\n\n\n\nExplanation: - ggplot() initializes the plot and specifies the data to be used. - aes() defines the aesthetic mappings, such as x and y variables. - geom_point() adds a layer of points (a scatter plot) to the plot.\n\n\n\n\n\n\nScatter plots are used to visualize the relationship between two continuous variables.\n\n# Scatter plot with additional customizations\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point(color = \"blue\", size = 3) +\n  labs(title = \"Student Scores vs. Age\", x = \"Age\", y = \"Score\")\n\n\n\n\n\n\n\n\nExplanation: - The color and size arguments in geom_point() customize the appearance of the points. - labs() is used to add titles and labels to the axes.\n\n\n\nBar charts are used to compare the counts or frequencies of categorical variables.\n\n# Example data frame for bar chart\nmajors_df &lt;- data.frame(\n  Major = c(\"Economics\", \"History\", \"Biology\"),\n  Students = c(50, 40, 30)\n)\n\n# Creating a bar chart of the number of students per major\nggplot(data = majors_df, aes(x = Major, y = Students)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(title = \"Number of Students by Major\", x = \"Major\", y = \"Number of Students\")\n\n\n\n\n\n\n\n\nExplanation: - geom_bar() is used for creating bar charts. The stat = \"identity\" argument indicates that the heights of the bars should represent the values in the dataset. - The fill argument customizes the color of the bars.\n\n\n\nLine plots are useful for visualizing trends over time or across ordered categories.\n\n# Example data frame for line plot\nyearly_scores_df &lt;- data.frame(\n  Year = c(2018, 2019, 2020, 2021, 2022),\n  AverageScore = c(80, 82, 85, 87, 90)\n)\n\n# Creating a line plot of average scores over years\nggplot(data = yearly_scores_df, aes(x = Year, y = AverageScore)) +\n  geom_line(color = \"red\", size = 1.5) +\n  geom_point(color = \"red\", size = 3) +\n  labs(title = \"Average Scores Over Time\", x = \"Year\", y = \"Average Score\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nExplanation: - geom_line() adds a line to the plot, while geom_point() overlays points on the line. - The color and size of the line and points are customized using color and size arguments.\n\n\n\nHistograms display the distribution of a single continuous variable by dividing it into bins.\n\n# Creating a histogram of student scores\nggplot(data = students_df, aes(x = Score)) +\n  geom_histogram(binwidth = 5, fill = \"green\", color = \"black\") +\n  labs(title = \"Distribution of Student Scores\", x = \"Score\", y = \"Frequency\")\n\n\n\n\n\n\n\n\nExplanation: - geom_histogram() creates the histogram. The binwidth argument controls the width of the bins. - The fill and color arguments customize the color of the bars and their outlines.\n\n\n\nBox plots are used to visualize the distribution of a continuous variable and identify potential outliers.\n\n# Example data frame with Major added\nstudents_major_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"),\n  Score = c(85, 90, 78, 88, 92),\n  Age = c(20, 21, 19, 22, 20),\n  Major = c(\"Economics\", \"Economics\", \"History\", \"Biology\", \"History\")\n)\n\n# Creating a box plot of scores by major\nggplot(data = students_major_df, aes(x = Major, y = Score)) +\n  geom_boxplot(fill = \"orange\") +\n  labs(title = \"Box Plot of Scores by Major\", x = \"Major\", y = \"Score\")\n\n\n\n\n\n\n\n\nExplanation: - geom_boxplot() creates the box plot, which shows the median, quartiles, and potential outliers for each group.\n\n\n\n\n\n\nThemes in ggplot2 allow you to customize the overall appearance of your plots.\n\n# Applying a minimal theme to a scatter plot\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point(color = \"blue\", size = 3) +\n  labs(title = \"Student Scores vs. Age\", x = \"Age\", y = \"Score\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nExplanation: - theme_minimal() applies a clean and minimalistic style to the plot. Other themes include theme_classic(), theme_light(), and more.\n\n\n\nFaceting allows you to create multiple plots based on a categorical variable.\n\n# Creating facets based on Major\nggplot(data = students_major_df, aes(x = Age, y = Score)) +\n  geom_point(color = \"purple\", size = 3) +\n  labs(title = \"Student Scores vs. Age by Major\", x = \"Age\", y = \"Score\") +\n  facet_wrap(~ Major)\n\n\n\n\n\n\n\n\nExplanation: - facet_wrap(~ Major) creates a separate plot for each level of the Major variable.\n\n\n\nYou can customize the scales of your plot, including axis limits and colors.\n\n# Customizing axis limits and colors\nggplot(data = students_major_df, aes(x = Age, y = Score)) +\n  geom_point(aes(color = Major), size = 3) +\n  labs(title = \"Student Scores vs. Age\", x = \"Age\", y = \"Score\") +\n  scale_x_continuous(limits = c(18, 25)) +\n  scale_color_manual(values = c(\"Economics\" = \"blue\", \"History\" = \"red\", \"Biology\" = \"green\"))\n\n\n\n\n\n\n\n\nExplanation: - scale_x_continuous() sets the limits for the x-axis. - `scale_color\n_manual()allows you to manually specify the colors for each level of theMajor` variable.\n\n\n\n\n\n\n\nCreate a scatter plot using a new data frame student_performance_df with variables Homework_Score and Exam_Score for eight students.\nAdd a third variable Study_Hours to the scatter plot, mapping it to the size of the points.\n\nSolution:\n\n# Creating the data frame\nstudent_performance_df &lt;- data.frame(\n  Student = c(\"Anna\", \"Ben\", \"Cathy\", \"Derek\", \"Ella\", \"Frank\", \"Grace\", \"Hannah\"),\n  Homework_Score = c(78, 85, 92, 88, 76, 90, 82, 94),\n  Exam_Score = c(80, 87, 90, 85, 79, 92, 85, 96),\n  Study_Hours = c(10, 12, 14, 9, 8, 13, 11, 15)\n)\n\n# Creating and customizing the scatter plot\nggplot(data = student_performance_df, aes(x = Homework_Score, y = Exam_Score, size = Study_Hours)) +\n  geom_point(color = \"blue\") +\n  labs(title = \"Homework vs. Exam Scores with Study Hours\", x = \"Homework Score\", y = \"Exam Score\")\n\n\n\n\n\n\n\n\n\n\n\n\nUsing a new data frame gender_major_df, create a stacked bar chart to visualize the number of male and female students in three different majors (Math, English, Science).\nCustomize the colors for male and female students differently and add titles and labels.\n\nSolution:\n\n# Creating the data frame\ngender_major_df &lt;- data.frame(\n  Major = rep(c(\"Math\", \"English\", \"Science\"), each = 2),\n  Gender = rep(c(\"Male\", \"Female\"), times = 3),\n  Count = c(30, 20, 25, 15, 35, 25)\n)\n\n# Creating and customizing the stacked bar chart\nggplot(data = gender_major_df, aes(x = Major, y = Count, fill = Gender)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Number of Students by Major and Gender\", x = \"Major\", y = \"Number of Students\") +\n  scale_fill_manual(values = c(\"Male\" = \"blue\", \"Female\" = \"pink\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCreate a line plot using a new data frame monthly_sales_df that tracks monthly sales (in thousands of dollars) for a company over a year.\nAdd points to the line plot, customize the line type to be dashed, and label the axes appropriately.\n\nSolution:\n\n# Creating the data frame\nmonthly_sales_df &lt;- data.frame(\n  Month = factor(c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"),\n                 levels = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\")),\n  Sales = c(120, 130, 150, 160, 170, 180, 175, 190, 200, 210, 220, 230)\n)\n\n# Creating and customizing the time series line plot\nggplot(data = monthly_sales_df, aes(x = Month, y = Sales)) +\n  geom_line(color = \"darkgreen\", linetype = \"dashed\", size = 1.2) +\n  geom_point(color = \"darkgreen\", size = 3) +\n  labs(title = \"Monthly Sales Over a Year\", x = \"Month\", y = \"Sales (in thousands)\")\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing a new data frame income_df, create a density plot to display the distribution of income levels (in thousands of dollars) across a population of 100 individuals.\nCustomize the density plot with a fill color and adjust the transparency.\n\nSolution:\n\n# Creating the data frame\nset.seed(42)  # For reproducibility\nincome_df &lt;- data.frame(\n  Income = c(rnorm(100, mean = 50, sd = 10))\n)\n\n# Creating and customizing the density plot\nggplot(data = income_df, aes(x = Income)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribution of Income Levels\", x = \"Income (in thousands)\", y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\n\nUsing a new data frame exam_scores_df that includes exam scores for three different classes (Math, Science, History), create a violin plot to visualize the distribution of scores for each class.\nCustomize the violin plot by changing the fill color and adding a title and labels.\n\nSolution:\n\n# Creating the data frame\nexam_scores_df &lt;- data.frame(\n  Class = rep(c(\"Math\", \"Science\", \"History\"), each = 50),\n  Score = c(rnorm(50, mean = 75, sd = 10), rnorm(50, mean = 80, sd = 12), rnorm(50, mean = 70, sd = 15))\n)\n\n# Creating and customizing the violin plot\nggplot(data = exam_scores_df, aes(x = Class, y = Score)) +\n  geom_violin(fill = \"purple\", color = \"black\") +\n  labs(title = \"Distribution of Exam Scores by Class\", x = \"Class\", y = \"Score\")",
    "crumbs": [
      "Tutorials",
      "5. Visualization with ggplot2"
    ]
  },
  {
    "objectID": "tutorial/05-content.html#the-grammar-of-graphics-the-gg-in-ggplot",
    "href": "tutorial/05-content.html#the-grammar-of-graphics-the-gg-in-ggplot",
    "title": "Tutorial 5: Visualization with ggplot2",
    "section": "",
    "text": "The Grammar of Graphics is a framework for data visualization that provides a structured and systematic approach to creating graphics. It was introduced by Leland Wilkinson in his book The Grammar of Graphics and serves as the foundation for ggplot2, a popular R package for data visualization. The key idea behind the Grammar of Graphics is that any statistical graphic can be built up from a few basic components, combined according to a set of rules. This approach allows for flexibility and consistency in creating complex visualizations.\n\n\n\nData: The dataset that you want to visualize. It typically consists of rows (observations) and columns (variables).\nAesthetics (aes): These are mappings between data variables and visual properties of the plot, such as position (x, y), color, size, shape, and more. For example, mapping a variable to the x-axis or mapping a variable to color.\nGeometries (geom): These are the visual elements that represent data on the plot, such as points, lines, bars, or shapes. For instance, geom_point() creates a scatter plot, geom_line() creates a line plot, and geom_bar() creates a bar chart.\nScales: Scales control how data values are mapped to aesthetic attributes like position, color, or size. For example, scale_x_continuous() controls the mapping of data values to positions along the x-axis.\nFacets: Faceting is a way to split the data into subsets and create multiple plots for each subset, allowing for comparisons across groups. For example, you can create separate plots for each level of a categorical variable.\nStatistics (stat): These are transformations of the data that are applied before plotting. For example, a histogram involves binning data and then counting the number of observations in each bin.\nCoordinates (coord): This component controls the coordinate system used for the plot. The most common coordinate system is Cartesian (x, y), but others include polar coordinates or log scales.\nThemes: Themes control the overall appearance of the plot, including non-data elements like font size, background color, grid lines, and axis labels. For example, theme_minimal() provides a clean, minimalistic style for the plot.\n\n\n\n\n\nggplot2 is an implementation of the Grammar of Graphics in R. It allows you to create complex visualizations by combining these basic components in a structured way. Here’s how ggplot2 uses the Grammar of Graphics:\n\nInitialization with ggplot():\n\nThe ggplot() function initializes a ggplot object and specifies the dataset you want to use. For example:\n\nggplot(data = students_df)\n\nThis function doesn’t produce a plot by itself; it sets up the plot object to which you can add layers.\n\nAesthetic Mapping with aes():\n\nInside the ggplot() function or within individual geometries, you define aesthetic mappings using the aes() function. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score))\n\nThis mapping connects the data to the visual properties of the plot, like mapping Age to the x-axis and Score to the y-axis.\n\nAdding Geometries with geom_*() Functions:\n\nGeometries are added to the plot to represent the data. Each geometry corresponds to a type of plot element, such as points, lines, or bars. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point()\n\nThis adds a layer of points to the plot, creating a scatter plot.\n\nCustomizing Scales and Axes:\n\nScales can be customized to control how data values map to visual attributes. For example, you can adjust the x-axis limits or change the color scale:\n\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point() +\n  scale_x_continuous(limits = c(18, 25))\n\n\nFaceting for Multi-Panel Plots:\n\nFaceting allows you to create multiple plots based on subsets of the data. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point() +\n  facet_wrap(~ Major)\n\nThis creates separate scatter plots for each Major.\n\nApplying Themes:\n\nThemes are used to control the appearance of non-data elements in the plot. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point() +\n  theme_minimal()\n\nThis applies a minimalistic style to the plot.\n\n\n\n\n\nMapping in ggplot2 refers to the connection between your data variables and the visual aspects of your plot. The aes() function is where this mapping happens. It tells ggplot2 how to map your data onto the plot. Here’s how mapping works:\n\nPosition Mapping (x and y):\n\nThe most common type of mapping is position mapping, where you map variables to the x-axis and y-axis. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score))\n\nThis maps the Age variable to the x-axis and the Score variable to the y-axis.\n\nColor Mapping:\n\nYou can map a variable to the color aesthetic to differentiate data points by a categorical or continuous variable. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score, color = Major))\n\nThis maps the Major variable to the color of the points, allowing different colors for different majors.\n\nSize Mapping:\n\nThe size of points or other elements can be mapped to a variable. For example:\n\nggplot(data = student_performance_df, aes(x = Homework_Score, y = Exam_Score, size = Study_Hours))\n\nThis maps the Study_Hours variable to the size of the points, with more study hours represented by larger points.\n\nShape Mapping:\n\nSimilarly, you can map a variable to the shape aesthetic to differentiate points by shape. For example:\n\nggplot(data = students_df, aes(x = Age, y = Score, shape = Gender))\n\nThis maps the Gender variable to the shape of the points, using different shapes for male and female students.\n\n\n\n\n\nUnderstanding the Grammar of Graphics is essential because it gives you a powerful, flexible, and consistent way to create visualizations. By understanding how the different components work together, you can build complex and customized plots to meet your specific data visualization needs. It also makes it easier to debug and refine your plots since you know exactly how each part of the plot is constructed.",
    "crumbs": [
      "Tutorials",
      "5. Visualization with ggplot2"
    ]
  },
  {
    "objectID": "tutorial/05-content.html#introduction-to-ggplot2",
    "href": "tutorial/05-content.html#introduction-to-ggplot2",
    "title": "Tutorial 5: Visualization with ggplot2",
    "section": "",
    "text": "ggplot2 is based on the grammar of graphics, which provides a structured approach to building plots by layering components such as data, aesthetics, and geometries.\n\n\nBefore diving into ggplot2, it’s important to understand the difference between tibbles and data frames.\n\nTibbles are modern versions of data frames provided by the Tidyverse, which are more user-friendly for data analysis. They provide better printing methods and do not convert strings to factors by default.\nFor now, we will continue using data.frame to create datasets for simplicity. However, in future tutorials, we will introduce tibbles and their advantages.\n\n\n\n\nIf you haven’t already installed the Tidyverse, you can install ggplot2 individually or load it as part of the Tidyverse.\n\n# Install ggplot2 (if not already installed)\ninstall.packages(\"ggplot2\")\n\n# Load ggplot2\nlibrary(ggplot2)\n\nExplanation: - install.packages() installs ggplot2 if it’s not already installed. - library() loads the package, making its functions available for use.\n\n\n\nThe basic structure of a ggplot2 plot consists of the following components: - Data: The dataset being used. - Aesthetics (aes): Mappings between variables and visual properties such as x and y positions, colors, sizes, etc. - Geometries (geom): The type of plot or geometric objects used to represent the data (e.g., points, lines, bars).\nHere’s an example of a simple scatter plot:\n\n# Example data frame\nstudents_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"),\n  Score = c(85, 90, 78, 88, 92),\n  Age = c(20, 21, 19, 22, 20)\n)\n\n# Creating a scatter plot of Score vs. Age\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point()\n\n\n\n\n\n\n\n\nExplanation: - ggplot() initializes the plot and specifies the data to be used. - aes() defines the aesthetic mappings, such as x and y variables. - geom_point() adds a layer of points (a scatter plot) to the plot.",
    "crumbs": [
      "Tutorials",
      "5. Visualization with ggplot2"
    ]
  },
  {
    "objectID": "tutorial/05-content.html#creating-different-types-of-plots",
    "href": "tutorial/05-content.html#creating-different-types-of-plots",
    "title": "Tutorial 5: Visualization with ggplot2",
    "section": "",
    "text": "Scatter plots are used to visualize the relationship between two continuous variables.\n\n# Scatter plot with additional customizations\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point(color = \"blue\", size = 3) +\n  labs(title = \"Student Scores vs. Age\", x = \"Age\", y = \"Score\")\n\n\n\n\n\n\n\n\nExplanation: - The color and size arguments in geom_point() customize the appearance of the points. - labs() is used to add titles and labels to the axes.\n\n\n\nBar charts are used to compare the counts or frequencies of categorical variables.\n\n# Example data frame for bar chart\nmajors_df &lt;- data.frame(\n  Major = c(\"Economics\", \"History\", \"Biology\"),\n  Students = c(50, 40, 30)\n)\n\n# Creating a bar chart of the number of students per major\nggplot(data = majors_df, aes(x = Major, y = Students)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(title = \"Number of Students by Major\", x = \"Major\", y = \"Number of Students\")\n\n\n\n\n\n\n\n\nExplanation: - geom_bar() is used for creating bar charts. The stat = \"identity\" argument indicates that the heights of the bars should represent the values in the dataset. - The fill argument customizes the color of the bars.\n\n\n\nLine plots are useful for visualizing trends over time or across ordered categories.\n\n# Example data frame for line plot\nyearly_scores_df &lt;- data.frame(\n  Year = c(2018, 2019, 2020, 2021, 2022),\n  AverageScore = c(80, 82, 85, 87, 90)\n)\n\n# Creating a line plot of average scores over years\nggplot(data = yearly_scores_df, aes(x = Year, y = AverageScore)) +\n  geom_line(color = \"red\", size = 1.5) +\n  geom_point(color = \"red\", size = 3) +\n  labs(title = \"Average Scores Over Time\", x = \"Year\", y = \"Average Score\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nExplanation: - geom_line() adds a line to the plot, while geom_point() overlays points on the line. - The color and size of the line and points are customized using color and size arguments.\n\n\n\nHistograms display the distribution of a single continuous variable by dividing it into bins.\n\n# Creating a histogram of student scores\nggplot(data = students_df, aes(x = Score)) +\n  geom_histogram(binwidth = 5, fill = \"green\", color = \"black\") +\n  labs(title = \"Distribution of Student Scores\", x = \"Score\", y = \"Frequency\")\n\n\n\n\n\n\n\n\nExplanation: - geom_histogram() creates the histogram. The binwidth argument controls the width of the bins. - The fill and color arguments customize the color of the bars and their outlines.\n\n\n\nBox plots are used to visualize the distribution of a continuous variable and identify potential outliers.\n\n# Example data frame with Major added\nstudents_major_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"),\n  Score = c(85, 90, 78, 88, 92),\n  Age = c(20, 21, 19, 22, 20),\n  Major = c(\"Economics\", \"Economics\", \"History\", \"Biology\", \"History\")\n)\n\n# Creating a box plot of scores by major\nggplot(data = students_major_df, aes(x = Major, y = Score)) +\n  geom_boxplot(fill = \"orange\") +\n  labs(title = \"Box Plot of Scores by Major\", x = \"Major\", y = \"Score\")\n\n\n\n\n\n\n\n\nExplanation: - geom_boxplot() creates the box plot, which shows the median, quartiles, and potential outliers for each group.",
    "crumbs": [
      "Tutorials",
      "5. Visualization with ggplot2"
    ]
  },
  {
    "objectID": "tutorial/05-content.html#customizing-ggplot2-plots",
    "href": "tutorial/05-content.html#customizing-ggplot2-plots",
    "title": "Tutorial 5: Visualization with ggplot2",
    "section": "",
    "text": "Themes in ggplot2 allow you to customize the overall appearance of your plots.\n\n# Applying a minimal theme to a scatter plot\nggplot(data = students_df, aes(x = Age, y = Score)) +\n  geom_point(color = \"blue\", size = 3) +\n  labs(title = \"Student Scores vs. Age\", x = \"Age\", y = \"Score\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nExplanation: - theme_minimal() applies a clean and minimalistic style to the plot. Other themes include theme_classic(), theme_light(), and more.\n\n\n\nFaceting allows you to create multiple plots based on a categorical variable.\n\n# Creating facets based on Major\nggplot(data = students_major_df, aes(x = Age, y = Score)) +\n  geom_point(color = \"purple\", size = 3) +\n  labs(title = \"Student Scores vs. Age by Major\", x = \"Age\", y = \"Score\") +\n  facet_wrap(~ Major)\n\n\n\n\n\n\n\n\nExplanation: - facet_wrap(~ Major) creates a separate plot for each level of the Major variable.\n\n\n\nYou can customize the scales of your plot, including axis limits and colors.\n\n# Customizing axis limits and colors\nggplot(data = students_major_df, aes(x = Age, y = Score)) +\n  geom_point(aes(color = Major), size = 3) +\n  labs(title = \"Student Scores vs. Age\", x = \"Age\", y = \"Score\") +\n  scale_x_continuous(limits = c(18, 25)) +\n  scale_color_manual(values = c(\"Economics\" = \"blue\", \"History\" = \"red\", \"Biology\" = \"green\"))\n\n\n\n\n\n\n\n\nExplanation: - scale_x_continuous() sets the limits for the x-axis. - `scale_color\n_manual()allows you to manually specify the colors for each level of theMajor` variable.",
    "crumbs": [
      "Tutorials",
      "5. Visualization with ggplot2"
    ]
  },
  {
    "objectID": "tutorial/05-content.html#exercises-and-solutions",
    "href": "tutorial/05-content.html#exercises-and-solutions",
    "title": "Tutorial 5: Visualization with ggplot2",
    "section": "",
    "text": "Create a scatter plot using a new data frame student_performance_df with variables Homework_Score and Exam_Score for eight students.\nAdd a third variable Study_Hours to the scatter plot, mapping it to the size of the points.\n\nSolution:\n\n# Creating the data frame\nstudent_performance_df &lt;- data.frame(\n  Student = c(\"Anna\", \"Ben\", \"Cathy\", \"Derek\", \"Ella\", \"Frank\", \"Grace\", \"Hannah\"),\n  Homework_Score = c(78, 85, 92, 88, 76, 90, 82, 94),\n  Exam_Score = c(80, 87, 90, 85, 79, 92, 85, 96),\n  Study_Hours = c(10, 12, 14, 9, 8, 13, 11, 15)\n)\n\n# Creating and customizing the scatter plot\nggplot(data = student_performance_df, aes(x = Homework_Score, y = Exam_Score, size = Study_Hours)) +\n  geom_point(color = \"blue\") +\n  labs(title = \"Homework vs. Exam Scores with Study Hours\", x = \"Homework Score\", y = \"Exam Score\")\n\n\n\n\n\n\n\n\n\n\n\n\nUsing a new data frame gender_major_df, create a stacked bar chart to visualize the number of male and female students in three different majors (Math, English, Science).\nCustomize the colors for male and female students differently and add titles and labels.\n\nSolution:\n\n# Creating the data frame\ngender_major_df &lt;- data.frame(\n  Major = rep(c(\"Math\", \"English\", \"Science\"), each = 2),\n  Gender = rep(c(\"Male\", \"Female\"), times = 3),\n  Count = c(30, 20, 25, 15, 35, 25)\n)\n\n# Creating and customizing the stacked bar chart\nggplot(data = gender_major_df, aes(x = Major, y = Count, fill = Gender)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Number of Students by Major and Gender\", x = \"Major\", y = \"Number of Students\") +\n  scale_fill_manual(values = c(\"Male\" = \"blue\", \"Female\" = \"pink\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCreate a line plot using a new data frame monthly_sales_df that tracks monthly sales (in thousands of dollars) for a company over a year.\nAdd points to the line plot, customize the line type to be dashed, and label the axes appropriately.\n\nSolution:\n\n# Creating the data frame\nmonthly_sales_df &lt;- data.frame(\n  Month = factor(c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"),\n                 levels = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\")),\n  Sales = c(120, 130, 150, 160, 170, 180, 175, 190, 200, 210, 220, 230)\n)\n\n# Creating and customizing the time series line plot\nggplot(data = monthly_sales_df, aes(x = Month, y = Sales)) +\n  geom_line(color = \"darkgreen\", linetype = \"dashed\", size = 1.2) +\n  geom_point(color = \"darkgreen\", size = 3) +\n  labs(title = \"Monthly Sales Over a Year\", x = \"Month\", y = \"Sales (in thousands)\")\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing a new data frame income_df, create a density plot to display the distribution of income levels (in thousands of dollars) across a population of 100 individuals.\nCustomize the density plot with a fill color and adjust the transparency.\n\nSolution:\n\n# Creating the data frame\nset.seed(42)  # For reproducibility\nincome_df &lt;- data.frame(\n  Income = c(rnorm(100, mean = 50, sd = 10))\n)\n\n# Creating and customizing the density plot\nggplot(data = income_df, aes(x = Income)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribution of Income Levels\", x = \"Income (in thousands)\", y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\n\nUsing a new data frame exam_scores_df that includes exam scores for three different classes (Math, Science, History), create a violin plot to visualize the distribution of scores for each class.\nCustomize the violin plot by changing the fill color and adding a title and labels.\n\nSolution:\n\n# Creating the data frame\nexam_scores_df &lt;- data.frame(\n  Class = rep(c(\"Math\", \"Science\", \"History\"), each = 50),\n  Score = c(rnorm(50, mean = 75, sd = 10), rnorm(50, mean = 80, sd = 12), rnorm(50, mean = 70, sd = 15))\n)\n\n# Creating and customizing the violin plot\nggplot(data = exam_scores_df, aes(x = Class, y = Score)) +\n  geom_violin(fill = \"purple\", color = \"black\") +\n  labs(title = \"Distribution of Exam Scores by Class\", x = \"Class\", y = \"Score\")",
    "crumbs": [
      "Tutorials",
      "5. Visualization with ggplot2"
    ]
  },
  {
    "objectID": "tutorial/06-content.html",
    "href": "tutorial/06-content.html",
    "title": "Tutorial 6: Advanced Data Wrangling with Tidyverse",
    "section": "",
    "text": "In this tutorial, we will explore advanced data wrangling techniques using the Tidyverse, with examples related to the economics of education. We will cover tasks such as merging datasets, reshaping data, handling missing values, and analyzing educational data. These techniques will help you efficiently prepare and analyze complex datasets in educational economics research. First, load the tidyverse package.\n\nlibrary(tidyverse)\n\n\n\nEducational datasets often come from multiple sources, such as student assessments, school funding records, and demographic surveys. Combining these datasets is a crucial step in analysis.\n\n\nAn inner join merges two datasets, keeping only rows with matching values in both. For instance, you may want to combine student test scores with school funding data.\n\n# Example data frames\ntest_scores_df &lt;- data.frame(\n  StudentID = c(1, 2, 3, 4, 5),\n  Math_Score = c(85, 90, 78, 88, 92),\n  Reading_Score = c(82, 88, 80, 85, 91)\n)\n\nschool_funding_df &lt;- data.frame(\n  SchoolID = c(1, 1, 2, 2, 3),\n  StudentID = c(1, 2, 3, 4, 5),\n  Funding_Per_Student = c(10000, 10000, 8000, 8000, 9000)\n)\n\n# Performing an inner join on StudentID\ncombined_df &lt;- test_scores_df |&gt; inner_join(school_funding_df, by = \"StudentID\")\ncombined_df\n\n  StudentID Math_Score Reading_Score SchoolID Funding_Per_Student\n1         1         85            82        1               10000\n2         2         90            88        1               10000\n3         3         78            80        2                8000\n4         4         88            85        2                8000\n5         5         92            91        3                9000\n\n\nExplanation: - inner_join() merges test_scores_df and school_funding_df by matching the StudentID column. Only students present in both datasets are included in the result.\n\n\n\nA left join includes all rows from the left dataset (e.g., student performance) and adds matching rows from the right dataset (e.g., demographics). Missing values are filled with NA.\n\n# Example data frames\ndemographics_df &lt;- data.frame(\n  StudentID = c(1, 2, 3, 6),\n  Gender = c(\"F\", \"M\", \"F\", \"M\"),\n  SES = c(\"High\", \"Low\", \"Medium\", \"Low\")\n)\n\n# Performing a left join on StudentID\ncombined_left_df &lt;- test_scores_df |&gt; left_join(demographics_df, by = \"StudentID\")\ncombined_left_df\n\n  StudentID Math_Score Reading_Score Gender    SES\n1         1         85            82      F   High\n2         2         90            88      M    Low\n3         3         78            80      F Medium\n4         4         88            85   &lt;NA&gt;   &lt;NA&gt;\n5         5         92            91   &lt;NA&gt;   &lt;NA&gt;\n\n\nExplanation: - left_join() includes all students from test_scores_df and adds corresponding demographic information where available. Students without demographic data have NA in those columns.\n\n\n\nA full join merges all rows from both datasets, filling unmatched areas with NA.\n\n# Performing a full join on StudentID\nfull_combined_df &lt;- test_scores_df |&gt; full_join(demographics_df, by = \"StudentID\")\nfull_combined_df\n\n  StudentID Math_Score Reading_Score Gender    SES\n1         1         85            82      F   High\n2         2         90            88      M    Low\n3         3         78            80      F Medium\n4         4         88            85   &lt;NA&gt;   &lt;NA&gt;\n5         5         92            91   &lt;NA&gt;   &lt;NA&gt;\n6         6         NA            NA      M    Low\n\n\nExplanation: - full_join() combines all rows from test_scores_df and demographics_df, retaining all students and filling in missing values with NA.\n\n\n\n\nReshaping data is often necessary to perform certain types of analyses, such as tracking student performance across subjects or years.\n\n\npivot_longer() is useful for converting wide data (where each subject is a column) into long data, which is more suitable for longitudinal analysis.\n\n# Example wide data frame\nsubject_scores_df &lt;- data.frame(\n  StudentID = c(1, 2, 3),\n  Math_2019 = c(85, 88, 90),\n  Math_2020 = c(87, 85, 92),\n  Reading_2019 = c(82, 80, 88),\n  Reading_2020 = c(85, 83, 90)\n)\n\n# Converting to long format\nlong_scores_df &lt;- subject_scores_df |&gt; \n  pivot_longer(cols = -StudentID, names_to = c(\"Subject\", \"Year\"), names_sep = \"_\", values_to = \"Score\")\nlong_scores_df\n\n# A tibble: 12 × 4\n   StudentID Subject Year  Score\n       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;\n 1         1 Math    2019     85\n 2         1 Math    2020     87\n 3         1 Reading 2019     82\n 4         1 Reading 2020     85\n 5         2 Math    2019     88\n 6         2 Math    2020     85\n 7         2 Reading 2019     80\n 8         2 Reading 2020     83\n 9         3 Math    2019     90\n10         3 Math    2020     92\n11         3 Reading 2019     88\n12         3 Reading 2020     90\n\n\nExplanation: - pivot_longer() reshapes the dataset so that each subject’s scores across different years are in their own rows. The names_to and names_sep arguments split the column names into Subject and Year.\n\n\n\npivot_wider() converts long-format data back to wide format, which is useful for comparing scores across subjects or years side by side.\n\n# Converting back to wide format\nwide_scores_df &lt;- long_scores_df |&gt; \n  pivot_wider(names_from = c(\"Subject\", \"Year\"), values_from = \"Score\")\nwide_scores_df\n\n# A tibble: 3 × 5\n  StudentID Math_2019 Math_2020 Reading_2019 Reading_2020\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1         1        85        87           82           85\n2         2        88        85           80           83\n3         3        90        92           88           90\n\n\nExplanation: - pivot_wider() rearranges the data so that each subject and year combination becomes a separate column, allowing for easy comparison across different time points.\n\n\n\n\nEducational datasets often contain missing values due to various reasons, such as incomplete surveys or missing records. Proper handling of missing data is crucial for accurate analysis.\n\n\nYou can use is.na() to identify missing values and summarise() to count them.\n\n# Identifying missing values in the combined dataset\nmissing_summary &lt;- combined_left_df |&gt; \n  summarise(across(everything(), ~sum(is.na(.))))\nmissing_summary\n\n  StudentID Math_Score Reading_Score Gender SES\n1         0          0             0      2   2\n\n\nExplanation: - This code counts the number of missing values (NA) in each column of the combined_left_df dataset, providing a summary of data completeness.\n\n\n\nImputation involves replacing missing values with substituted values. A common approach in educational data is to use the mean or median.\n\n# Replacing missing SES values with \"Unknown\"\nfilled_df &lt;- combined_left_df |&gt; \n  mutate(SES = replace_na(SES, \"Unknown\"))\nfilled_df\n\n  StudentID Math_Score Reading_Score Gender     SES\n1         1         85            82      F    High\n2         2         90            88      M     Low\n3         3         78            80      F  Medium\n4         4         88            85   &lt;NA&gt; Unknown\n5         5         92            91   &lt;NA&gt; Unknown\n\n\nExplanation: - replace_na() replaces NA values in the SES column with \"Unknown\", which is useful when the socioeconomic status is missing.\n\n\n\nIn some cases, it may be necessary to remove rows with missing data to ensure the integrity of the analysis.\n\n# Removing rows with missing Math scores\ncleaned_scores_df &lt;- combined_df |&gt; drop_na(Math_Score)\ncleaned_scores_df\n\n  StudentID Math_Score Reading_Score SchoolID Funding_Per_Student\n1         1         85            82        1               10000\n2         2         90            88        1               10000\n3         3         78            80        2                8000\n4         4         88            85        2                8000\n5         5         92            91        3                9000\n\n\nExplanation: - drop_na() removes rows where the Math_Score is missing, ensuring that only complete cases are used in the analysis.\n\n\n\n\n\n\n\nCreate two data frames, student_scores_df with columns StudentID, Math_Score, and Reading_Score, and teacher_info_df with columns TeacherID, StudentID, and TeacherExperience. Perform a left join to combine these datasets.\n\nSolution:\n\n# Creating the data frames\nstudent_scores_df &lt;- data.frame(\n  StudentID = c(1, 2, 3, 4),\n  Math_Score = c(85, 90, 78, 88),\n  Reading_Score = c(82, 88, 80, 85)\n)\n\nteacher_info_df &lt;- data.frame(\n  TeacherID = c(101, 102, 101, 103),\n  StudentID = c(1, 2, 3, 4),\n  TeacherExperience = c(5, 10, 5, 7)\n)\n\n# Performing the left join\ncombined_teacher_df &lt;- student_scores_df |&gt; left_join(teacher_info_df, by = \"StudentID\")\ncombined_teacher_df\n\n  StudentID Math_Score Reading_Score TeacherID TeacherExperience\n1         1         85            82       101                 5\n2         2         90            88       102                10\n3         3         78            80       101                 5\n4         4         88            85       103                 7\n\n\n\n\n\n\nStart with a wide data frame cohort_scores_df with columns StudentID, Cohort_2019_Math, Cohort_2019_Reading, Cohort_2020_Math, and Cohort_2020_Reading. Convert this data frame to a long format, separating cohort year and subject.\n\nSolution:\n\n# Creating the wide data frame\ncohort_scores_df &lt;- data.frame(\n  StudentID = c(1, 2, 3),\n  Cohort_2019_Math = c(85, 88, 90),\n  Cohort_2019_Reading = c(82, 80, 88),\n  Cohort_2020_Math = c(87, 85, 92),\n  Cohort_2020_Reading = c(85, 83, 90)\n)\n\n# Converting to long format\nlong_cohort_df &lt;- cohort_scores_df |&gt; \n  pivot_longer(\n    cols = -StudentID, \n    names_to = c(\"Cohort_Year\", \"Subject\"), names_sep = \"_\", values_to = \"Score\"\n  )\n\nWarning: Expected 2 pieces. Additional pieces discarded in 4 rows [1, 2, 3, 4].\n\nlong_cohort_df\n\n# A tibble: 12 × 4\n   StudentID Cohort_Year Subject Score\n       &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   &lt;dbl&gt;\n 1         1 Cohort      2019       85\n 2         1 Cohort      2019       82\n 3         1 Cohort      2020       87\n 4         1 Cohort      2020       85\n 5         2 Cohort      2019       88\n 6         2 Cohort      2019       80\n 7         2 Cohort      2020       85\n 8         2 Cohort      2020       83\n 9         3 Cohort      2019       90\n10         3 Cohort      2019       88\n11         3 Cohort      2020       92\n12         3 Cohort      2020       90\n\n\n\n\n\n\nCreate a data frame school_survey_df with columns SchoolID, StudentSatisfaction, and TeacherTurnover. Introduce missing values into the StudentSatisfaction column. Replace these missing values with the median of the available satisfaction scores.\n\nSolution:\n\n# Creating the data frame with missing values\nschool_survey_df &lt;- data.frame(\n  SchoolID = c(1, 2, 3, 4),\n  StudentSatisfaction = c(85, NA, 78, 90),\n  TeacherTurnover = c(10, 15, 8, 12)\n)\n\n# Replacing missing values with the median\nschool_survey_df &lt;- school_survey_df |&gt; \n  mutate(StudentSatisfaction = replace_na(StudentSatisfaction, median(StudentSatisfaction, na.rm = TRUE)))\nschool_survey_df\n\n  SchoolID StudentSatisfaction TeacherTurnover\n1        1                  85              10\n2        2                  85              15\n3        3                  78               8\n4        4                  90              12\n\n\n\n\n\n\nCreate two data frames, school_expenditure_df with columns SchoolID, Expenditure_Per_Student, and Total_Expenditure, and student_scores_df with SchoolID, Math_Score, and Reading_Score. Perform a full join on SchoolID to combine these datasets, then filter to keep only schools with available expenditure data.\n\nSolution:\n\n# Creating the data frames\nschool_expenditure_df &lt;- data.frame(\n  SchoolID = c(1, 2, 3),\n  Expenditure_Per_Student = c(10000, 8000, 9000),\n  Total_Expenditure = c(500000, 400000, 450000)\n)\n\nstudent_scores_df &lt;- data.frame(\n  SchoolID = c(1, 2, 4),\n  Math_Score = c(85, 90, 78),\n  Reading_Score = c(82, 88, 80)\n)\n\n# Performing the full join\ncombined_expenditure_df &lt;- school_expenditure_df |&gt; full_join(student_scores_df, by = \"SchoolID\")\n\n# Filtering to keep only schools with expenditure data\nfiltered_expenditure_df &lt;- combined_expenditure_df |&gt; filter(!is.na(Expenditure_Per_Student))\nfiltered_expenditure_df\n\n  SchoolID Expenditure_Per_Student Total_Expenditure Math_Score Reading_Score\n1        1                   10000            500000         85            82\n2        2                    8000            400000         90            88\n3        3                    9000            450000         NA            NA\n\n\n\n\n\n\nUsing a data frame annual_scores_df with columns Year, SchoolID, Average_Math_Score, and Average_Reading_Score, convert the data from wide to long format to analyze trends in average scores over time.\n\nSolution:\n\n# Creating the wide data frame\nannual_scores_df &lt;- data.frame(\n  Year = c(2019, 2020, 2021),\n  SchoolID = c(1, 1, 1),\n  Average_Math_Score = c(78, 80, 82),\n  Average_Reading_Score = c(75, 77, 79)\n)\n\n# Converting to long format\nlong_annual_scores_df &lt;- annual_scores_df |&gt; \n  pivot_longer(cols = starts_with(\"Average\"), names_to = \"Subject\", names_prefix = \"Average_\", values_to = \"Score\")\nlong_annual_scores_df\n\n# A tibble: 6 × 4\n   Year SchoolID Subject       Score\n  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n1  2019        1 Math_Score       78\n2  2019        1 Reading_Score    75\n3  2020        1 Math_Score       80\n4  2020        1 Reading_Score    77\n5  2021        1 Math_Score       82\n6  2021        1 Reading_Score    79",
    "crumbs": [
      "Tutorials",
      "6. Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "tutorial/06-content.html#merging-datasets-in-education-research",
    "href": "tutorial/06-content.html#merging-datasets-in-education-research",
    "title": "Tutorial 6: Advanced Data Wrangling with Tidyverse",
    "section": "",
    "text": "Educational datasets often come from multiple sources, such as student assessments, school funding records, and demographic surveys. Combining these datasets is a crucial step in analysis.\n\n\nAn inner join merges two datasets, keeping only rows with matching values in both. For instance, you may want to combine student test scores with school funding data.\n\n# Example data frames\ntest_scores_df &lt;- data.frame(\n  StudentID = c(1, 2, 3, 4, 5),\n  Math_Score = c(85, 90, 78, 88, 92),\n  Reading_Score = c(82, 88, 80, 85, 91)\n)\n\nschool_funding_df &lt;- data.frame(\n  SchoolID = c(1, 1, 2, 2, 3),\n  StudentID = c(1, 2, 3, 4, 5),\n  Funding_Per_Student = c(10000, 10000, 8000, 8000, 9000)\n)\n\n# Performing an inner join on StudentID\ncombined_df &lt;- test_scores_df |&gt; inner_join(school_funding_df, by = \"StudentID\")\ncombined_df\n\n  StudentID Math_Score Reading_Score SchoolID Funding_Per_Student\n1         1         85            82        1               10000\n2         2         90            88        1               10000\n3         3         78            80        2                8000\n4         4         88            85        2                8000\n5         5         92            91        3                9000\n\n\nExplanation: - inner_join() merges test_scores_df and school_funding_df by matching the StudentID column. Only students present in both datasets are included in the result.\n\n\n\nA left join includes all rows from the left dataset (e.g., student performance) and adds matching rows from the right dataset (e.g., demographics). Missing values are filled with NA.\n\n# Example data frames\ndemographics_df &lt;- data.frame(\n  StudentID = c(1, 2, 3, 6),\n  Gender = c(\"F\", \"M\", \"F\", \"M\"),\n  SES = c(\"High\", \"Low\", \"Medium\", \"Low\")\n)\n\n# Performing a left join on StudentID\ncombined_left_df &lt;- test_scores_df |&gt; left_join(demographics_df, by = \"StudentID\")\ncombined_left_df\n\n  StudentID Math_Score Reading_Score Gender    SES\n1         1         85            82      F   High\n2         2         90            88      M    Low\n3         3         78            80      F Medium\n4         4         88            85   &lt;NA&gt;   &lt;NA&gt;\n5         5         92            91   &lt;NA&gt;   &lt;NA&gt;\n\n\nExplanation: - left_join() includes all students from test_scores_df and adds corresponding demographic information where available. Students without demographic data have NA in those columns.\n\n\n\nA full join merges all rows from both datasets, filling unmatched areas with NA.\n\n# Performing a full join on StudentID\nfull_combined_df &lt;- test_scores_df |&gt; full_join(demographics_df, by = \"StudentID\")\nfull_combined_df\n\n  StudentID Math_Score Reading_Score Gender    SES\n1         1         85            82      F   High\n2         2         90            88      M    Low\n3         3         78            80      F Medium\n4         4         88            85   &lt;NA&gt;   &lt;NA&gt;\n5         5         92            91   &lt;NA&gt;   &lt;NA&gt;\n6         6         NA            NA      M    Low\n\n\nExplanation: - full_join() combines all rows from test_scores_df and demographics_df, retaining all students and filling in missing values with NA.",
    "crumbs": [
      "Tutorials",
      "6. Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "tutorial/06-content.html#reshaping-educational-data",
    "href": "tutorial/06-content.html#reshaping-educational-data",
    "title": "Tutorial 6: Advanced Data Wrangling with Tidyverse",
    "section": "",
    "text": "Reshaping data is often necessary to perform certain types of analyses, such as tracking student performance across subjects or years.\n\n\npivot_longer() is useful for converting wide data (where each subject is a column) into long data, which is more suitable for longitudinal analysis.\n\n# Example wide data frame\nsubject_scores_df &lt;- data.frame(\n  StudentID = c(1, 2, 3),\n  Math_2019 = c(85, 88, 90),\n  Math_2020 = c(87, 85, 92),\n  Reading_2019 = c(82, 80, 88),\n  Reading_2020 = c(85, 83, 90)\n)\n\n# Converting to long format\nlong_scores_df &lt;- subject_scores_df |&gt; \n  pivot_longer(cols = -StudentID, names_to = c(\"Subject\", \"Year\"), names_sep = \"_\", values_to = \"Score\")\nlong_scores_df\n\n# A tibble: 12 × 4\n   StudentID Subject Year  Score\n       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;\n 1         1 Math    2019     85\n 2         1 Math    2020     87\n 3         1 Reading 2019     82\n 4         1 Reading 2020     85\n 5         2 Math    2019     88\n 6         2 Math    2020     85\n 7         2 Reading 2019     80\n 8         2 Reading 2020     83\n 9         3 Math    2019     90\n10         3 Math    2020     92\n11         3 Reading 2019     88\n12         3 Reading 2020     90\n\n\nExplanation: - pivot_longer() reshapes the dataset so that each subject’s scores across different years are in their own rows. The names_to and names_sep arguments split the column names into Subject and Year.\n\n\n\npivot_wider() converts long-format data back to wide format, which is useful for comparing scores across subjects or years side by side.\n\n# Converting back to wide format\nwide_scores_df &lt;- long_scores_df |&gt; \n  pivot_wider(names_from = c(\"Subject\", \"Year\"), values_from = \"Score\")\nwide_scores_df\n\n# A tibble: 3 × 5\n  StudentID Math_2019 Math_2020 Reading_2019 Reading_2020\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1         1        85        87           82           85\n2         2        88        85           80           83\n3         3        90        92           88           90\n\n\nExplanation: - pivot_wider() rearranges the data so that each subject and year combination becomes a separate column, allowing for easy comparison across different time points.",
    "crumbs": [
      "Tutorials",
      "6. Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "tutorial/06-content.html#handling-missing-data-in-educational-datasets",
    "href": "tutorial/06-content.html#handling-missing-data-in-educational-datasets",
    "title": "Tutorial 6: Advanced Data Wrangling with Tidyverse",
    "section": "",
    "text": "Educational datasets often contain missing values due to various reasons, such as incomplete surveys or missing records. Proper handling of missing data is crucial for accurate analysis.\n\n\nYou can use is.na() to identify missing values and summarise() to count them.\n\n# Identifying missing values in the combined dataset\nmissing_summary &lt;- combined_left_df |&gt; \n  summarise(across(everything(), ~sum(is.na(.))))\nmissing_summary\n\n  StudentID Math_Score Reading_Score Gender SES\n1         0          0             0      2   2\n\n\nExplanation: - This code counts the number of missing values (NA) in each column of the combined_left_df dataset, providing a summary of data completeness.\n\n\n\nImputation involves replacing missing values with substituted values. A common approach in educational data is to use the mean or median.\n\n# Replacing missing SES values with \"Unknown\"\nfilled_df &lt;- combined_left_df |&gt; \n  mutate(SES = replace_na(SES, \"Unknown\"))\nfilled_df\n\n  StudentID Math_Score Reading_Score Gender     SES\n1         1         85            82      F    High\n2         2         90            88      M     Low\n3         3         78            80      F  Medium\n4         4         88            85   &lt;NA&gt; Unknown\n5         5         92            91   &lt;NA&gt; Unknown\n\n\nExplanation: - replace_na() replaces NA values in the SES column with \"Unknown\", which is useful when the socioeconomic status is missing.\n\n\n\nIn some cases, it may be necessary to remove rows with missing data to ensure the integrity of the analysis.\n\n# Removing rows with missing Math scores\ncleaned_scores_df &lt;- combined_df |&gt; drop_na(Math_Score)\ncleaned_scores_df\n\n  StudentID Math_Score Reading_Score SchoolID Funding_Per_Student\n1         1         85            82        1               10000\n2         2         90            88        1               10000\n3         3         78            80        2                8000\n4         4         88            85        2                8000\n5         5         92            91        3                9000\n\n\nExplanation: - drop_na() removes rows where the Math_Score is missing, ensuring that only complete cases are used in the analysis.",
    "crumbs": [
      "Tutorials",
      "6. Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "tutorial/06-content.html#exercises-and-solutions",
    "href": "tutorial/06-content.html#exercises-and-solutions",
    "title": "Tutorial 6: Advanced Data Wrangling with Tidyverse",
    "section": "",
    "text": "Create two data frames, student_scores_df with columns StudentID, Math_Score, and Reading_Score, and teacher_info_df with columns TeacherID, StudentID, and TeacherExperience. Perform a left join to combine these datasets.\n\nSolution:\n\n# Creating the data frames\nstudent_scores_df &lt;- data.frame(\n  StudentID = c(1, 2, 3, 4),\n  Math_Score = c(85, 90, 78, 88),\n  Reading_Score = c(82, 88, 80, 85)\n)\n\nteacher_info_df &lt;- data.frame(\n  TeacherID = c(101, 102, 101, 103),\n  StudentID = c(1, 2, 3, 4),\n  TeacherExperience = c(5, 10, 5, 7)\n)\n\n# Performing the left join\ncombined_teacher_df &lt;- student_scores_df |&gt; left_join(teacher_info_df, by = \"StudentID\")\ncombined_teacher_df\n\n  StudentID Math_Score Reading_Score TeacherID TeacherExperience\n1         1         85            82       101                 5\n2         2         90            88       102                10\n3         3         78            80       101                 5\n4         4         88            85       103                 7\n\n\n\n\n\n\nStart with a wide data frame cohort_scores_df with columns StudentID, Cohort_2019_Math, Cohort_2019_Reading, Cohort_2020_Math, and Cohort_2020_Reading. Convert this data frame to a long format, separating cohort year and subject.\n\nSolution:\n\n# Creating the wide data frame\ncohort_scores_df &lt;- data.frame(\n  StudentID = c(1, 2, 3),\n  Cohort_2019_Math = c(85, 88, 90),\n  Cohort_2019_Reading = c(82, 80, 88),\n  Cohort_2020_Math = c(87, 85, 92),\n  Cohort_2020_Reading = c(85, 83, 90)\n)\n\n# Converting to long format\nlong_cohort_df &lt;- cohort_scores_df |&gt; \n  pivot_longer(\n    cols = -StudentID, \n    names_to = c(\"Cohort_Year\", \"Subject\"), names_sep = \"_\", values_to = \"Score\"\n  )\n\nWarning: Expected 2 pieces. Additional pieces discarded in 4 rows [1, 2, 3, 4].\n\nlong_cohort_df\n\n# A tibble: 12 × 4\n   StudentID Cohort_Year Subject Score\n       &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   &lt;dbl&gt;\n 1         1 Cohort      2019       85\n 2         1 Cohort      2019       82\n 3         1 Cohort      2020       87\n 4         1 Cohort      2020       85\n 5         2 Cohort      2019       88\n 6         2 Cohort      2019       80\n 7         2 Cohort      2020       85\n 8         2 Cohort      2020       83\n 9         3 Cohort      2019       90\n10         3 Cohort      2019       88\n11         3 Cohort      2020       92\n12         3 Cohort      2020       90\n\n\n\n\n\n\nCreate a data frame school_survey_df with columns SchoolID, StudentSatisfaction, and TeacherTurnover. Introduce missing values into the StudentSatisfaction column. Replace these missing values with the median of the available satisfaction scores.\n\nSolution:\n\n# Creating the data frame with missing values\nschool_survey_df &lt;- data.frame(\n  SchoolID = c(1, 2, 3, 4),\n  StudentSatisfaction = c(85, NA, 78, 90),\n  TeacherTurnover = c(10, 15, 8, 12)\n)\n\n# Replacing missing values with the median\nschool_survey_df &lt;- school_survey_df |&gt; \n  mutate(StudentSatisfaction = replace_na(StudentSatisfaction, median(StudentSatisfaction, na.rm = TRUE)))\nschool_survey_df\n\n  SchoolID StudentSatisfaction TeacherTurnover\n1        1                  85              10\n2        2                  85              15\n3        3                  78               8\n4        4                  90              12\n\n\n\n\n\n\nCreate two data frames, school_expenditure_df with columns SchoolID, Expenditure_Per_Student, and Total_Expenditure, and student_scores_df with SchoolID, Math_Score, and Reading_Score. Perform a full join on SchoolID to combine these datasets, then filter to keep only schools with available expenditure data.\n\nSolution:\n\n# Creating the data frames\nschool_expenditure_df &lt;- data.frame(\n  SchoolID = c(1, 2, 3),\n  Expenditure_Per_Student = c(10000, 8000, 9000),\n  Total_Expenditure = c(500000, 400000, 450000)\n)\n\nstudent_scores_df &lt;- data.frame(\n  SchoolID = c(1, 2, 4),\n  Math_Score = c(85, 90, 78),\n  Reading_Score = c(82, 88, 80)\n)\n\n# Performing the full join\ncombined_expenditure_df &lt;- school_expenditure_df |&gt; full_join(student_scores_df, by = \"SchoolID\")\n\n# Filtering to keep only schools with expenditure data\nfiltered_expenditure_df &lt;- combined_expenditure_df |&gt; filter(!is.na(Expenditure_Per_Student))\nfiltered_expenditure_df\n\n  SchoolID Expenditure_Per_Student Total_Expenditure Math_Score Reading_Score\n1        1                   10000            500000         85            82\n2        2                    8000            400000         90            88\n3        3                    9000            450000         NA            NA\n\n\n\n\n\n\nUsing a data frame annual_scores_df with columns Year, SchoolID, Average_Math_Score, and Average_Reading_Score, convert the data from wide to long format to analyze trends in average scores over time.\n\nSolution:\n\n# Creating the wide data frame\nannual_scores_df &lt;- data.frame(\n  Year = c(2019, 2020, 2021),\n  SchoolID = c(1, 1, 1),\n  Average_Math_Score = c(78, 80, 82),\n  Average_Reading_Score = c(75, 77, 79)\n)\n\n# Converting to long format\nlong_annual_scores_df &lt;- annual_scores_df |&gt; \n  pivot_longer(cols = starts_with(\"Average\"), names_to = \"Subject\", names_prefix = \"Average_\", values_to = \"Score\")\nlong_annual_scores_df\n\n# A tibble: 6 × 4\n   Year SchoolID Subject       Score\n  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n1  2019        1 Math_Score       78\n2  2019        1 Reading_Score    75\n3  2020        1 Math_Score       80\n4  2020        1 Reading_Score    77\n5  2021        1 Math_Score       82\n6  2021        1 Reading_Score    79",
    "crumbs": [
      "Tutorials",
      "6. Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "tutorial/02-content.html",
    "href": "tutorial/02-content.html",
    "title": "Tutorial 2: Working with Data Structures in R",
    "section": "",
    "text": "In this tutorial, we will explore three fundamental data structures in R: matrices, lists, and data frames. Understanding these structures is essential for effective data manipulation and analysis. This tutorial includes detailed explanations, code examples, and exercises with solutions to reinforce learning.\n\n\nA matrix is a two-dimensional data structure that stores elements of the same data type arranged in rows and columns. Matrices are useful for mathematical computations and organizing data in a tabular format.\n\n\nUse the matrix() function to create a matrix by specifying the data, number of rows, and number of columns.\n\n# Creating a matrix of student scores across 3 subjects\nscores &lt;- c(85, 78, 92, 90, 82, 79, 78, 91, 86)\nstudent_scores &lt;- matrix(scores, nrow = 3, ncol = 3, byrow = TRUE)\n\n# Assigning row and column names\nrownames(student_scores) &lt;- c(\"Student1\", \"Student2\", \"Student3\")\ncolnames(student_scores) &lt;- c(\"Math\", \"History\", \"Biology\")\n\nstudent_scores\n\n         Math History Biology\nStudent1   85      78      92\nStudent2   90      82      79\nStudent3   78      91      86\n\n\nExplanation: - A numeric vector scores is created containing nine score values. - The matrix() function organizes these scores into a 3x3 matrix filled by rows. - rownames() and colnames() assign descriptive labels to rows and columns for clarity.\n\n\n\nAccess specific elements, rows, or columns using square brackets [].\n\n# Accessing the score of Student2 in History\nstudent_scores[\"Student2\", \"History\"]\n\n[1] 82\n\n# Accessing all scores of Student3\nstudent_scores[\"Student3\", ]\n\n   Math History Biology \n     78      91      86 \n\n# Modifying a specific score\nstudent_scores[\"Student1\", \"Biology\"] &lt;- 95\n\nExplanation: - Specify row and column names or indices within brackets to access elements. - Assign new values to modify existing data in the matrix.\n\n\n\nPerform various operations such as calculating row and column sums or means.\n\n# Calculating total scores for each student\ntotal_scores &lt;- rowSums(student_scores)\n\n# Calculating average scores for each subject\naverage_subject_scores &lt;- colMeans(student_scores)\n\nExplanation: - rowSums() computes the sum across rows, giving total scores per student. - colMeans() computes the average across columns, providing average scores per subject.\n\n\n\n\nA list is a versatile data structure that can contain elements of different types, including numbers, strings, vectors, and even other lists.\n\n\nUse the list() function to create a list containing heterogeneous elements.\n\n# Creating a list with student information\nstudent_info &lt;- list(\n  name = \"Alice\",\n  age = 20,\n  major = \"Economics\",\n  scores = c(88, 92, 85)\n)\n\nstudent_info\n\n$name\n[1] \"Alice\"\n\n$age\n[1] 20\n\n$major\n[1] \"Economics\"\n\n$scores\n[1] 88 92 85\n\n\nExplanation: - The list student_info contains character, numeric, and vector elements, encapsulating diverse data related to a student.\n\n\n\nAccess list elements using the $ operator or double square brackets [[]].\n\n# Accessing the student's major\nstudent_info$major\n\n[1] \"Economics\"\n\n# Accessing the student's scores\nstudent_info[[\"scores\"]]\n\n[1] 88 92 85\n\n# Modifying the student's age\nstudent_info$age &lt;- 21\n\nExplanation: - $ and [[]] operators retrieve specific elements from the list. - Assign new values to update existing elements within the list.\n\n\n\nLists can contain other lists, allowing for complex data structures.\n\n# Creating a nested list with course details\ncourse_details &lt;- list(\n  course_name = \"Introduction to Economics\",\n  credits = 3,\n  instructor = list(\n    name = \"Dr. Smith\",\n    office = \"Room 101\",\n    email = \"dr.smith@university.edu\"\n  )\n)\n\ncourse_details\n\n$course_name\n[1] \"Introduction to Economics\"\n\n$credits\n[1] 3\n\n$instructor\n$instructor$name\n[1] \"Dr. Smith\"\n\n$instructor$office\n[1] \"Room 101\"\n\n$instructor$email\n[1] \"dr.smith@university.edu\"\n\n\nExplanation: - The instructor element is itself a list containing detailed information, demonstrating how lists can be nested for hierarchical data representation.\n\n\n\n\nA data frame is a table-like structure where each column can contain different data types. Data frames are widely used for storing and manipulating datasets.\n\n\nUse the data.frame() function to create a data frame by combining vectors of equal length.\n\n# Creating a data frame with multiple students' information\nstudents_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  Age = c(20, 22, 19),\n  Major = c(\"Economics\", \"History\", \"Biology\"),\n  GPA = c(3.8, 3.6, 3.9)\n)\n\nstudents_df\n\n     Name Age     Major GPA\n1   Alice  20 Economics 3.8\n2     Bob  22   History 3.6\n3 Charlie  19   Biology 3.9\n\n\nExplanation: - Each vector represents a column in the data frame, and each row represents an observation (a student in this case).\n\n\n\nAccess data frame elements using $, [], or subset().\n\n# Accessing the 'Major' column\nstudents_df$Major\n\n[1] \"Economics\" \"History\"   \"Biology\"  \n\n# Accessing the second row\nstudents_df[2, ]\n\n  Name Age   Major GPA\n2  Bob  22 History 3.6\n\n# Modifying Bob's GPA\nstudents_df[students_df$Name == \"Bob\", \"GPA\"] &lt;- 3.7\n\nExplanation: - $ retrieves entire columns. - [] with row and column indices retrieves specific elements or subsets. - Logical conditions identify and modify specific rows.\n\n\n\nAdd new columns or remove existing ones as needed.\n\n# Adding a new column for graduation year\nstudents_df$GraduationYear &lt;- c(2022, 2021, 2023)\n\n# Removing the 'Age' column\nstudents_df$Age &lt;- NULL\n\nExplanation: - Assigning a vector to a new column name adds it to the data frame. - Setting a column to NULL removes it from the data frame.\n\n\n\nUse conditions to filter rows and select subsets of data.\n\n# Filtering students with GPA above 3.7\nhigh_gpa_students &lt;- subset(students_df, GPA &gt; 3.7)\n\n# Selecting specific columns\nname_major_df &lt;- students_df[, c(\"Name\", \"Major\")]\n\nExplanation: - subset() filters rows based on specified conditions. - Column indices within [] select specific columns for a new data frame.\n\n\n\n\n\n\n\nCreate a matrix named enrollment representing the number of students enrolled in three courses over four semesters. Use the following data:\n\nSemester 1: 120, 85, 90\nSemester 2: 130, 80, 95\nSemester 3: 125, 90, 100\nSemester 4: 140, 88, 110\n\nAssign row names as “Semester1” to “Semester4” and column names as “Economics”, “History”, “Biology”.\nCalculate the average enrollment for each course across all semesters.\n\nSolution:\n\n# Step 1: Creating the enrollment matrix\nenrollment_numbers &lt;- c(120, 85, 90, 130, 80, 95, 125, 90, 100, 140, 88, 110)\nenrollment &lt;- matrix(enrollment_numbers, nrow = 4, byrow = TRUE)\n\n# Step 2: Assigning row and column names\nrownames(enrollment) &lt;- c(\"Semester1\", \"Semester2\", \"Semester3\", \"Semester4\")\ncolnames(enrollment) &lt;- c(\"Economics\", \"History\", \"Biology\")\n\n# Step 3: Calculating average enrollment for each course\naverage_enrollment &lt;- colMeans(enrollment)\naverage_enrollment\n\nEconomics   History   Biology \n   128.75     85.75     98.75 \n\n\n\n\n\n\nCreate a list named university containing:\n\nname: “ABC University”\nestablished: 1965\ndepartments: a vector of “Economics”, “History”, “Biology”\nstudent_count: a vector of enrollment numbers 5000, 3000, 4000 corresponding to the departments.\n\nAccess the departments element from the list.\nAdd a new element location with the value “Cityville”.\n\nSolution:\n\n# Step 1: Creating the university list\nuniversity &lt;- list(\n  name = \"ABC University\",\n  established = 1965,\n  departments = c(\"Economics\", \"History\", \"Biology\"),\n  student_count = c(5000, 3000, 4000)\n)\n\n# Step 2: Accessing the departments element\nuniversity_departments &lt;- university$departments\n\n# Step 3: Adding the location element\nuniversity$location &lt;- \"Cityville\"\n\n\n\n\n\nCreate a data frame named faculty_df with the following data:\n\nName: “Dr. Adams”, “Dr. Baker”, “Dr. Clark”\nDepartment: “Economics”, “History”, “Biology”\nExperienceYears: 10, 8, 12\n\nAdd a new row for “Dr. Davis” from the “Economics” department with 5 years of experience.\nChange “Dr. Baker”’s experience years to 9.\n\nSolution:\n\n# Step 1: Creating the faculty_df data frame\nfaculty_df &lt;- data.frame(\n  Name = c(\"Dr. Adams\", \"Dr. Baker\", \"Dr. Clark\"),\n  Department = c(\"Economics\", \"History\", \"Biology\"),\n  ExperienceYears = c(10, 8, 12),\n  stringsAsFactors = FALSE\n)\n\n# Step 2: Adding a new row for Dr. Davis\nnew_faculty &lt;- data.frame(\n  Name = \"Dr. Davis\",\n  Department = \"Economics\",\n  ExperienceYears = 5,\n  stringsAsFactors = FALSE\n)\nfaculty_df &lt;- rbind(faculty_df, new_faculty)\n\n# Step 3: Updating Dr. Baker's experience years\nfaculty_df[faculty_df$Name == \"Dr. Baker\", \"ExperienceYears\"] &lt;- 9\n\n\n\n\n\nUsing the faculty_df from Exercise 3, filter the data frame to include only faculty members from the “Economics” department.\nSelect only the Name and ExperienceYears columns from the filtered data.\n\nSolution:\n\n# Step 1: Filtering faculty members from Economics department\neconomics_faculty &lt;- subset(faculty_df, Department == \"Economics\")\n\n# Step 2: Selecting Name and ExperienceYears columns\neconomics_faculty_details &lt;- economics_faculty[, c(\"Name\", \"ExperienceYears\")]\n\n\n\n\n\nCreate a data frame named courses_df with:\n\nCourseID: 101, 102, 103\nCourseName: “Microeconomics”, “World History”, “Genetics”\nDepartment: “Economics”, “History”, “Biology”\n\nMerge courses_df with faculty_df based on the Department column.\nRemove any rows where there is no matching department in both data frames.\n\nSolution:\n\n# Step 1: Creating the courses_df data frame\ncourses_df &lt;- data.frame(\n  CourseID = c(101, 102, 103),\n  CourseName = c(\"Microeconomics\", \"World History\", \"Genetics\"),\n  Department = c(\"Economics\", \"History\", \"Biology\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 2: Merging courses_df with faculty_df\nmerged_df &lt;- merge(courses_df, faculty_df, by = \"Department\")\n\n# Step 3: Ensuring all rows have matching departments (already ensured by merge function)\nmerged_df\n\n  Department CourseID     CourseName      Name ExperienceYears\n1    Biology      103       Genetics Dr. Clark              12\n2  Economics      101 Microeconomics Dr. Adams              10\n3  Economics      101 Microeconomics Dr. Davis               5\n4    History      102  World History Dr. Baker               9",
    "crumbs": [
      "Tutorials",
      "2. Data Structures"
    ]
  },
  {
    "objectID": "tutorial/02-content.html#matrices",
    "href": "tutorial/02-content.html#matrices",
    "title": "Tutorial 2: Working with Data Structures in R",
    "section": "",
    "text": "A matrix is a two-dimensional data structure that stores elements of the same data type arranged in rows and columns. Matrices are useful for mathematical computations and organizing data in a tabular format.\n\n\nUse the matrix() function to create a matrix by specifying the data, number of rows, and number of columns.\n\n# Creating a matrix of student scores across 3 subjects\nscores &lt;- c(85, 78, 92, 90, 82, 79, 78, 91, 86)\nstudent_scores &lt;- matrix(scores, nrow = 3, ncol = 3, byrow = TRUE)\n\n# Assigning row and column names\nrownames(student_scores) &lt;- c(\"Student1\", \"Student2\", \"Student3\")\ncolnames(student_scores) &lt;- c(\"Math\", \"History\", \"Biology\")\n\nstudent_scores\n\n         Math History Biology\nStudent1   85      78      92\nStudent2   90      82      79\nStudent3   78      91      86\n\n\nExplanation: - A numeric vector scores is created containing nine score values. - The matrix() function organizes these scores into a 3x3 matrix filled by rows. - rownames() and colnames() assign descriptive labels to rows and columns for clarity.\n\n\n\nAccess specific elements, rows, or columns using square brackets [].\n\n# Accessing the score of Student2 in History\nstudent_scores[\"Student2\", \"History\"]\n\n[1] 82\n\n# Accessing all scores of Student3\nstudent_scores[\"Student3\", ]\n\n   Math History Biology \n     78      91      86 \n\n# Modifying a specific score\nstudent_scores[\"Student1\", \"Biology\"] &lt;- 95\n\nExplanation: - Specify row and column names or indices within brackets to access elements. - Assign new values to modify existing data in the matrix.\n\n\n\nPerform various operations such as calculating row and column sums or means.\n\n# Calculating total scores for each student\ntotal_scores &lt;- rowSums(student_scores)\n\n# Calculating average scores for each subject\naverage_subject_scores &lt;- colMeans(student_scores)\n\nExplanation: - rowSums() computes the sum across rows, giving total scores per student. - colMeans() computes the average across columns, providing average scores per subject.",
    "crumbs": [
      "Tutorials",
      "2. Data Structures"
    ]
  },
  {
    "objectID": "tutorial/02-content.html#lists",
    "href": "tutorial/02-content.html#lists",
    "title": "Tutorial 2: Working with Data Structures in R",
    "section": "",
    "text": "A list is a versatile data structure that can contain elements of different types, including numbers, strings, vectors, and even other lists.\n\n\nUse the list() function to create a list containing heterogeneous elements.\n\n# Creating a list with student information\nstudent_info &lt;- list(\n  name = \"Alice\",\n  age = 20,\n  major = \"Economics\",\n  scores = c(88, 92, 85)\n)\n\nstudent_info\n\n$name\n[1] \"Alice\"\n\n$age\n[1] 20\n\n$major\n[1] \"Economics\"\n\n$scores\n[1] 88 92 85\n\n\nExplanation: - The list student_info contains character, numeric, and vector elements, encapsulating diverse data related to a student.\n\n\n\nAccess list elements using the $ operator or double square brackets [[]].\n\n# Accessing the student's major\nstudent_info$major\n\n[1] \"Economics\"\n\n# Accessing the student's scores\nstudent_info[[\"scores\"]]\n\n[1] 88 92 85\n\n# Modifying the student's age\nstudent_info$age &lt;- 21\n\nExplanation: - $ and [[]] operators retrieve specific elements from the list. - Assign new values to update existing elements within the list.\n\n\n\nLists can contain other lists, allowing for complex data structures.\n\n# Creating a nested list with course details\ncourse_details &lt;- list(\n  course_name = \"Introduction to Economics\",\n  credits = 3,\n  instructor = list(\n    name = \"Dr. Smith\",\n    office = \"Room 101\",\n    email = \"dr.smith@university.edu\"\n  )\n)\n\ncourse_details\n\n$course_name\n[1] \"Introduction to Economics\"\n\n$credits\n[1] 3\n\n$instructor\n$instructor$name\n[1] \"Dr. Smith\"\n\n$instructor$office\n[1] \"Room 101\"\n\n$instructor$email\n[1] \"dr.smith@university.edu\"\n\n\nExplanation: - The instructor element is itself a list containing detailed information, demonstrating how lists can be nested for hierarchical data representation.",
    "crumbs": [
      "Tutorials",
      "2. Data Structures"
    ]
  },
  {
    "objectID": "tutorial/02-content.html#data-frames",
    "href": "tutorial/02-content.html#data-frames",
    "title": "Tutorial 2: Working with Data Structures in R",
    "section": "",
    "text": "A data frame is a table-like structure where each column can contain different data types. Data frames are widely used for storing and manipulating datasets.\n\n\nUse the data.frame() function to create a data frame by combining vectors of equal length.\n\n# Creating a data frame with multiple students' information\nstudents_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  Age = c(20, 22, 19),\n  Major = c(\"Economics\", \"History\", \"Biology\"),\n  GPA = c(3.8, 3.6, 3.9)\n)\n\nstudents_df\n\n     Name Age     Major GPA\n1   Alice  20 Economics 3.8\n2     Bob  22   History 3.6\n3 Charlie  19   Biology 3.9\n\n\nExplanation: - Each vector represents a column in the data frame, and each row represents an observation (a student in this case).\n\n\n\nAccess data frame elements using $, [], or subset().\n\n# Accessing the 'Major' column\nstudents_df$Major\n\n[1] \"Economics\" \"History\"   \"Biology\"  \n\n# Accessing the second row\nstudents_df[2, ]\n\n  Name Age   Major GPA\n2  Bob  22 History 3.6\n\n# Modifying Bob's GPA\nstudents_df[students_df$Name == \"Bob\", \"GPA\"] &lt;- 3.7\n\nExplanation: - $ retrieves entire columns. - [] with row and column indices retrieves specific elements or subsets. - Logical conditions identify and modify specific rows.\n\n\n\nAdd new columns or remove existing ones as needed.\n\n# Adding a new column for graduation year\nstudents_df$GraduationYear &lt;- c(2022, 2021, 2023)\n\n# Removing the 'Age' column\nstudents_df$Age &lt;- NULL\n\nExplanation: - Assigning a vector to a new column name adds it to the data frame. - Setting a column to NULL removes it from the data frame.\n\n\n\nUse conditions to filter rows and select subsets of data.\n\n# Filtering students with GPA above 3.7\nhigh_gpa_students &lt;- subset(students_df, GPA &gt; 3.7)\n\n# Selecting specific columns\nname_major_df &lt;- students_df[, c(\"Name\", \"Major\")]\n\nExplanation: - subset() filters rows based on specified conditions. - Column indices within [] select specific columns for a new data frame.",
    "crumbs": [
      "Tutorials",
      "2. Data Structures"
    ]
  },
  {
    "objectID": "tutorial/02-content.html#exercises-and-solutions",
    "href": "tutorial/02-content.html#exercises-and-solutions",
    "title": "Tutorial 2: Working with Data Structures in R",
    "section": "",
    "text": "Create a matrix named enrollment representing the number of students enrolled in three courses over four semesters. Use the following data:\n\nSemester 1: 120, 85, 90\nSemester 2: 130, 80, 95\nSemester 3: 125, 90, 100\nSemester 4: 140, 88, 110\n\nAssign row names as “Semester1” to “Semester4” and column names as “Economics”, “History”, “Biology”.\nCalculate the average enrollment for each course across all semesters.\n\nSolution:\n\n# Step 1: Creating the enrollment matrix\nenrollment_numbers &lt;- c(120, 85, 90, 130, 80, 95, 125, 90, 100, 140, 88, 110)\nenrollment &lt;- matrix(enrollment_numbers, nrow = 4, byrow = TRUE)\n\n# Step 2: Assigning row and column names\nrownames(enrollment) &lt;- c(\"Semester1\", \"Semester2\", \"Semester3\", \"Semester4\")\ncolnames(enrollment) &lt;- c(\"Economics\", \"History\", \"Biology\")\n\n# Step 3: Calculating average enrollment for each course\naverage_enrollment &lt;- colMeans(enrollment)\naverage_enrollment\n\nEconomics   History   Biology \n   128.75     85.75     98.75 \n\n\n\n\n\n\nCreate a list named university containing:\n\nname: “ABC University”\nestablished: 1965\ndepartments: a vector of “Economics”, “History”, “Biology”\nstudent_count: a vector of enrollment numbers 5000, 3000, 4000 corresponding to the departments.\n\nAccess the departments element from the list.\nAdd a new element location with the value “Cityville”.\n\nSolution:\n\n# Step 1: Creating the university list\nuniversity &lt;- list(\n  name = \"ABC University\",\n  established = 1965,\n  departments = c(\"Economics\", \"History\", \"Biology\"),\n  student_count = c(5000, 3000, 4000)\n)\n\n# Step 2: Accessing the departments element\nuniversity_departments &lt;- university$departments\n\n# Step 3: Adding the location element\nuniversity$location &lt;- \"Cityville\"\n\n\n\n\n\nCreate a data frame named faculty_df with the following data:\n\nName: “Dr. Adams”, “Dr. Baker”, “Dr. Clark”\nDepartment: “Economics”, “History”, “Biology”\nExperienceYears: 10, 8, 12\n\nAdd a new row for “Dr. Davis” from the “Economics” department with 5 years of experience.\nChange “Dr. Baker”’s experience years to 9.\n\nSolution:\n\n# Step 1: Creating the faculty_df data frame\nfaculty_df &lt;- data.frame(\n  Name = c(\"Dr. Adams\", \"Dr. Baker\", \"Dr. Clark\"),\n  Department = c(\"Economics\", \"History\", \"Biology\"),\n  ExperienceYears = c(10, 8, 12),\n  stringsAsFactors = FALSE\n)\n\n# Step 2: Adding a new row for Dr. Davis\nnew_faculty &lt;- data.frame(\n  Name = \"Dr. Davis\",\n  Department = \"Economics\",\n  ExperienceYears = 5,\n  stringsAsFactors = FALSE\n)\nfaculty_df &lt;- rbind(faculty_df, new_faculty)\n\n# Step 3: Updating Dr. Baker's experience years\nfaculty_df[faculty_df$Name == \"Dr. Baker\", \"ExperienceYears\"] &lt;- 9\n\n\n\n\n\nUsing the faculty_df from Exercise 3, filter the data frame to include only faculty members from the “Economics” department.\nSelect only the Name and ExperienceYears columns from the filtered data.\n\nSolution:\n\n# Step 1: Filtering faculty members from Economics department\neconomics_faculty &lt;- subset(faculty_df, Department == \"Economics\")\n\n# Step 2: Selecting Name and ExperienceYears columns\neconomics_faculty_details &lt;- economics_faculty[, c(\"Name\", \"ExperienceYears\")]\n\n\n\n\n\nCreate a data frame named courses_df with:\n\nCourseID: 101, 102, 103\nCourseName: “Microeconomics”, “World History”, “Genetics”\nDepartment: “Economics”, “History”, “Biology”\n\nMerge courses_df with faculty_df based on the Department column.\nRemove any rows where there is no matching department in both data frames.\n\nSolution:\n\n# Step 1: Creating the courses_df data frame\ncourses_df &lt;- data.frame(\n  CourseID = c(101, 102, 103),\n  CourseName = c(\"Microeconomics\", \"World History\", \"Genetics\"),\n  Department = c(\"Economics\", \"History\", \"Biology\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 2: Merging courses_df with faculty_df\nmerged_df &lt;- merge(courses_df, faculty_df, by = \"Department\")\n\n# Step 3: Ensuring all rows have matching departments (already ensured by merge function)\nmerged_df\n\n  Department CourseID     CourseName      Name ExperienceYears\n1    Biology      103       Genetics Dr. Clark              12\n2  Economics      101 Microeconomics Dr. Adams              10\n3  Economics      101 Microeconomics Dr. Davis               5\n4    History      102  World History Dr. Baker               9",
    "crumbs": [
      "Tutorials",
      "2. Data Structures"
    ]
  },
  {
    "objectID": "resource/style.html",
    "href": "resource/style.html",
    "title": "R style suggestions",
    "section": "",
    "text": "R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\n\nmpg |&gt; \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg |&gt; filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg |&gt; \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\nBut you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times.",
    "crumbs": [
      "Resources",
      "R style suggestions"
    ]
  },
  {
    "objectID": "resource/style.html#r-style-conventions",
    "href": "resource/style.html#r-style-conventions",
    "title": "R style suggestions",
    "section": "",
    "text": "R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\n\nmpg |&gt; \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg |&gt; filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg |&gt; \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\nBut you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times.",
    "crumbs": [
      "Resources",
      "R style suggestions"
    ]
  },
  {
    "objectID": "resource/style.html#main-style-things-to-pay-attention-to-for-this-class",
    "href": "resource/style.html#main-style-things-to-pay-attention-to-for-this-class",
    "title": "R style suggestions",
    "section": "Main style things to pay attention to for this class",
    "text": "Main style things to pay attention to for this class\n\nImportant note: I won’t ever grade you on any of this! If you submit something like filter(mpg,cty&gt;10,class==\"compact\"), I might recommend adding spaces, but it won’t affect your grade or points or anything.\n\n\nSpacing\n\nSee the “Spacing” section in the tidyverse style guide.\n\nPut spaces after commas (like in regular English):\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter(mpg , cty &gt; 10)\nfilter(mpg ,cty &gt; 10)\nfilter(mpg,cty &gt; 10)\n\nPut spaces around operators like +, -, &gt;, =, etc.:\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter(mpg, cty&gt;10)\nfilter(mpg, cty&gt; 10)\nfilter(mpg, cty &gt;10)\n\nDon’t put spaces around parentheses that are parts of functions:\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter (mpg, cty &gt; 10)\nfilter ( mpg, cty &gt; 10)\nfilter( mpg, cty &gt; 10 )\n\n\n\nLong lines\n\nSee the “Long lines” section in the tidyverse style guide.\n\nIt’s generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters. Instead of counting characters by hand (ew), in RStudio go to “Tools” &gt; “Global Options” &gt; “Code” &gt; “Display” and check the box for “Show margin”. You should now see a really thin line indicating 80 characters. Again, you can go beyond this—that’s fine. It’s just good practice to avoid going too far past it.\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n\n# Good\nfilter(mpg, cty &gt; 10, class == \"compact\")\n\n# Good\nfilter(mpg, cty &gt; 10, \n       class == \"compact\")\n\n# Good\nfilter(mpg,\n       cty &gt; 10,\n       class == \"compact\")\n\n# Bad\nfilter(mpg, cty &gt; 10, class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \"suv\", \"2seater\", \"minivan\"))\n\n# Good\nfilter(mpg, \n       cty &gt; 10, \n       class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \n                    \"suv\", \"2seater\", \"minivan\"))\n\n\n\nPipes (|&gt;) and ggplot layers (+)\nPut each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n\n# Good\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth() +\n  theme_bw()\n\n# Bad\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() + geom_smooth() +\n  theme_bw()\n\n# Super bad\nggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw()\n\n# Super bad and won't even work\nggplot(mpg, aes(x = cty, y = hwy, color = class))\n  + geom_point()\n  + geom_smooth() \n  + theme_bw()\n\nPut each step in a dplyr pipeline on separate lines, with the |&gt; at the end of the line, indented with two spaces:\n\n# Good\nmpg |&gt; \n  filter(cty &gt; 10) |&gt; \n  group_by(class) |&gt; \n  summarize(avg_hwy = mean(hwy))\n\n# Bad\nmpg |&gt; filter(cty &gt; 10) |&gt; group_by(class) |&gt; \n  summarize(avg_hwy = mean(hwy))\n\n# Super bad\nmpg |&gt; filter(cty &gt; 10) |&gt; group_by(class) |&gt; summarize(avg_hwy = mean(hwy))\n\n# Super bad and won't even work\nmpg |&gt; \n  filter(cty &gt; 10)\n  |&gt; group_by(class)\n  |&gt; summarize(avg_hwy = mean(hwy))\n\n\n\nComments\n\nSee the “Comments” section in the tidyverse style guide.\n\nComments should start with a comment symbol and a single space: #\n\n# Good\n\n#Bad\n\n    #Bad\n\nIf the comment is really short (and won’t cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\n\nmpg |&gt; \n  filter(cty &gt; 10) |&gt;  # Only rows where cty is 10 +\n  group_by(class) |&gt;  # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\n\nYou can add extra spaces to get inline comments to align, if you want:\n\nmpg |&gt; \n  filter(cty &gt; 10) |&gt;            # Only rows where cty is 10 +\n  group_by(class) |&gt;             # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\n\nIf the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to “Code” &gt; “Reflow comment”\n\n# Good\n# Happy families are all alike; every unhappy family is unhappy in its own way.\n# Everything was in confusion in the Oblonskys’ house. The wife had discovered\n# that the husband was carrying on an intrigue with a French girl, who had been\n# a governess in their family, and she had announced to her husband that she\n# could not go on living in the same house with him. This position of affairs\n# had now lasted three days, and not only the husband and wife themselves, but\n# all the members of their family and household, were painfully conscious of it.\n\n# Bad\n# Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it.\n\nThough, if you’re dealing with comments that are that long, consider putting the text in Quarto instead and having it be actual prose.",
    "crumbs": [
      "Resources",
      "R style suggestions"
    ]
  },
  {
    "objectID": "2024/weeks/week02/lab.html",
    "href": "2024/weeks/week02/lab.html",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "",
    "text": "In this lab session, you’ll work with a dataset containing information about PISA data. The data comes from the learningtower package. Throughout the lab, you will use the following R functions to achieve the final visualization: filter(), group_by(), summarise(), pivot_longer(), mutate(), ggplot(), aes(), geom_line(), geom_point(), facet_wrap(), scale_y_continuous(), labs(), and theme_minimal().\n\n\nThe dataset contains the following variables:\n\nyear: Year of the PISA data. Factor.\ncountry: Country 3-character code. Note that some regions/territories are coded as country for ease of input. Factor.\nschool_id: The school identification number, unique for each country and year combination. Factor.\nstudent_id: The student identification number, unique for each school, country, and year combination. Factor.\nmother_educ: Highest level of mother’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\nfather_educ: Highest level of father’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\ngender: Gender of the student. Only “male” and “female” are recorded. Factor. Note that we call this variable gender and not sex as this term was used in the OECD PISA database.\ncomputer: Possession of a computer. Only “yes” and “no” are recorded. Factor.\ninternet: Access to the internet. Only “yes” and “no” are recorded. Factor.\nmath: Simulated score in mathematics. Numeric.\nread: Simulated score in reading. Numeric.\nscience: Simulated score in science. Numeric.\nstu_wgt: The final survey weight score for the student. Numeric.\ndesk: Possession of a desk to study at. Only “yes” and “no” are recorded. Factor.\nroom: Possession of a room of your own. Only “yes” and “no” are recorded. Factor.\ndishwasher: Possession of a dishwasher. Only “yes” and “no” are recorded. Factor. Note that in 2015 and 2018, all entries are missing.\ntelevision: Number of televisions. “0”, “1”, “2” are coded for no, one, and two TVs in the house. “3+” codes for three or more TVs. Factor. Note that in 2003, all entries are missing.\ncomputer_n: Number of computers. “0”, “1”, “2” are coded for no, one, and two computers in the house. “3+” codes for three or more computers. Factor. Note that in 2003, all entries are missing.\ncar: Number of cars. “0”, “1”, “2” are coded for no, one, and two cars in the house. “3+” codes for three or more cars. Factor. Note that in 2003, all entries are missing.\nbook: Number of books. Factor. Note that encoding is different in the years 2000 and 2003 compared to all other years. Evaluate table(student$book, student$year) for a demo.\nwealth: Family wealth. Numeric. Note that in 2003, all entries are missing.\nescs: Index of economic, social, and cultural status. Numeric.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week02/lab.html#description-of-the-dataset",
    "href": "2024/weeks/week02/lab.html#description-of-the-dataset",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "",
    "text": "The dataset contains the following variables:\n\nyear: Year of the PISA data. Factor.\ncountry: Country 3-character code. Note that some regions/territories are coded as country for ease of input. Factor.\nschool_id: The school identification number, unique for each country and year combination. Factor.\nstudent_id: The student identification number, unique for each school, country, and year combination. Factor.\nmother_educ: Highest level of mother’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\nfather_educ: Highest level of father’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\ngender: Gender of the student. Only “male” and “female” are recorded. Factor. Note that we call this variable gender and not sex as this term was used in the OECD PISA database.\ncomputer: Possession of a computer. Only “yes” and “no” are recorded. Factor.\ninternet: Access to the internet. Only “yes” and “no” are recorded. Factor.\nmath: Simulated score in mathematics. Numeric.\nread: Simulated score in reading. Numeric.\nscience: Simulated score in science. Numeric.\nstu_wgt: The final survey weight score for the student. Numeric.\ndesk: Possession of a desk to study at. Only “yes” and “no” are recorded. Factor.\nroom: Possession of a room of your own. Only “yes” and “no” are recorded. Factor.\ndishwasher: Possession of a dishwasher. Only “yes” and “no” are recorded. Factor. Note that in 2015 and 2018, all entries are missing.\ntelevision: Number of televisions. “0”, “1”, “2” are coded for no, one, and two TVs in the house. “3+” codes for three or more TVs. Factor. Note that in 2003, all entries are missing.\ncomputer_n: Number of computers. “0”, “1”, “2” are coded for no, one, and two computers in the house. “3+” codes for three or more computers. Factor. Note that in 2003, all entries are missing.\ncar: Number of cars. “0”, “1”, “2” are coded for no, one, and two cars in the house. “3+” codes for three or more cars. Factor. Note that in 2003, all entries are missing.\nbook: Number of books. Factor. Note that encoding is different in the years 2000 and 2003 compared to all other years. Evaluate table(student$book, student$year) for a demo.\nwealth: Family wealth. Numeric. Note that in 2003, all entries are missing.\nescs: Index of economic, social, and cultural status. Numeric.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week02/lab.html#extra-exercises",
    "href": "2024/weeks/week02/lab.html#extra-exercises",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "Extra exercises",
    "text": "Extra exercises\n\nExercise 8: Customizing the Plot\nExperiment with different themes and color palettes to make the plot more visually appealing.\n\n\nExercise 9: Adding Context to the Visualization\nAdd annotations or text to the plot to highlight significant events or changes in the data.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html",
    "href": "2024/weeks/week03/hands-on.html",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "",
    "text": "In this hands-on session, you will create a Quarto document that simulates a report. You’ll learn how to structure your report, integrate R code for analysis, and generate visualizations using the tidyverse. By the end of this session, you’ll have a fully reproducible report that you can apply to your problem sets.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#objective",
    "href": "2024/weeks/week03/hands-on.html#objective",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Objective",
    "text": "Objective\nSet up a Quarto document that will serve as the foundation for your report.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#instructions",
    "href": "2024/weeks/week03/hands-on.html#instructions",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Instructions",
    "text": "Instructions\n\nCreate a New Quarto Document:\n\nOpen RStudio (or your preferred editor).\nGo to File &gt; New File &gt; Quarto Document.\nChoose “HTML” as the output format.\n\nAdd Document Metadata:\n\nGive your document a title, author, and date.\nExample:\n---\ntitle: \"TITLE\"\nauthor: \"Your Name\"\ndate: \"2024-08-25\"\nformat: html\n---\n\nSave Your Document:\n\nSave the file with a descriptive name, like ps_test.qmd.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#objective-1",
    "href": "2024/weeks/week03/hands-on.html#objective-1",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Objective",
    "text": "Objective\nIntroduce the purpose of your report and the dataset you will be analyzing.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#instructions-1",
    "href": "2024/weeks/week03/hands-on.html#instructions-1",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Instructions",
    "text": "Instructions\n\nWrite an Introduction Section:\n\nDescribe the PISA dataset and the focus of your analysis.\nExample:\n# Introduction\n\nThis report analyzes data from the PISA dataset to explore the relationship between students' socioeconomic status and their academic performance in mathematics, reading, and science. The goal is to identify trends and disparities across different countries and years.\n\nOutline the Structure of the Report:\n\nBriefly mention the different sections that will be included in the report (e.g., Data Exploration, Analysis, Visualization, Conclusion).",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#objective-2",
    "href": "2024/weeks/week03/hands-on.html#objective-2",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Objective",
    "text": "Objective\nLoad the PISA dataset and explore its structure to understand the variables and data types.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#instructions-2",
    "href": "2024/weeks/week03/hands-on.html#instructions-2",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Instructions",
    "text": "Instructions\n\nLoad the Required Libraries:\n\nAt the top of your document, add a code chunk to load the tidyverse package.\nExample:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nLoad the Dataset:\n\nUse read_csv() to load the PISA dataset.\nExample:\n\npisa_data &lt;- read_csv(\"path_to_your_data/pisa.csv\")\n\n\nExplore the Data:\n\nUse functions like head(), glimpse(), and summary() to get an overview of the dataset.\nExample:\n\nhead(pisa_data)\nglimpse(pisa_data)\nsummary(pisa_data)\n\n\nWrite a Data Description Section:\n\nDescribe the dataset, including the key variables and their types.\nExample:\n# Data Description\n\nThe PISA dataset includes information on students' performance in mathematics, reading, and science across various countries. Key variables include year, country, gender, and socioeconomic indicators such as access to resources at home.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#objective-3",
    "href": "2024/weeks/week03/hands-on.html#objective-3",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Objective",
    "text": "Objective\nFilter the dataset to focus on specific countries and summarize the data to understand trends over time.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#instructions-3",
    "href": "2024/weeks/week03/hands-on.html#instructions-3",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Instructions",
    "text": "Instructions\n\nFilter the Data:\n\nFocus on Canada, the United States, and Mexico.\nExample:\n\npisa_filtered &lt;- pisa_data %&gt;%\n  filter(country %in% c(\"CAN\", \"USA\", \"MEX\"))\n\n\nSummarize the Data:\n\nCalculate the mean scores in mathematics, reading, and science for each country by year.\nExample:\n\npisa_summary &lt;- pisa_filtered %&gt;%\n  group_by(country, year) %&gt;%\n  summarise(\n    mean_math = mean(math, na.rm = TRUE),\n    mean_read = mean(read, na.rm = TRUE),\n    mean_science = mean(science, na.rm = TRUE)\n  )\npisa_summary\n\n\nWrite a Summary Section:\n\nDescribe the summary statistics and what they reveal about the data.\nExample:\n# Data Summary\n\nThe summary statistics show that over the years, the average scores in mathematics, reading, and science have varied significantly across the three countries. Notably, there are consistent trends in the relative performance of each country in these subjects.\nExercise 5: Data Visualization",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#objective-4",
    "href": "2024/weeks/week03/hands-on.html#objective-4",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Objective",
    "text": "Objective\nCreate visualizations to explore the trends in PISA scores across the selected countries.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#instructions-4",
    "href": "2024/weeks/week03/hands-on.html#instructions-4",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Instructions",
    "text": "Instructions\n\nCreate a Line Plot for Math Scores:\n\nUse ggplot2 to visualize the average math scores over time for each country.\nExample:\n\nggplot(pisa_summary, aes(x = year, y = mean_math, color = country)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Average PISA Math Scores Over Time\",\n    x = \"Year\",\n    y = \"Average Math Score\"\n  ) +\n  theme_minimal()\n\n\nCreate Faceted Plots:\n\nCreate faceted plots for math, reading, and science scores.\nExample:\n\npisa_long &lt;- pisa_summary %&gt;%\n  pivot_longer(cols = starts_with(\"mean_\"), names_to = \"subject\", values_to = \"score\")\n\nggplot(pisa_long, aes(x = year, y = score, color = country)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ subject) +\n  labs(\n    title = \"Average PISA Scores Over Time by Subject\",\n    x = \"Year\",\n    y = \"Average Score\"\n  ) +\n  theme_minimal()\n\n\nWrite a Visualization Section:\n\nInclude the plots and describe the trends they reveal.\nExample:\n# Data Visualization\n\nThe plots below illustrate the trends in PISA scores over time for Canada, the United States, and Mexico. Each plot is faceted by subject (mathematics, reading, and science) to allow for a clear comparison of trends across different areas of academic performance.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#objective-5",
    "href": "2024/weeks/week03/hands-on.html#objective-5",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Objective",
    "text": "Objective\nSummarize your findings and discuss any patterns or trends observed in the data.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#instructions-5",
    "href": "2024/weeks/week03/hands-on.html#instructions-5",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Instructions",
    "text": "Instructions\n\nWrite a Conclusion Section:\n\nDiscuss the key insights gained from your analysis and visualizations.\nExample:\n# Conclusion\n\nThis analysis of the PISA dataset reveals several important trends. For instance, Canada's performance in mathematics has consistently been strong relative to the United States and Mexico. The visualizations also highlight how socioeconomic factors may influence academic performance, as seen in the varying trends across different countries.\n\nSuggest Further Analysis:\n\nMention any additional questions or analyses that could be explored in future work.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#objective-6",
    "href": "2024/weeks/week03/hands-on.html#objective-6",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Objective",
    "text": "Objective\nRender your Quarto document to HTML and share your results.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#instructions-6",
    "href": "2024/weeks/week03/hands-on.html#instructions-6",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Instructions",
    "text": "Instructions\n\nRender the Document:\n\nClick the “Render” button in RStudio to generate the HTML output.\n\nReview the Report:\n\nCheck the output for any errors or formatting issues.\n\nShare Your Report:\n\nSave the rendered HTML file and share it with your peers or instructor.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#what-youve-learned",
    "href": "2024/weeks/week03/hands-on.html#what-youve-learned",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "What You’ve Learned",
    "text": "What You’ve Learned\n\nHow to set up a Quarto document and structure it like a report.\nHow to integrate R code and perform data analysis using the tidyverse.\nHow to create and interpret visualizations.\nHow to produce a reproducible report that can be shared with others.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week03/hands-on.html#next-steps",
    "href": "2024/weeks/week03/hands-on.html#next-steps",
    "title": "Hands-On Session: Creating a Quarto Report",
    "section": "Next Steps",
    "text": "Next Steps\n\nPractice: Apply these skills to your problem sets and other projects.\nExplore More: Look into advanced Quarto features, such as creating PDFs, Word documents, or interactive websites.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "tutorial/07-content.html",
    "href": "tutorial/07-content.html",
    "title": "Tutorial 7: Applied Examples in Economics of Education",
    "section": "",
    "text": "Note\n\n\n\nUnfortunately, I haven’t been able to finish this tutorial.",
    "crumbs": [
      "Tutorials",
      "7. Applied Examples in Economics of Education"
    ]
  },
  {
    "objectID": "tutorial/07-content.html#regression-analysis-in-education-research",
    "href": "tutorial/07-content.html#regression-analysis-in-education-research",
    "title": "Tutorial 7: Applied Examples in Economics of Education",
    "section": "7.1 Regression Analysis in Education Research",
    "text": "7.1 Regression Analysis in Education Research\nRegression analysis is a powerful statistical tool used to examine the relationships between variables. In the context of education economics, it can be used to explore factors affecting student performance, school funding, and other key outcomes.\n\n7.1.1 Simple Linear Regression: Analyzing the Impact of Study Hours on Test Scores\nA simple linear regression can be used to assess the relationship between a student’s study hours and their test scores.\n\n# Example data frame\nstudy_data_df &lt;- data.frame(\n  StudentID = c(1, 2, 3, 4, 5),\n  Study_Hours = c(10, 12, 8, 15, 9),\n  Test_Score = c(85, 88, 78, 92, 80)\n)\n\n# Performing simple linear regression\nstudy_regression &lt;- lm(Test_Score ~ Study_Hours, data = study_data_df)\n\n# Summary of the regression model\nsummary(study_regression)\n\n\nCall:\nlm(formula = Test_Score ~ Study_Hours, data = study_data_df)\n\nResiduals:\n 1  2  3  4  5 \n 2  1 -1 -1 -1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  63.0000     3.2607  19.321 0.000303 ***\nStudy_Hours   2.0000     0.2942   6.797 0.006511 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.633 on 3 degrees of freedom\nMultiple R-squared:  0.939, Adjusted R-squared:  0.9187 \nF-statistic:  46.2 on 1 and 3 DF,  p-value: 0.006511\n\n\nExplanation:\n\nlm() fits a linear regression model to the data, with Test_Score as the dependent variable and Study_Hours as the independent variable.\nsummary() provides detailed statistics about the regression model, including coefficients, R-squared, and p-values.",
    "crumbs": [
      "Tutorials",
      "7. Applied Examples in Economics of Education"
    ]
  },
  {
    "objectID": "resource/markdown.html",
    "href": "resource/markdown.html",
    "title": "Using Markdown",
    "section": "",
    "text": "Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Markdown"
    ]
  },
  {
    "objectID": "resource/markdown.html#basic-markdown-formatting",
    "href": "resource/markdown.html#basic-markdown-formatting",
    "title": "Using Markdown",
    "section": "Basic Markdown formatting",
    "text": "Basic Markdown formatting\n\n\n\n\n\n\n\nType…\n…to get\n\n\n\n\nSome text in a paragraph.\n\nMore text in the next paragraph. Always\nuse empty lines between paragraphs.\nSome text in a paragraph.\nMore text in the next paragraph. Always use empty lines between paragraphs.\n\n\n*Italic* or _Italic_\nItalic\n\n\n**Bold** or __Bold__\nBold\n\n\n# Heading 1\nHeading 1\n\n\n## Heading 2\nHeading 2\n\n\n### Heading 3\nHeading 3\n\n\n(Go up to heading level 6 with ######)\n\n\n\n[Link text](https://www.example.com)\nLink text\n\n\n![Image caption](path/to/image.png)\n\n\n\nImage caption\n\n\n\n\n`Inline code` with backticks\nInline code with backticks\n\n\nBlock of code with triple backticks:\n\n\n\n```\nBlock of code in between\ntriple backticks\n```\nBlock of code in between\ntriple backticks\n\n\nOptionally specify a language:\n\n\n\n``` r\nx &lt;- c(1, 3, 5, 7)\nplot(x)\n```\nx &lt;- c(1, 3, 5, 7)\nplot(x)\n\n\n&gt; Blockquote\n\nBlockquote\n\n\n\n- Things in\n- an unordered\n- list\n\nThings in\nan unordered\nlist\n\n\n\n1. Things in\n1. an ordered\n2. list\n3. Notice that the\n8. numbers don't\n18. matter\n\nThings in\nan ordered\nlist\nNotice that the\nnumbers don’t\nmatter\n\n\n\nHorizontal line\n---\nHorizontal line",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Markdown"
    ]
  },
  {
    "objectID": "resource/markdown.html#math",
    "href": "resource/markdown.html#math",
    "title": "Using Markdown",
    "section": "Math",
    "text": "Math\n\nBasic math commands\nMarkdown uses LaTeX to create fancy mathematical equations. There are like a billion little options and features available for math equations—you can find helpful examples of the the most common basic commands here. In this class, these will be the most common things you’ll use:\n\n\n\n\n\n  \n    \n    \n    \n  \n  \n    \n      Description\n      Command\n      Output\n    \n  \n  \n    \n      Letters\n    \n    Roman letters\n\na b c d e f\n\n\\(a\\ b\\ c\\ d\\ e\\ f\\)\n\n    Greek letters (see this for all possible letters)\n\n\\alpha \\beta \\Gamma \\gamma \\Delta \\delta \\epsilon\n\n\\(\\alpha\\ \\beta\\ \\Gamma\\ \\gamma\\ \\Delta\\ \\delta\\ \\epsilon\\)\n\n    Letters will automatically be italicized and treated as math variables;\nif you want actual text in the math, use \\text{}\n\nEw: Treatment = \\beta\nGood: \\text{Treatment} = \\beta\n\nEw: \\(Treatment = \\beta\\)\nGood: \\(\\text{Treatment} = \\beta\\)\n\n    Extra spaces will automatically be removed; if you want a space, use \\ \n\nNo space: x y\nSpace: x\\ y\n\nNo space: \\(x y\\)\nSpace: \\(x\\ y\\)\n\n    \n      Superscripts and subscripts\n    \n    Use ^ to make one character superscripted.\n\nx^2\n\n\\(x^2\\)\n\n    Wrap the superscripted part in {} if there’s more than one character\n\nx^{2+y}\n\n\\(x^{2+y}\\)\n\n    Use _ to make one character subscripted\n\n\\beta_1\n\n\\(\\beta_1\\)\n\n    Wrap the subscripted part in {} if there’s more than one character\n\n\\beta_{i, t}\n\n\\(\\beta_{i, t}\\)\n\n    Use superscripts and subscripts simultaneously\n\n\\beta_1^{\\text{Treatment}}\n\n\\(\\beta_1^{\\text{Treatment}}\\)\n\n    You can even nest them\n\nx^{2^{2^2}}\n\n\\(x^{2^{2^2}}\\)\n\n    \n      Math operations\n    \n    Addition\n\n2 + 5 = 7\n\n\\(2 + 5 = 7\\)\n\n    Subtraction\n\n2 - 5 = -3\n\n\\(2 - 5 = -3\\)\n\n    Multiplication\n\nx \\times y\nx \\cdot y\n\n\\(x \\times y\\)\n\\(x \\cdot y\\)\n\n    Division\n\n8 \\div 2\n\n\\(8 \\div 2\\)\n\n    Fractions\n\n\\frac{8}{2}\n\n\\(\\frac{8}{2}\\)\n\n    Square roots; use [3] for other roots\n\n\\sqrt{81} = 9\n\\sqrt[3]{27} = 3\n\n\\(\\sqrt{81} = 9\\)\n\\(\\sqrt[3]{27} = 3\\)\n\n    Summation; use sub/superscripts for extra details\n\n\\sum x\n\\sum_{n=1}^{\\infty} \\frac{1}{n}\n\n\\(\\sum x\\)\n\\(\\sum_{n=1}^{\\infty} \\frac{1}{n}\\)\n\n    Products; use sub/superscripts for extra details\n\n\\prod x\n\\prod_{n=1}^{5} n^2\n\n\\(\\prod x\\)\n\\(\\prod_{n=1}^{5} n^2\\)\n\n    Integrals; use sub/superscripts for extra details\n\n\\int x^2 \\ dx\n\\int_{1}^{100} x^2 \\ dx\n\n\\(\\int x^2 \\ dx\\)\n\\(\\int_{1}^{100} x^2 \\ dx\\)\n\n    \n      Extra symbols\n    \n    Add a bar for things like averages\n\n\\bar{x}\n\n\\(\\bar{x}\\)\n\n    Use an overline for longer things\n\nEw: \\bar{abcdef}\nGood: \\overline{abcdef}\n\nEw: \\(\\bar{abcdef}\\)\nGood: \\(\\overline{abcdef}\\)\n\n    Add a hat for things like estimates\n\n\\hat{y}\n\n\\(\\hat{y}\\)\n\n    Use a wide hat for longer things\n\nEw: \\hat{abcdef}\nGood: \\widehat{abcdef}\n\nEw: \\(\\hat{abcdef}\\)\nGood: \\(\\widehat{abcdef}\\)\n\n    Use arrows for DAG-like things\n\nZ \\rightarrow Y \\leftarrow X\n\n\\(Z \\rightarrow Y \\leftarrow X\\)\n\n    \n      Bonus fun\n    \n    Use colors!; see here for more details and here for a list of color names\n\n{\\color{red} y} = {\\color{blue} \\beta_1 x_1}\n\n\\({\\color{red} y} = {\\color{blue} \\beta_1 x_1}\\)\n\n  \n  \n  \n\n\n\n\n\n\nUsing math inline\nYou can use math in two different ways: inline or in a display block. To use math inline, wrap it in single dollar signs, like $y = mx + b$:\n\n\n\n\n\n\nInline math\n\n\n\nType…\nBased on the DAG, the regression model for estimating the effect of education on wages\nis $\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon$, or $\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon$.\n…to get…\n\nBased on the DAG, the regression model for estimating the effect of education on wages is \\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon\\), or \\(\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon\\)\n\n\n\n\n\nUsing math in a block\nTo put an equation on its own line in a display block, wrap it in double dollar signs, like this:\n\n\n\n\n\n\nBlock math\n\n\n\nType…\nThe quadratic equation was an important part of high school math:\n\n$$\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n$$\n\nBut now we just use computers to solve for $x$.\n…to get…\n\nThe quadratic equation was an important part of high school math:\n\\[\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n\\]\nBut now we just use computers to solve for \\(x\\).\n\n\n\n\n\nDollar signs and math\nBecause dollar signs are used to indicate math equations, you can’t just use dollar signs like normal if you’re writing about actual dollars. For instance, if you write This book costs $5.75 and this other costs $40, Markdown will treat everything that comes between the dollar signs as math, like so: “This book costs \\(5.75 and this other costs \\)40”.\nTo get around that, put a backslash (\\) in front of the dollar signs, so that This book costs \\$5.75 and this other costs \\$40 becomes “This book costs $5.75 and this other costs $40”.",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Markdown"
    ]
  },
  {
    "objectID": "resource/markdown.html#tables",
    "href": "resource/markdown.html#tables",
    "title": "Using Markdown",
    "section": "Tables",
    "text": "Tables\nThere are a few different ways to hand-create tables in Markdown—I say “hand-create” because it’s normally way easier to use R to generate these things with packages like {gt} or {knitr} or {kableExtra}. The two most common are simple tables and pipe tables. You should look at the full documentation here.\n\n\n\n\n\n\nSimple tables\n\n\n\nFor simple tables, type…\n  Right     Left     Center     Default\n-------     ------ ----------   -------\n     12     12        12            12\n    123     123       123          123\n      1     1          1             1\n\nTable: Caption goes here\n…to get…\n\nCaption goes here\n\n\nRight\nLeft\nCenter\nDefault\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\n\n\nPipe tables\n\n\n\nFor pipe tables, type…\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\nTable: Caption goes here\n…to get…\n\nCaption goes here\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Markdown"
    ]
  },
  {
    "objectID": "resource/markdown.html#footnotes",
    "href": "resource/markdown.html#footnotes",
    "title": "Using Markdown",
    "section": "Footnotes",
    "text": "Footnotes\nThere are two different ways to add footnotes (see here for complete documentation): regular and inline.\nRegular notes need (1) an identifier and (2) the actual note. The identifier can be whatever you want. Some people like to use numbers like [^1], but if you ever rearrange paragraphs or add notes before #1, the numbering will be wrong (in your Markdown file, not in the output; everything will be correct in the output). Because of that, I prefer to use some sort of text label:\n\n\n\n\n\n\nFootnotes\n\n\n\nType…\nHere is a footnote reference[^1] and here is another [^note-on-dags].\n\n[^1]: This is a note.\n\n[^note-on-dags]: DAGs are neat. \n\nAnd here's more of the document.\n…to get…\n\nHere is a footnote reference1 and here is another.2\nAnd here’s more of the document.\n\n\n\n\n\nThis is a note.↩︎\n\n\n\n\nDAGs are neat.↩︎\n\n\n\n\n\n\n\nYou can also use inline footnotes with ^[Text of the note goes here], which are often easier because you don’t need to worry about identifiers:\n\n\n\n\n\n\nInline footnotes\n\n\n\nType…\nCausal inference is neat.^[But it can be hard too!]\n…to get…\n\nCausal inference is neat.1\n\n\n\n\n\nBut it can be hard too!↩︎",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Markdown"
    ]
  },
  {
    "objectID": "resource/markdown.html#front-matter",
    "href": "resource/markdown.html#front-matter",
    "title": "Using Markdown",
    "section": "Front matter",
    "text": "Front matter\nYou can include a special section at the top of a Markdown document that contains metadata (or data about your document) like the title, date, author, etc. This section uses a special simple syntax named YAML (or “YAML Ain’t Markup Language”) that follows this basic outline: setting: value for setting. Here’s an example YAML metadata section. Note that it must start and end with three dashes (---).\n---\ntitle: Title of your document\ndate: \"June 4, 2024\"\nauthor: \"Your name\"\n---\nYou can put the values inside quotes (like the date and name in the example above), or you can leave them outside of quotes (like the title in the example above). I typically use quotes just to be safe—if the value you’re using has a colon (:) in it, it’ll confuse Markdown since it’ll be something like title: My cool title: a subtitle, which has two colons. It’s better to do this:\n---\ntitle: \"My cool title: a subtitle\"\n---\nIf you want to use quotes inside one of the values (e.g. your document is An evaluation of \"scare quotes\"), you can use single quotes instead:\n---\ntitle: 'An evaluation of \"scare quotes\"'\n---",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Markdown"
    ]
  },
  {
    "objectID": "resource/markdown.html#citations",
    "href": "resource/markdown.html#citations",
    "title": "Using Markdown",
    "section": "Citations",
    "text": "Citations\nOne of the most powerful features of Markdown + pandoc is the ability to automatically cite things and generate bibliographies. to use citations, you need to create a BibTeX file (ends in .bib) that contains a database of the things you want to cite. You can do this with bibliography managers designed to work with BibTeX directly (like BibDesk on macOS), or you can use Zotero (macOS and Windows) to export a .bib file. You can download an example .bib file of all the readings from this class here.\nComplete details for using citations can be found here. In brief, you need to do three things:\n\nAdd a bibliography: entry to the YAML metadata:\n---\ntitle: Title of your document\ndate: \"June 4, 2024\"\nauthor: \"Your name\"\nbibliography: name_of_file.bib\n---\nChoose a citation style based on a CSL file. The default is Chicago author-date, but you can choose from 2,000+ at this repository. Download the CSL file, put it in your project folder, and add an entry to the YAML metadata (or provide a URL to the online version):\n---\ntitle: Title of your document\ndate: \"June 4, 2024\"\nauthor: \"Your name\"\nbibliography: name_of_file.bib\ncsl: \"https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\"\n---\nSome of the most common CSLs are:\n\nChicago author-date\nChicago note-bibliography\nChicago full note-bibliography (no shortened notes or ibids)\nAPA 7th edition\nMLA 8th edition\n\nCite things in your document. Check the documentation for full details of how to do this. Essentially, you use @citationkey inside square brackets ([]):\n\n\n\n\n\n\n\nType…\n…to get…\n\n\n\n\nCausal inference is neat [@Rohrer:2018;\n@AngristPischke:2015].\nCausal inference is neat (Rohrer 2018; Angrist and Pischke 2015).\n\n\nCausal inference is neat [see @Rohrer:2018, p. 34;\nalso @AngristPischke:2015, chapter 1].\nCausal inference is neat (see Rohrer 2018, 34; also Angrist and Pischke 2015, chap. 1).\n\n\nAngrist and Pischke say causal inference is neat\n[-@AngristPischke:2015; see also @Rohrer:2018].\nAngrist and Pischke say causal inference is neat (2015; see also Rohrer 2018).\n\n\n@AngristPischke:2015 [chapter 1] say causal\ninference is neat, and @Rohrer:2018 agrees.\nAngrist and Pischke (2015, chap. 1) say causal inference is neat, and Rohrer (2018) agrees.\n\n\n\nAfter compiling, you should have a perfectly formatted bibliography added to the end of your document too:\n\nAngrist, Joshua D., and Jörn-Steffen Pischke. 2015. Mastering ’Metrics: The Path from Cause to Effect. Princeton, NJ: Princeton University Press.\nRohrer, Julia M. 2018. “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Markdown"
    ]
  },
  {
    "objectID": "resource/markdown.html#other-references",
    "href": "resource/markdown.html#other-references",
    "title": "Using Markdown",
    "section": "Other references",
    "text": "Other references\nThese websites have additional details and examples and practice tools:\n\nCommonMark’s Markdown tutorial: A quick interactive Markdown tutorial.\nMarkdown tutorial: Another interactive tutorial to practice using Markdown.\nMarkdown cheatsheet: Useful one-page reminder of Markdown syntax.\nThe Plain Person’s Guide to Plain Text Social Science: A comprehensive explanation and tutorial about why you should write data-based reports in Markdown.",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Markdown"
    ]
  },
  {
    "objectID": "2024/weeks/week03/page.html",
    "href": "2024/weeks/week03/page.html",
    "title": "🗓️ Week 03 - Reproducibility in Research",
    "section": "",
    "text": "This week, we focus on the importance of reproducibility in research, particularly in the social sciences. We’ll discuss the challenges posed by the replication crisis and how adopting reproducible practices can help mitigate these issues. You’ll learn how tools like Quarto can be used to create reproducible reports, ensuring that your research is transparent, credible, and easy for others to replicate.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03"
    ]
  },
  {
    "objectID": "2024/weeks/week03/page.html#overview",
    "href": "2024/weeks/week03/page.html#overview",
    "title": "🗓️ Week 03 - Reproducibility in Research",
    "section": "",
    "text": "This week, we focus on the importance of reproducibility in research, particularly in the social sciences. We’ll discuss the challenges posed by the replication crisis and how adopting reproducible practices can help mitigate these issues. You’ll learn how tools like Quarto can be used to create reproducible reports, ensuring that your research is transparent, credible, and easy for others to replicate.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03"
    ]
  },
  {
    "objectID": "2024/weeks/week03/page.html#guiding-questions",
    "href": "2024/weeks/week03/page.html#guiding-questions",
    "title": "🗓️ Week 03 - Reproducibility in Research",
    "section": "Guiding Questions",
    "text": "Guiding Questions\n\n\n\n\n\n\nThese are optional!\n\n\n\nYou don’t need to answer all of these—or even any of them! They are here to help guide your thinking and reflection on the content. Feel free to explore whatever aspects you find most interesting.\n\n\n\nWhat is the replication crisis, and how does it affect the credibility of social science research?\nWhy is reproducibility essential for building trust in research?\nHow can tools like Quarto support reproducibility in your own research and problem sets?",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03"
    ]
  },
  {
    "objectID": "2024/weeks/week03/page.html#readings",
    "href": "2024/weeks/week03/page.html#readings",
    "title": "🗓️ Week 03 - Reproducibility in Research",
    "section": "Readings",
    "text": "Readings\n\nNo readings for this session.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03"
    ]
  },
  {
    "objectID": "2024/weeks/week03/page.html#lesson-slides",
    "href": "2024/weeks/week03/page.html#lesson-slides",
    "title": "🗓️ Week 03 - Reproducibility in Research",
    "section": "👨‍🏫 Lesson Slides",
    "text": "👨‍🏫 Lesson Slides\nEither click on the slide area below or click here to view it in fullscreen. Use your keypad to navigate the slides.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03"
    ]
  },
  {
    "objectID": "2024/weeks/week01/page.html",
    "href": "2024/weeks/week01/page.html",
    "title": "🗓️ Week 01 - Introduction, Context & Data Wrangling",
    "section": "",
    "text": "STOP\n\n\n\n\nIf you didn’t complete the summer assignments, you should definitely make time to do complete the following primers. The original content is coming from RStudio and was adapted by Prof. Andrew Heiss.\n\nFor the first part of this week’s lesson, you need to work through a few of Posit’s introductory primers. You’ll do these in your browser, where you can type code and see results immediately.\nYou’ll learn some of the basics of R, as well as some powerful methods for manipulating data with the {dplyr} package.\nComplete these primers. It may seem like there are a lot, but they’re short and go fairly quickly, especially as you get the hang of the syntax. Also, I have no way of seeing what you do or what you get wrong or right, and that’s totally fine! If you get stuck or want to skip some (or if it gets too easy), feel free to move on!\n\nThe Basics\n\nVisualization basics\nProgramming basics\n\nWork with Data\n\nWorking with tibbles\nIsolating data with {dplyr}\nDeriving information with {dplyr}\n\n\nThe content from these primers comes from the (free and online!) book R for Data Science by Garrett Grolemund and Hadley Wickham. I highly recommend the book as a reference and for continuing to learn and use R in the future (like running regression models and other types of statistical analysis).",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01"
    ]
  },
  {
    "objectID": "2024/weeks/week01/page.html#introduction",
    "href": "2024/weeks/week01/page.html#introduction",
    "title": "🗓️ Week 01 - Introduction, Context & Data Wrangling",
    "section": "Introduction",
    "text": "Introduction\nIn this first week, we will cover what you can expect to learn from this course and the course logistics: all you need to know about the structure of the lectures, classes, assessments, and how we will interact throughout this course.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01"
    ]
  },
  {
    "objectID": "2024/weeks/week01/page.html#lesson-slides",
    "href": "2024/weeks/week01/page.html#lesson-slides",
    "title": "🗓️ Week 01 - Introduction, Context & Data Wrangling",
    "section": "👨‍🏫 Lesson Slides",
    "text": "👨‍🏫 Lesson Slides\nEither click on the slide area below or click here to view it in fullscreen. Use your keypad to navigate the slides.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01"
    ]
  },
  {
    "objectID": "resource/install.html",
    "href": "resource/install.html",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "",
    "text": "You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.",
    "crumbs": [
      "Resources",
      "Guides",
      "Installing R, RStudio, tidyverse, and tinytex"
    ]
  },
  {
    "objectID": "resource/install.html#posit.cloud",
    "href": "resource/install.html#posit.cloud",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "Posit.cloud",
    "text": "Posit.cloud\nR is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free Posit.cloud service initially, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in Posit.cloud that will let you quickly copy templates for assignments.\nGo to https://posit.cloud/ and create an account. You’ll receive a link to join the shared class workspace separately. If you don’t get this link, let me know and I will invite you.",
    "crumbs": [
      "Resources",
      "Guides",
      "Installing R, RStudio, tidyverse, and tinytex"
    ]
  },
  {
    "objectID": "resource/install.html#rstudio-on-your-computer",
    "href": "resource/install.html#rstudio-on-your-computer",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "RStudio on your computer",
    "text": "RStudio on your computer\nPosit.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets, more complicated analysis, or fancier graphics. Over the course of the semester, you should wean yourself off of Posit.cloud and install all these things locally. This is also important if you want to customize fonts, since Posit.cloud has extremely limited support for fonts other than Helvetica.\nHere’s how you install all these things\n\nInstall R\nFirst you need to install R itself (the engine).\n\nGo to the CRAN (Collective R Archive Network) website: https://cran.r-project.org/\nClick on “Download R for XXX”, where XXX is either Mac or Windows:\n\n\nIf you use macOS, scroll down to the first .pkg file in the list of files (in this picture, it’s R-4.0.0.pkg; as of right now, the current version is 4.4.0) and download it.\n\nIf you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n\n\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nIf you use macOS, download and install XQuartz. You do not need to do this on Windows.\n\n\n\nInstall RStudio\nNext, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\n\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\nThe website should automatically detect your operating system (macOS or Windows) and show a big download button for it:\n\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n\nDouble click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n\nDouble click on RStudio to run it (check your applications folder or start menu).\n\n\nInstall tidyverse\nR packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\n\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including {ggplot2}) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\n\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\n\n\nInstall TinyTeX\nWhen you render to PDF, R uses a special scientific typesetting program named LaTeX (pronounced “lay-tek” or “lah-tex”; for goofy nerdy reasons, the x is technically the “ch” sound in “Bach”, but most people just say it as “k”—saying “layteks” is frowned on for whatever reason).\nLaTeX is neat and makes pretty documents, but it’s a huge program—the macOS version, for instance, is nearly 4 GB! To make life easier, there’s a smaller version named TinyTeX that automatically deals with differences between macOS and Windows and automatically installs any missing LaTeX packages as needed.\nHere’s how to install TinyTeX so you can create pretty PDFs:\n\nOpen the Terminal panel in RStudio (down in the bottom left corner where the Console panel is; there’s a tab named “Terminal” there)\nType this:\nquarto install tinytex",
    "crumbs": [
      "Resources",
      "Guides",
      "Installing R, RStudio, tidyverse, and tinytex"
    ]
  },
  {
    "objectID": "2024/weeks/week01/hands-on.html",
    "href": "2024/weeks/week01/hands-on.html",
    "title": "Hands-on: Data Wrangling",
    "section": "",
    "text": "Note\n\n\n\nPosit Cloud project\n\n\nWelcome to the interactive hands-on session on migration data. This session is designed to be an interactive part of our website, allowing you to engage directly with the R code and data manipulation techniques discussed. For your convenience, the same script used here is available in R format within our Posit Cloud project, which you can access here. You are also welcome to use RStudio or Positron on your local machine to follow along.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week01/hands-on.html#introduction",
    "href": "2024/weeks/week01/hands-on.html#introduction",
    "title": "Hands-on: Data Wrangling",
    "section": "",
    "text": "Note\n\n\n\nPosit Cloud project\n\n\nWelcome to the interactive hands-on session on migration data. This session is designed to be an interactive part of our website, allowing you to engage directly with the R code and data manipulation techniques discussed. For your convenience, the same script used here is available in R format within our Posit Cloud project, which you can access here. You are also welcome to use RStudio or Positron on your local machine to follow along.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week01/hands-on.html#migration-data",
    "href": "2024/weeks/week01/hands-on.html#migration-data",
    "title": "Hands-on: Data Wrangling",
    "section": "Migration Data",
    "text": "Migration Data\nThe data on immigrant and emigrant stocks used in this session is sourced from the United Nations Department of Economic and Social Affairs (UN DESA).\n\nHow does the UN define a migrant?\nAccording to the United Nations Population Division, an international migrant is someone who has been living for one year or longer in a country other than the one in which they were born. This definition includes many foreign workers and international students, as well as refugees and, in some cases, their descendants (such as Palestinians born in refugee camps outside of the Palestinian territories). Estimates of unauthorized immigrants living in various countries are also included in these totals.\nTourists, foreign-aid workers, temporary workers employed abroad for less than a year, and overseas military personnel are typically not counted as migrants.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week01/hands-on.html#loading-and-cleaning-the-data",
    "href": "2024/weeks/week01/hands-on.html#loading-and-cleaning-the-data",
    "title": "Hands-on: Data Wrangling",
    "section": "Loading and Cleaning the Data",
    "text": "Loading and Cleaning the Data\nLet’s begin by loading our data using the read.csv function:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote for Web-R Application Users\n\n\n\nIf you’re working on your local computer or in Posit Cloud, you can use the read_csv() function instead. The read.csv() function is used here due to bugs related to the Web-R application.\n\n\nWe can use the glimpse() function to check our columns (variables). Now, you realize that probably this dataset contains really nasty names. This is what we will usually called as “raw” data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe’ll use the clean_names() function from janitor to standardize column names by converting them to snake_case, which makes them easier to work with.\n\n\n\n\n\n\nThis web-r application\n\n\n\nThis web-r application already loaded the required package. See at the top of this page. Therefore, remember to load the required packages when you test yourself or use the posit cloud project.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis should be sufficient for the type of names we have.\n\nExercise 1\nPart 1:. Let’s focus on a subset of countries in Central America. We want to analyze data from Nicaragua, El Salvador, Costa Rica, Panama, Guatemala, and Belize, and only consider the years from 1990 to 2020. Test below and select any countries you would like\n\n Interactive editor Hint\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nHint: You’ll want to change something in the code that creates migration_filtered.\n\n\n\nPart 2: Summarizing the Data. Now that we have our filtered dataset, let’s summarize the data to calculate the mean number of emigrants by country.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nWhat’s the issue with the above code?\n\n\n\nHINT: Think about what happens if there are missing values (NA) in the ‘emigrants’ column.\nThe mean() function by default includes NA values, which will return NA as the result if any NA values are present. We need to handle missing values properly.\n\n\nTry below and correct the code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nPart 3: Add the summarize function more stats: such as observations, min year, and max year.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nExercise: What could be wrong with this approach?\n\n\n\nHINT: Are all the observations being used in the calculation? What about years with missing data?\n\n\nPart 4: Identifying Missing Data\nLet’s investigate how many missing values exist for each country in the ‘emigrants’ variable. This will help us understand how missing data might affect our summary statistics.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere, we’re counting the number of missing values (n_missing) for each country, and calculating the proportion of missing data (missing_rate).\nPart 5: Re-doing the Summary with Improved Understanding\nNow, let’s improve our summary by accounting for missing values. We’ll calculate the mean only where data is available, and ensure that our count of observations reflects only those used in the mean calculation.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nPart 6: Simplifying the Process\nTo avoid handling missing data in multiple steps, we can filter out the missing values before grouping and summarizing. This ensures our calculations are straightforward and accurate. Test it in the chunk below\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nExercise 2\nIn this exercise, we will explore how to summarize multiple variables at once using the across() function. We will start with a simple example and gradually build up to more complex summaries, including calculating multiple statistics (mean, standard deviation, etc.). Finally, we’ll create a function to automate this process for any set of variables.\nPart 1: Selecting Relevant Variables\nSuppose we want to analyze multiple columns: emigrants, and international_migrants. Let’s start by selecting these variables.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nPart 2: Summarizing Multiple Variables\nWe want to calculate the mean of both emigrants and international_migrants for each country. Let’s use the across() function to do this.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nWarning\n\n\n\nWhat issue might arise with the above code? HINT: Think about how missing values (NA) are handled in the mean() function.\nExplanation: As in the previous exercise, the mean calculation will return NA if there are any missing values. We need to handle these missing values properly.\n\n\nPart 3: Handling Missing Values\nLet’s modify the code to remove the missing values before calculating the mean.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nPart 4: Calculating Multiple Statistics\nWhat if we want to calculate additional statistics, such as the standard deviation? We can use the list() function within across() to calculate both the mean and standard deviation.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nPart 5 (HARD): Creating a Function\nLet’s create a more advanced exercise. What if we want to automate this process so that we can apply it to any set of variables? We’ll create a function that takes two arguments: the dataset we want to analyze and the set of variables we want to summarize.\n\n Interactive editor Hint\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nHint: When creating the summarize_migration_data function, start by understanding that the purpose is to summarize several variables based on a grouping variable, such as a country. You’ll need to define parameters for the dataset (data), the grouping variable (group_var), and the variables you want to summarize (summary_vars).\nTo group the data by the specified variable, use group_by(). This should be done with across(all_of(group_var)) to ensure the grouping works dynamically with the variable(s) passed to the function.\nNext, you’ll summarize the data using summarize() and across(). Within across(), apply a list of functions to calculate the number of observations (n), mean, standard deviation (sd), minimum (min), and maximum (max). It’s important to handle missing values using na.rm = TRUE for the mean, standard deviation, minimum, and maximum calculations to avoid issues with missing data.\nAfter calculating the summaries, you’ll need to reshape the data for better readability. Use pivot_longer() to transform the summarized data into a long format, where each row represents a combination of a statistic and a variable. Then, use pivot_wider() to pivot the data back into a wide format, with each statistic as a column. This step helps in organizing the results in a structured manner.\nThroughout this process, pay attention to how you name the output columns in the summarize() step. The .names argument in across() should be set up to clearly label each statistic with both the function and the variable names, ensuring clarity in the final output.\nFinally, ensure that your function is flexible enough to be applied to different datasets and variables by testing it with various inputs. This will confirm that it performs as expected across different scenarios.\n\n\n\nLet’s test the function:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "tutorial/index.html",
    "href": "tutorial/index.html",
    "title": "Intro to R – Tutorials",
    "section": "",
    "text": "Welcome to the Tutorials section! This is your go-to resource for fully annotated R code, detailed explanations, and supplementary materials that will be indispensable as you work through the problem sets and final project.\n\nOverview\nThese tutorials are designed to build your skills in data analysis and visualization using R. Each tutorial builds on the previous one, guiding you from basic concepts to advanced techniques. By the end, you’ll have the tools you need to conduct your own comprehensive analysis in the field of education.\n\n\nHow to Use These Tutorials\n\nFollow the Sequence: The tutorials are structured to build your knowledge step by step. Start with the first tutorial and progress sequentially.\nLive Coding Examples: Many sections include videos where you can watch live coding examples. These will help you see the process of working with R in real time. You’ll notice that making mistakes is totally normal—everyone does it, and it’s part of the learning process!\nPractice Makes Perfect: After each tutorial, try to complete the exercises. These are designed to reinforce your understanding and help you apply what you’ve learned to real-world data.\nMy Recommendation: Start a new R Project in RStudio and create R scripts that follow each of the tutorials.\n\n\n\nTutorials Included\n\nTutorial 1: Introduction to R and Basic Data Type\nTutorial 2: Data Structures\nTutorial 3: Introduction to Tidyverse\nTutorial 4: Data Analysis\nTutorial 5: Visualization with ggplot2\nTutorial 6: Advanced Data Wrangling\nTutorial 7: Applied Economics of Education Examples",
    "crumbs": [
      "Tutorials",
      "Overview",
      "🏠 Home"
    ]
  },
  {
    "objectID": "resource/visualization.html",
    "href": "resource/visualization.html",
    "title": "Visualization",
    "section": "",
    "text": "The Stories Behind a Line\nAustralia as 100 people: You can make something like this with d3 and the potato project.\nMarrying Later, Staying Single Longer",
    "crumbs": [
      "Resources",
      "Visualization"
    ]
  },
  {
    "objectID": "resource/visualization.html#interesting-and-excellent-real-world-examples",
    "href": "resource/visualization.html#interesting-and-excellent-real-world-examples",
    "title": "Visualization",
    "section": "",
    "text": "The Stories Behind a Line\nAustralia as 100 people: You can make something like this with d3 and the potato project.\nMarrying Later, Staying Single Longer",
    "crumbs": [
      "Resources",
      "Visualization"
    ]
  },
  {
    "objectID": "resource/visualization.html#how-to-select-the-appropriate-chart-type",
    "href": "resource/visualization.html#how-to-select-the-appropriate-chart-type",
    "title": "Visualization",
    "section": "How to select the appropriate chart type",
    "text": "How to select the appropriate chart type\nMany people have created many useful tools for selecting the correct chart type for a given dataset or question. The Financial Times has an excellent diagram that shows what kind of charts are appropriate for which kinds of data you have:\n\nThe Financial Times’s “Visual Vocabulary” (PDF poster and interactive website)\n\nHere are some other fantastic resources too:\n\nThe Data Visualisation Catalogue: Descriptions, explanations, examples, and tools for creating 60 different types of visualizations.\nThe Data Viz Project: Descriptions and examples for 150 different types of visualizations. Also allows you to search by data shape and chart function (comparison, correlation, distribution, geographical, part to whole, trend over time, etc.).\nFrom Data to Viz: A decision tree for dozens of chart types with links to R and Python code.\nThe Chartmaker Directory: Examples of how to create 51 different types of visualizations in 31 different software packages, including Excel, Tableau, and R.\nR Graph Catalog: R code for 124 ggplot graphs.\nEmery’s Essentials: Descriptions and examples of 26 different chart types.",
    "crumbs": [
      "Resources",
      "Visualization"
    ]
  },
  {
    "objectID": "resource/visualization.html#general-resources",
    "href": "resource/visualization.html#general-resources",
    "title": "Visualization",
    "section": "General resources",
    "text": "General resources\n\nStorytelling with Data: Blog and site full of resources by Cole Nussbaumer Knaflic.\nAnn K. Emery’s blog: Blog and tutorials by Ann Emery.\nEvergreen Data: Helful resources by Stephanie Evergreen.\nPolicyViz: Regular podcast and site full of helpful resources by Jon Schwabisch.\nVisualising Data: Fantastic collection of visualization resources, articles, and tutorials by Andy Kirk.\nInfo We Trust: Detailed explorations of visualizations by RJ Andrews, including a beautiful visual history of the field.\nFlowingData: Blog by Nathan Yau.\nInformation is Beautiful: Blog by David McCandless.\nJunk Charts: Blog by Kaiser Fung.\nWTF Visualizations: Visualizations that make you ask “wtf?”\nThe Data Visualization Checklist: A helpful set of criteria for grading the effectiveness of a graphic.\nData Literacy Starter Kit: Compilation of resources to become data literate by Laura Calloway.\nSeeing Data: A series of research projects about perceptions and visualizations.",
    "crumbs": [
      "Resources",
      "Visualization"
    ]
  },
  {
    "objectID": "resource/visualization.html#visualization-in-excel",
    "href": "resource/visualization.html#visualization-in-excel",
    "title": "Visualization",
    "section": "Visualization in Excel",
    "text": "Visualization in Excel\n\nHow to Build Data Visualizations in Excel: Detailed tutorials for creating 14 different visualizations in Excel.\nAnn Emery’s tutorials: Fantastic series of tutorials for creating charts in Excel.",
    "crumbs": [
      "Resources",
      "Visualization"
    ]
  },
  {
    "objectID": "resource/visualization.html#visualization-in-tableau",
    "href": "resource/visualization.html#visualization-in-tableau",
    "title": "Visualization",
    "section": "Visualization in Tableau",
    "text": "Visualization in Tableau\nBecause it is focused entirely on visualization (and because it’s a well-supported commercial product), Tableau has a phenomenal library of tutorials and training videos. There’s a helpful collections of videos here, as well.",
    "crumbs": [
      "Resources",
      "Visualization"
    ]
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Helpful Resources",
    "section": "",
    "text": "Here are some resources and guides on graphic design, data visualization, R programming, and related topics. Most of these resources are coming from Prof. Andrew Heiss’ website.",
    "crumbs": [
      "Resources",
      "Helpful Resources"
    ]
  },
  {
    "objectID": "2025/weeks/week01/slides.html#your-lecturer",
    "href": "2025/weeks/week01/slides.html#your-lecturer",
    "title": "🗓️ Week 01 Introduction",
    "section": "Your lecturer",
    "text": "Your lecturer\n\n\n\n\n\nProf. Octopian Professor of Octopus Issues Head of the Python vs R Debate Society\n\n\n\n\nPhD in Octopi Engineering\nBackground: Engineering of Deep Ocean constructions\nFormer Lead Data Scientist\n\ndeep ocean  engineering  octopus"
  },
  {
    "objectID": "2025/weeks/week01/slides.html#teaching-assistants",
    "href": "2025/weeks/week01/slides.html#teaching-assistants",
    "title": "🗓️ Week 01 Introduction",
    "section": "Teaching Assistants",
    "text": "Teaching Assistants\n\n\n\n\n\nOctopnuian Arveda  PhD Candidate at OctopusLab, OUN  MSc in Octopus Transportation 📧 \n\n\n\n\n\n\nOctopnuian Arveda  PhD Candidate at OctopusLab, UOS  MSc in Octopus Transportation 📧 \n\n\n\n\n\n\n\nMY_COURSE_CODE – MY_COURSE_NAME"
  },
  {
    "objectID": "2025/index.html",
    "href": "2025/index.html",
    "title": "MY_COURSE_CODE - MY_COURSE_NAME",
    "section": "",
    "text": "🧑🏻‍🏫 Our Team\n\nCourse ConvenorTeaching Staff\n\n\n\nMY_NAME  MY_JOB_TITLE  MY_INSTITUTION 📧 MY_EMAIL ( at )\nOffice Hours:\n\nWhen:\nWhere:\nHow to book:\n\n\n\n\nTA_NAME  PhD Candidate at PLACE  📧 EMAIL ( at )\n\nTA_NAME  PhD Candidate at PLACE  📧 EMAIL ( at )\n\n\n\n\n\n📍 Lecture\nFridays 2pm-4pm at PLACE\n\n\n💻 Class Groups\n\nGroup 01\n\n📆 Mondays\n⌚ 09:00 - 10:30\n📍\n🧑‍🏫 TA_NAME\n\n\n\nGroup 02\n\n📆 Mondays\n⌚ 10:30 - 12:00\n📍\n🧑‍🏫 TA_NAME\n\n\n\nGroup 03\n\n📆 Fridays\n⌚ 16:00 - 17:30\n📍\n🧑‍🏫 TA_NAME"
  },
  {
    "objectID": "2024/weeks/week04/lab.html",
    "href": "2024/weeks/week04/lab.html",
    "title": "Lab 4: Statiscal Modeling",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#why-reproducibility",
    "href": "2024/weeks/week03/slides03.html#why-reproducibility",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Why Reproducibility?",
    "text": "Why Reproducibility?\nAre We in a Crisis?\n\nThe replication crisis in social sciences has highlighted significant issues in the credibility of research findings.\nMany high-profile studies have failed to replicate, raising concerns about the reliability of published results.\nThe crisis has prompted a call for greater transparency and rigor in research practices."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#the-replication-crisis",
    "href": "2024/weeks/week03/slides03.html#the-replication-crisis",
    "title": "Week 03Intro to Reproducible Research",
    "section": "The Replication Crisis",
    "text": "The Replication Crisis\nWhat Went Wrong?\n\nSelective Reporting: Only significant findings get published, leading to publication bias.\nP-Hacking: Manipulating data and analyses until nonsignificant results become significant.\nLack of Transparency: Opaque methodologies that others cannot replicate or verify."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#the-importance-of-reproducibility",
    "href": "2024/weeks/week03/slides03.html#the-importance-of-reproducibility",
    "title": "Week 03Intro to Reproducible Research",
    "section": "The Importance of Reproducibility",
    "text": "The Importance of Reproducibility\nBuilding Trust in Research\n\nReproducibility ensures that research findings are not just a result of chance or specific conditions.\nIt allows others to verify results and build upon them, fostering cumulative knowledge.\nTransparent reporting of data and methods strengthens the credibility and utility of research."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#how-can-we-improve-reproducibility",
    "href": "2024/weeks/week03/slides03.html#how-can-we-improve-reproducibility",
    "title": "Week 03Intro to Reproducible Research",
    "section": "How Can We Improve Reproducibility?",
    "text": "How Can We Improve Reproducibility?\nAdopting Best Practices\n\nPre-registration: Outlining the study design and analysis plan before data collection.\nOpen Data and Code: Sharing data and analysis scripts for others to verify and use.\nReproducible Workflows: Using tools like Quarto to create dynamic documents that combine analysis and narrative."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#reproducibility-the-basics",
    "href": "2024/weeks/week03/slides03.html#reproducibility-the-basics",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Reproducibility: The Basics",
    "text": "Reproducibility: The Basics\n\n\nReproducibility refers to the ability to duplicate the results of a prior study using the same materials and procedures as the original investigator.\nThis may involve using the same computer code or reimplementing statistical procedures in a different software package.\nIn essence, reproducibility is analogous to a ‘unit test’ in software engineering, ensuring that the study’s results can be consistently obtained under the same conditions."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#replicability-expanding-the-horizon",
    "href": "2024/weeks/week03/slides03.html#replicability-expanding-the-horizon",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Replicability: Expanding the Horizon",
    "text": "Replicability: Expanding the Horizon\n\n\nReplicability involves duplicating the results of a prior study by following the same procedures but using new data.\nThis concept extends beyond mere reproduction and tests whether the findings hold true across different datasets or slightly altered conditions.\nSometimes referred to as “scientific replication,” replicability is critical for validating the robustness and generalizability of research findings."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#reproducibility-vs.-replicability",
    "href": "2024/weeks/week03/slides03.html#reproducibility-vs.-replicability",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Reproducibility vs. Replicability",
    "text": "Reproducibility vs. Replicability\n\n\n\nReproducibility:\n\nduplication with the same data and procedures;\nensuring accuracy and precision.\n\n\n\n\nReplicability:\n\ntests the findings using new data but the same methods;’\nemphasizing robustness and generalization.\n\n\n\nBoth concepts are crucial for ensuring the credibility and reliability of research, but they serve different purposes within the scientific process."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#quarto-a-tool-for-reproducible-research",
    "href": "2024/weeks/week03/slides03.html#quarto-a-tool-for-reproducible-research",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Quarto: A Tool for Reproducible Research",
    "text": "Quarto: A Tool for Reproducible Research\nWhat is Quarto?\nQuarto is an open-source scientific and technical publishing system that enables researchers to create dynamic documents, reports, presentations, and websites."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#why-quarto",
    "href": "2024/weeks/week03/slides03.html#why-quarto",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Why Quarto?",
    "text": "Why Quarto?\nThe Need for Reproducible Research\n\nQuarto ensures that your analysis and outputs (tables, figures, etc.) can be reproduced by others, enhancing the credibility of your work.\nIntegrated with R, Python, Julia, etc.: Quarto supports multiple languages, making it versatile for various research needs."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#why-quarto-1",
    "href": "2024/weeks/week03/slides03.html#why-quarto-1",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Why Quarto?",
    "text": "Why Quarto?"
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#quarto-for-literate-programming",
    "href": "2024/weeks/week03/slides03.html#quarto-for-literate-programming",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Quarto for literate programming",
    "text": "Quarto for literate programming"
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#key-features-of-quarto",
    "href": "2024/weeks/week03/slides03.html#key-features-of-quarto",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Key Features of Quarto",
    "text": "Key Features of Quarto\n\nDynamic Documents: Create documents that are automatically updated with the latest data and analysis.\nMultiple Outputs: Generate reports, presentations, blogs, and books from a single source.\nVersion Control: Integrates seamlessly with Git for version control, tracking changes, and collaboration.\nCross-Platform: Works with RStudio, VSCode, or directly from the command line."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#why-use-quarto-for-your-problem-sets",
    "href": "2024/weeks/week03/slides03.html#why-use-quarto-for-your-problem-sets",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Why Use Quarto for Your Problem Sets?",
    "text": "Why Use Quarto for Your Problem Sets?\nConsistency and Organization\n\nQuarto helps you organize your code, analysis, and narrative in a single document.\nIt ensures that your problem sets are well-documented and easily understandable."
  },
  {
    "objectID": "2024/weeks/week03/slides03.html#why-the-name-quarto1",
    "href": "2024/weeks/week03/slides03.html#why-the-name-quarto1",
    "title": "Week 03Intro to Reproducible Research",
    "section": "Why the name “Quarto”?1",
    "text": "Why the name “Quarto”?1\n\n\n\n\n\n\n\n\n\n\n\n\nWhy Quarto? From Posit “We wanted to use a name that had meaning in the history of publishing and landed on Quarto, which is the format of a book or pamphlet produced from full sheets printed with eight pages of text, four to a side, then folded twice to produce four leaves. The earliest known European printed book is a Quarto, the Sibyllenbuch, believed to have been printed by Johannes Gutenberg in 1452–53.”"
  },
  {
    "objectID": "2024/index.html",
    "href": "2024/index.html",
    "title": "API209Summer Math Camp",
    "section": "",
    "text": "📢 Important\n\n\n\n\n\n(12/03/2023)\n\n🗓️ Week 03 lecture material is now available!\n\n\n\n\n\n🧑🏻‍🏫 Our Team\n\nCourse ConvenorCourse Assistants\n\n\n\n\n\n\n\nProf. Dan Levy Harvard Kennedy School 📧 dan_levy at hks dot harvard dot edu\n\n\n\n\n\n\nTF Rony Rodriguez-Ramirez Harvard University 📧 rrodriguezramirez at g dot harvard dot edu\n\n\nOffice Hours (TF):\nHow to book:\n\n Schedule an appointment using Calendly\n\nWhere: Zoom\n\n\n\n\n\nAyush Shukla  MPA/ID Candidate 2025  📧 ayushshukla at hks dot harvard dot edu\n\nSara Wong Becerra  MPA/ID Candidate 2025  📧 EMAIL (swongbecerra at hks dot harvard dot edu)\n\nHussaini Shan-e-Abba  MPA/ID Candidate 2025  📧 hshaneabbas at hks dot harvard dot edu\n\n\n\n\n\n📍 Lessons/Hands-on Sessions/Labs\n\n Wexner 436. HKS",
    "crumbs": [
      "Math Camp 2024",
      "Overview",
      "🏠 Home"
    ]
  },
  {
    "objectID": "2024/weeks/week03/lab.html",
    "href": "2024/weeks/week03/lab.html",
    "title": "Lab 3: Your Quarto Projects",
    "section": "",
    "text": "Introduction",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 03",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week04/slides04.html#to-complete",
    "href": "2024/weeks/week04/slides04.html#to-complete",
    "title": "Week 03Intro to Reproducible Research",
    "section": "To Complete",
    "text": "To Complete"
  },
  {
    "objectID": "2025/weeks/week01/page.html",
    "href": "2025/weeks/week01/page.html",
    "title": "🗓️ Week 01 - Introduction, Context & Key Concepts",
    "section": "",
    "text": "In this first week, we will cover what you can expect to learn from this course and the course logistics: all you need to know about the structure of the lectures, classes, assessments, and how we will interact throughout this course."
  },
  {
    "objectID": "2025/weeks/week01/page.html#lecture-slides",
    "href": "2025/weeks/week01/page.html#lecture-slides",
    "title": "🗓️ Week 01 - Introduction, Context & Key Concepts",
    "section": "👨‍🏫 Lecture Slides",
    "text": "👨‍🏫 Lecture Slides\nEither click on the slide area below or click here to view it in fullscreen. Use your keypad to navigate the slides.\n\n\n\n\n🎥 Looking for lecture recordings? You can only find those on Moodle."
  },
  {
    "objectID": "2025/weeks/week01/page.html#coursework",
    "href": "2025/weeks/week01/page.html#coursework",
    "title": "🗓️ Week 01 - Introduction, Context & Key Concepts",
    "section": "✍️ Coursework",
    "text": "✍️ Coursework\n🚧 Come back after the lecture to read the coursework instructions for the week 🚧"
  },
  {
    "objectID": "2025/weeks/week01/page.html#recommended-reading",
    "href": "2025/weeks/week01/page.html#recommended-reading",
    "title": "🗓️ Week 01 - Introduction, Context & Key Concepts",
    "section": "📚 Recommended Reading",
    "text": "📚 Recommended Reading\n\nCheck the end of slides for the list of references cited in the lecture."
  },
  {
    "objectID": "2025/weeks/week01/page.html#communication",
    "href": "2025/weeks/week01/page.html#communication",
    "title": "🗓️ Week 01 - Introduction, Context & Key Concepts",
    "section": "📟 Communication",
    "text": "📟 Communication\n\nIf you feel like it, introduce yourself in the #introductions channel on Slack"
  },
  {
    "objectID": "resource/data.html",
    "href": "resource/data.html",
    "title": "Data",
    "section": "",
    "text": "There are a ton of places to find data related to public policy and administration (as well as data on pretty much any topic you want) online:\n\nData is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\nGoogle Dataset Search: Google indexes thousands of public datasets; search for them here.\nKaggle: Kaggle hosts machine learning competitions where people compete to create the fastest, most efficient, most predictive algorithms. A byproduct of these competitions is a host of fascinating datasets that are generally free and open to the public. See, for example, the European Soccer Database, the Salem Witchcraft Dataset or results from an Oreo flavors taste test.\n360Giving: Dozens of British foundations follow a standard file format for sharing grant data and have made that data available online.\nUS City Open Data Census: More than 100 US cities have committed to sharing dozens of types of data, including data about crime, budgets, campaign finance, lobbying, transit, and zoning. This site from the Sunlight Foundation and Code for America collects this data and rates cities by how well they’re doing.\nPolitical science and economics datasets: There’s a wealth of data available for political science- and economics-related topics:\n\nFrançois Briatte’s extensive curated lists: Includes data from/about intergovernmental organizations (IGOs), nongovernmental organizations (NGOs), public opinion surveys, parliaments and legislatures, wars, human rights, elections, and municipalities.\nThomas Leeper’s list of political science datasets: Good short list of useful datasets, divided by type of data (country-level data, survey data, social media data, event data, text data, etc.).\nErik Gahner’s list of political science datasets: Huge list of useful datasets, divided by topic (governance, elections, policy, political elites, etc.)",
    "crumbs": [
      "Resources",
      "Data"
    ]
  },
  {
    "objectID": "resource/r.html",
    "href": "resource/r.html",
    "title": "R",
    "section": "",
    "text": "I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”). Also, since most of your R work in this class will deal with {ggplot2}, it’s often easier to just search for that instead of the letter “r” (e.g. “ggplot scatterplot”).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful. Also check out StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nThese resources are also really really helpful:\n\nR for Data Science: A free online book for learning the basics of R and the tidyverse.\nR and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, {ggplot2}, and other R-related things.\nStat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online.\nSTA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online.\nCSE 631: Principles & Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio.",
    "crumbs": [
      "Resources",
      "R"
    ]
  },
  {
    "objectID": "resource/r.html#learning-r",
    "href": "resource/r.html#learning-r",
    "title": "R",
    "section": "",
    "text": "I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”). Also, since most of your R work in this class will deal with {ggplot2}, it’s often easier to just search for that instead of the letter “r” (e.g. “ggplot scatterplot”).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful. Also check out StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nThese resources are also really really helpful:\n\nR for Data Science: A free online book for learning the basics of R and the tidyverse.\nR and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, {ggplot2}, and other R-related things.\nStat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online.\nSTA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online.\nCSE 631: Principles & Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio.",
    "crumbs": [
      "Resources",
      "R"
    ]
  },
  {
    "objectID": "resource/r.html#r-in-the-wild",
    "href": "resource/r.html#r-in-the-wild",
    "title": "R",
    "section": "R in the wild",
    "text": "R in the wild\nA popular (and increasingly standard) way for sharing your analyses and visualizations is to post an annotated explanation of your process somewhere online. RStudio allows you to publish rendered HTML files directly to RPubs, but you can also post your output to a blog or other type of website. Reading these kinds of posts is one of the best ways to learn R, since they walk you through each step of the process and show the code and output.\nHere are some of the best examples I’ve come across:\n\nText analysis of Trump’s tweets confirms he writes only the (angrier) Android half (with a follow-up)\nBob Ross - Joy of Painting\nBechdel analysis using the tidyverse: There are also a bunch of other examples using data from FiveThirtyEight.\nSexism on the Silver Screen: Exploring film’s gender divide\nComparison of Quentin Tarantino Movies by Box Office and the Bechdel Test\nWho came to vote in Utah’s caucuses?\nHealth care indicators in Utah counties\nSong lyrics across the United States\nA decade (ish) of listening to Sigur Rós\nWhen is Tom peeping these days?: There are a also bunch of final projects from other R and data visualization classes here and here.\nMapping Fall Foliage\nGeneral (Attys) Distributions\nDisproving Approval",
    "crumbs": [
      "Resources",
      "R"
    ]
  },
  {
    "objectID": "tutorial/archive/08-content.html",
    "href": "tutorial/archive/08-content.html",
    "title": "Tutorial 8: Project Work and Integration",
    "section": "",
    "text": "In this final tutorial, we will bring together all the concepts and techniques you have learned throughout this course by working on a comprehensive project. This project will involve data wrangling, analysis, and visualization, focusing on a real-world problem in the economics of education. The project will guide you through the process of conducting a full analysis from start to finish, providing a holistic understanding of how to apply these skills in practice.\n\n\n\n\nIn this project, you will perform a comprehensive analysis of educational inequality across different regions. You will work with a dataset that includes information on student performance, school funding, socioeconomic status, and other relevant factors. The goal is to understand how these variables contribute to educational inequality and to visualize these differences across regions.\n\n\n\nFirst, we need to prepare and clean the dataset. This step involves loading the data, handling missing values, and possibly merging multiple datasets.\n\n\n# Loading the dataset\neducation_inequality_df &lt;- read.csv(\"education_inequality.csv\")\n\n# Previewing the dataset\nhead(education_inequality_df)\nExplanation: - The dataset education_inequality.csv contains data on student performance, school funding, socioeconomic status (SES), and regional information. This data will be the foundation of our analysis.\n\n\n\nIdentify and handle any missing data that may affect our analysis.\n# Summarizing missing values in the dataset\nmissing_summary &lt;- education_inequality_df |&gt; \n  summarise(across(everything(), ~sum(is.na(.))))\n\n# Handling missing values: Example replacing missing SES values with \"Unknown\"\neducation_inequality_df &lt;- education_inequality_df |&gt; \n  mutate(SES = replace_na(SES, \"Unknown\"))\nExplanation: - We summarize the missing values to understand where they occur and then replace missing values in the SES column with \"Unknown\".\n\n\n\n\nNext, we will reshape and merge the data as needed to facilitate our analysis.\n\n\nIf the data is split into multiple files or sources (e.g., student performance data and school funding data), we need to merge them.\n# Example merging datasets by SchoolID and RegionID\nschool_funding_df &lt;- read.csv(\"school_funding.csv\")\n\n# Merging with the main dataset\neducation_inequality_df &lt;- education_inequality_df |&gt; \n  left_join(school_funding_df, by = c(\"SchoolID\", \"RegionID\"))\nExplanation: - We perform a left join to merge school funding data with the main dataset, ensuring that all schools in the performance data are retained.\n\n\n\nWe might need to reshape the data from wide to long format to analyze trends or comparisons across regions.\n# Reshaping data to long format for analysis\nlong_education_df &lt;- education_inequality_df |&gt; \n  pivot_longer(cols = starts_with(\"Score\"), names_to = \"Subject\", values_to = \"Score\")\nExplanation: - pivot_longer() is used to reshape the data so that each subject’s scores are in a single column, making it easier to analyze performance across different subjects.\n\n\n\n\nBefore diving into complex analyses, it’s important to perform EDA to understand the distributions, relationships, and potential patterns in the data.\n\n\nGenerate descriptive statistics to summarize the key variables.\n# Descriptive statistics for key variables\nsummary_stats &lt;- education_inequality_df |&gt; \n  summarise(\n    Avg_Funding = mean(Funding_Per_Student, na.rm = TRUE),\n    Avg_Score = mean(Score, na.rm = TRUE),\n    Avg_SES = mean(as.numeric(SES), na.rm = TRUE)\n  )\nsummary_stats\nExplanation: - We calculate the average funding per student, average score, and average socioeconomic status (SES) across all regions.\n\n\n\nVisualize the distribution of student scores and the relationship between funding and scores across regions.\n# Histogram of student scores\nggplot(data = education_inequality_df, aes(x = Score)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\") +\n  labs(title = \"Distribution of Student Scores\", x = \"Score\", y = \"Frequency\")\n\n# Scatter plot of Funding vs. Scores by Region\nggplot(data = education_inequality_df, aes(x = Funding_Per_Student, y = Score, color = RegionID)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Funding vs. Scores by Region\", x = \"Funding Per Student\", y = \"Score\")\nExplanation: - The histogram provides insight into the distribution of student scores. - The scatter plot shows the relationship between school funding and student performance, with different colors representing different regions.\n\n\n\n\nNow, we move on to more complex analyses, such as regression analysis and comparisons across regions.\n\n\nPerform a multiple regression analysis to assess the impact of funding, SES, and region on student performance.\n# Multiple regression analysis\nregression_model &lt;- lm(Score ~ Funding_Per_Student + SES + RegionID, data = education_inequality_df)\n\n# Summary of the regression model\nsummary(regression_model)\nExplanation: - This regression model includes funding, SES, and region as predictors of student performance (score). The results help identify key factors driving educational inequality.\n\n\n\nUse faceted plots to compare the relationship between funding and scores across different regions.\n# Faceted scatter plot by Region\nggplot(data = education_inequality_df, aes(x = Funding_Per_Student, y = Score)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ RegionID) +\n  labs(title = \"Funding vs. Scores Across Regions\", x = \"Funding Per Student\", y = \"Score\")\nExplanation: - This faceted plot allows for direct comparison of the funding-performance relationship across different regions, helping to identify regions with greater inequality.\n\n\n\n\nFinally, we interpret the results of our analyses and prepare a report that communicates our findings effectively.\n\n\n\nRegression Results: Discuss which variables (e.g., funding, SES) have the most significant impact on student performance and how these effects vary by region.\nVisual Insights: Highlight key patterns observed in the visualizations, such as regions where funding has a stronger correlation with student scores.\n\n\n\n\nPrepare a summary report that includes: - Introduction: Contextualize the problem of educational inequality and outline the goals of the analysis. - Methodology: Describe the data sources, variables used, and the analytical methods applied. - Results: Present the results of the regression analysis and visualizations, interpreting their implications. - Conclusion: Discuss the broader implications of your findings for policy and practice in addressing educational inequality.\n# Example summary report outline (in Markdown)\n# \n# # Analysis of Educational Inequality Across Regions\n# \n# ## Introduction\n# Educational inequality remains a significant challenge, with disparities in funding, socioeconomic status, and other factors contributing to uneven student outcomes across regions. This analysis aims to explore the relationships between these variables and student performance, providing insights into the drivers of inequality.\n# \n# ## Methodology\n# The analysis combines data on student performance, school funding, and socioeconomic status across multiple regions. We employ data wrangling techniques to clean and prepare the data, followed by regression analysis and visualization to uncover key patterns.\n# \n# ## Results\n# - **Regression Analysis**: Funding per student and SES are significant predictors of student performance, with notable variations across regions.\n# - **Visual Analysis**: Regions with higher funding show a stronger correlation between funding and performance, highlighting areas where investment may be more impactful.\n# \n# ## Conclusion\n# The findings suggest that targeted funding increases in underperforming regions could help mitigate educational inequality. Policymakers should consider these insights when designing interventions to improve educational outcomes across the board.\n\n\n\n\nThis project has guided you through the entire process of conducting an in-depth analysis in the field of economics of education, from data preparation and analysis to interpretation and reporting. By integrating the skills you’ve learned throughout this course, you are now well-equipped to tackle complex research questions and contribute meaningful insights to the field of educational economics."
  },
  {
    "objectID": "tutorial/archive/08-content.html#final-project-analyzing-educational-inequality-across-regions",
    "href": "tutorial/archive/08-content.html#final-project-analyzing-educational-inequality-across-regions",
    "title": "Tutorial 8: Project Work and Integration",
    "section": "",
    "text": "In this project, you will perform a comprehensive analysis of educational inequality across different regions. You will work with a dataset that includes information on student performance, school funding, socioeconomic status, and other relevant factors. The goal is to understand how these variables contribute to educational inequality and to visualize these differences across regions.\n\n\n\nFirst, we need to prepare and clean the dataset. This step involves loading the data, handling missing values, and possibly merging multiple datasets.\n\n\n# Loading the dataset\neducation_inequality_df &lt;- read.csv(\"education_inequality.csv\")\n\n# Previewing the dataset\nhead(education_inequality_df)\nExplanation: - The dataset education_inequality.csv contains data on student performance, school funding, socioeconomic status (SES), and regional information. This data will be the foundation of our analysis.\n\n\n\nIdentify and handle any missing data that may affect our analysis.\n# Summarizing missing values in the dataset\nmissing_summary &lt;- education_inequality_df |&gt; \n  summarise(across(everything(), ~sum(is.na(.))))\n\n# Handling missing values: Example replacing missing SES values with \"Unknown\"\neducation_inequality_df &lt;- education_inequality_df |&gt; \n  mutate(SES = replace_na(SES, \"Unknown\"))\nExplanation: - We summarize the missing values to understand where they occur and then replace missing values in the SES column with \"Unknown\".\n\n\n\n\nNext, we will reshape and merge the data as needed to facilitate our analysis.\n\n\nIf the data is split into multiple files or sources (e.g., student performance data and school funding data), we need to merge them.\n# Example merging datasets by SchoolID and RegionID\nschool_funding_df &lt;- read.csv(\"school_funding.csv\")\n\n# Merging with the main dataset\neducation_inequality_df &lt;- education_inequality_df |&gt; \n  left_join(school_funding_df, by = c(\"SchoolID\", \"RegionID\"))\nExplanation: - We perform a left join to merge school funding data with the main dataset, ensuring that all schools in the performance data are retained.\n\n\n\nWe might need to reshape the data from wide to long format to analyze trends or comparisons across regions.\n# Reshaping data to long format for analysis\nlong_education_df &lt;- education_inequality_df |&gt; \n  pivot_longer(cols = starts_with(\"Score\"), names_to = \"Subject\", values_to = \"Score\")\nExplanation: - pivot_longer() is used to reshape the data so that each subject’s scores are in a single column, making it easier to analyze performance across different subjects.\n\n\n\n\nBefore diving into complex analyses, it’s important to perform EDA to understand the distributions, relationships, and potential patterns in the data.\n\n\nGenerate descriptive statistics to summarize the key variables.\n# Descriptive statistics for key variables\nsummary_stats &lt;- education_inequality_df |&gt; \n  summarise(\n    Avg_Funding = mean(Funding_Per_Student, na.rm = TRUE),\n    Avg_Score = mean(Score, na.rm = TRUE),\n    Avg_SES = mean(as.numeric(SES), na.rm = TRUE)\n  )\nsummary_stats\nExplanation: - We calculate the average funding per student, average score, and average socioeconomic status (SES) across all regions.\n\n\n\nVisualize the distribution of student scores and the relationship between funding and scores across regions.\n# Histogram of student scores\nggplot(data = education_inequality_df, aes(x = Score)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\") +\n  labs(title = \"Distribution of Student Scores\", x = \"Score\", y = \"Frequency\")\n\n# Scatter plot of Funding vs. Scores by Region\nggplot(data = education_inequality_df, aes(x = Funding_Per_Student, y = Score, color = RegionID)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Funding vs. Scores by Region\", x = \"Funding Per Student\", y = \"Score\")\nExplanation: - The histogram provides insight into the distribution of student scores. - The scatter plot shows the relationship between school funding and student performance, with different colors representing different regions.\n\n\n\n\nNow, we move on to more complex analyses, such as regression analysis and comparisons across regions.\n\n\nPerform a multiple regression analysis to assess the impact of funding, SES, and region on student performance.\n# Multiple regression analysis\nregression_model &lt;- lm(Score ~ Funding_Per_Student + SES + RegionID, data = education_inequality_df)\n\n# Summary of the regression model\nsummary(regression_model)\nExplanation: - This regression model includes funding, SES, and region as predictors of student performance (score). The results help identify key factors driving educational inequality.\n\n\n\nUse faceted plots to compare the relationship between funding and scores across different regions.\n# Faceted scatter plot by Region\nggplot(data = education_inequality_df, aes(x = Funding_Per_Student, y = Score)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ RegionID) +\n  labs(title = \"Funding vs. Scores Across Regions\", x = \"Funding Per Student\", y = \"Score\")\nExplanation: - This faceted plot allows for direct comparison of the funding-performance relationship across different regions, helping to identify regions with greater inequality.\n\n\n\n\nFinally, we interpret the results of our analyses and prepare a report that communicates our findings effectively.\n\n\n\nRegression Results: Discuss which variables (e.g., funding, SES) have the most significant impact on student performance and how these effects vary by region.\nVisual Insights: Highlight key patterns observed in the visualizations, such as regions where funding has a stronger correlation with student scores.\n\n\n\n\nPrepare a summary report that includes: - Introduction: Contextualize the problem of educational inequality and outline the goals of the analysis. - Methodology: Describe the data sources, variables used, and the analytical methods applied. - Results: Present the results of the regression analysis and visualizations, interpreting their implications. - Conclusion: Discuss the broader implications of your findings for policy and practice in addressing educational inequality.\n# Example summary report outline (in Markdown)\n# \n# # Analysis of Educational Inequality Across Regions\n# \n# ## Introduction\n# Educational inequality remains a significant challenge, with disparities in funding, socioeconomic status, and other factors contributing to uneven student outcomes across regions. This analysis aims to explore the relationships between these variables and student performance, providing insights into the drivers of inequality.\n# \n# ## Methodology\n# The analysis combines data on student performance, school funding, and socioeconomic status across multiple regions. We employ data wrangling techniques to clean and prepare the data, followed by regression analysis and visualization to uncover key patterns.\n# \n# ## Results\n# - **Regression Analysis**: Funding per student and SES are significant predictors of student performance, with notable variations across regions.\n# - **Visual Analysis**: Regions with higher funding show a stronger correlation between funding and performance, highlighting areas where investment may be more impactful.\n# \n# ## Conclusion\n# The findings suggest that targeted funding increases in underperforming regions could help mitigate educational inequality. Policymakers should consider these insights when designing interventions to improve educational outcomes across the board.\n\n\n\n\nThis project has guided you through the entire process of conducting an in-depth analysis in the field of economics of education, from data preparation and analysis to interpretation and reporting. By integrating the skills you’ve learned throughout this course, you are now well-equipped to tackle complex research questions and contribute meaningful insights to the field of educational economics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Advanced Quantitative Methods:Description and PredictionSummer Math Camp\n        ",
    "section": "",
    "text": "Advanced Quantitative Methods:Description and PredictionSummer Math Camp\n        \n        \n            Conceptual mastery of statistical methods for public policy, focusing on application rather than mechanics\n        \n        \n            API 209 • Summer 2024Prof: Dan Levy | Summer TF: Rony RodriguezHarvard University\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\nSelect Academic Term/Year:\n\n Fall 2024 \n Fall 2025 \n\n\n\n\nSummer TF\n\n Rony Rodriguez-Ramirez\n Wexner 436. HKS\n rrodriguezramirez@g.harvard.edu\n Bluesky\n\n\n\nCourse details\n\n Check schedule page\n August 15-August 28, 2024\n Time: Varies\n Wexner 436. HKS\n\n\n\nContacting me\n\n Schedule an appointment\n Slack\n\nThe best way to reach me is through email or Slack. I’ll do my best to respond as quickly as possible, but please understand if there’s a bit of a delay—sometimes things get busy! Looking forward to helping out with any questions you have.\n\n\n\n\n📑 Course Overview\nThis summer camp focuses on advanced R programming, specifically on four key areas of data manipulation using the tidyverse. This is a continuation of the pre-summer assignment you completed, where you started using Posit Cloud. There is no formal syllabus for this course, as it is designed to be hands-on and interactive, emphasizing practical application over traditional lecture formats.\n\n\n🎯 Learning Objectives\nBy the end of this summer camp, you will be able to:\n\nMaster Advanced Data Manipulation Techniques: Apply complex filtering, selection, and data reshaping operations using the tidyverse.\nCreate Elegant Data Visualizations: Utilize advanced ggplot2 features to produce publication-quality visuals and interactive plots.\nBuild and Interpret Statistical Models: Develop and diagnose statistical models, including regression and mixed models, to analyze real-world data.\nAutomate and Reproduce Research Workflows: Use RMarkdown and workflow automation tools to create reproducible, efficient research workflows.\n\nFocus:\nThe course centers on applying advanced R programming concepts to solve practical data problems. Emphasis is placed on mastering the tidyverse, creating high-quality data visualizations, constructing robust statistical models, and automating research processes for efficiency and reproducibility.\nHow:\n\nHands-On Learning: The course is designed around interactive coding sessions where you’ll actively engage with datasets, applying techniques as you learn them.\nReal-World Applications: Each lesson is tied to a real-world problem or dataset, ensuring that what you learn is immediately relevant and applicable.\nCollaborative Projects: You will work on collaborative projects that simulate actual research scenarios, allowing you to practice and refine your skills in a team setting.\nFeedback and Iteration: Regular feedback loops and peer reviews will help you iteratively improve your code and understanding, promoting deeper learning.\n\nThroughout the camp, you will:\n\nDiscover how to solve complex data problems using advanced R techniques.\nDistinguish between different methods for data manipulation and visualization, understanding when and why to use each.\nLearn to automate repetitive tasks and create workflows that enhance the efficiency and reproducibility of your research.\n\nThis camp is about not just learning the concepts but mastering their application to become a better R programmer before the semester starts."
  },
  {
    "objectID": "2024/weeks/week01/lab.html",
    "href": "2024/weeks/week01/lab.html",
    "title": "Lab 1: Analyzing Olympic Data with R",
    "section": "",
    "text": "If you haven’t installed R and RStudio, use the following Posit Cloud project\n\n\n\n\n\n\n\nSTOP: Super important warning!\n\n\n\nIf you didn’t complete the summer assignments, you should definitely make time to do complete the following primers. The original content is coming from RStudio and was adapted by Prof. Andrew Heiss.\nFor the first part of this week’s lesson, you need to work through a few of Posit’s introductory primers. You’ll do these in your browser, where you can type code and see results immediately.\nYou’ll learn some of the basics of R, as well as some powerful methods for manipulating data with the {dplyr} package.\nComplete these primers. It may seem like there are a lot, but they’re short and go fairly quickly, especially as you get the hang of the syntax. Also, I have no way of seeing what you do or what you get wrong or right, and that’s totally fine! If you get stuck or want to skip some (or if it gets too easy), feel free to move on!\n\nThe Basics\n\nVisualization basics\nProgramming basics\n\nWork with Data\n\nWorking with tibbles\nIsolating data with {dplyr}\nDeriving information with {dplyr}\n\n\nThe content from these primers comes from the (free and online!) book R for Data Science by Garrett Grolemund and Hadley Wickham. I highly recommend the book as a reference and for continuing to learn and use R in the future (like running regression models and other types of statistical analysis).",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week01/lab.html#exercise-1-data-exploration",
    "href": "2024/weeks/week01/lab.html#exercise-1-data-exploration",
    "title": "Lab 1: Analyzing Olympic Data with R",
    "section": "Exercise 1: Data Exploration",
    "text": "Exercise 1: Data Exploration\n\nLoad the dataset into R.\nUse the code provided above to load the dataset.\nGet an overview of the dataset.\nYou should display the first few rows and summarize each variable to understand the dataset’s structure. This step is crucial for familiarizing yourself with the data you’ll be working with.\nDetermine the number of unique editions, sports, and events in the dataset.\nYour goal here is to identify the diversity within the dataset. Use R functions to calculate how many unique Olympic editions, sports, and events are represented in the data.\n\n\nExpected Outcome:\n\nAn understanding of the dataset’s structure.\nInsights into the diversity of the data, such as the number of unique Olympic editions and sports.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week01/lab.html#exercise-2-handling-missing-values",
    "href": "2024/weeks/week01/lab.html#exercise-2-handling-missing-values",
    "title": "Lab 1: Analyzing Olympic Data with R",
    "section": "Exercise 2: Handling Missing Values",
    "text": "Exercise 2: Handling Missing Values\n\nIdentify missing values.\nDetermine which variables have missing values and how many missing values are present in each. This will help you understand the completeness of the data.\nCreate a subset of the data where all missing values are removed.\nYou should generate a clean dataset without missing values. Consider how this might impact your analysis.\nDiscuss the impact of removing rows with missing values.\nReflect on how the removal of rows could influence the results and representativeness of the data.\n\n\nExpected Outcome:\n\nA list of variables with missing values.\nA cleaned version of the dataset.\nA thoughtful consideration of the implications of removing missing data.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week01/lab.html#exercise-3-analyzing-medals-distribution",
    "href": "2024/weeks/week01/lab.html#exercise-3-analyzing-medals-distribution",
    "title": "Lab 1: Analyzing Olympic Data with R",
    "section": "Exercise 3: Analyzing Medals Distribution",
    "text": "Exercise 3: Analyzing Medals Distribution\n\nCalculate the total number of medals won by each country.\nYou’ll need to group the data by country and count the total number of medals won.\nIdentify the country with the most gold medals.\nFocus on identifying which country has excelled the most in terms of winning gold medals.\n\n\nExpected Outcome:\n\nA summary table showing the total medals won by each country.\nIdentification of the top-performing country in terms of gold medals.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week01/lab.html#exercise-4-analyzing-performance-by-athlete",
    "href": "2024/weeks/week01/lab.html#exercise-4-analyzing-performance-by-athlete",
    "title": "Lab 1: Analyzing Olympic Data with R",
    "section": "Exercise 4: Analyzing Performance by Athlete",
    "text": "Exercise 4: Analyzing Performance by Athlete\n\nIdentify the athlete with the most medals overall.\nYour task is to find the athlete who has won the most medals in the Olympics.\nDetermine the number of unique events the athlete has participated in.\nInvestigate the range of events this top athlete has competed in.\n\n\nExpected Outcome:\n\nThe name of the athlete with the most medals.\nThe number of unique events this athlete has participated in, offering insight into their versatility.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "2024/weeks/week01/lab.html#exercise-5-team-sports-vs.-individual-sports",
    "href": "2024/weeks/week01/lab.html#exercise-5-team-sports-vs.-individual-sports",
    "title": "Lab 1: Analyzing Olympic Data with R",
    "section": "Exercise 5: Team Sports vs. Individual Sports",
    "text": "Exercise 5: Team Sports vs. Individual Sports\n\nCompare the number of medals won in team sports versus individual sports.\nAnalyze how successful athletes have been in team sports compared to individual sports.\nIdentify the most successful team sport.\nDetermine which team sport has yielded the most medals.\n\n\nExpected Outcome:\n\nA comparison of medals won in team versus individual sports.\nIdentification of the most successful team sport, providing insights into which team events dominate in terms of medals.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 01",
      "🧪 Lab"
    ]
  },
  {
    "objectID": "resource/quarto.html",
    "href": "resource/quarto.html",
    "title": "Using Quarto",
    "section": "",
    "text": "Quarto Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other code output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with Quarto. This whole course website is created with Quarto.\nQuarto’s predecessor was called R Markdown and worked exclusively with R (though there are ways to use other languages in document). Quarto is essentially “R Markdown 2.0,” but it is designed to be language agnostic. You can use R, Python, Julia, Observable JS, and even Stata code all in the same document. It is magical.\nHere are the most important things you’ll need to know about Quarto in this class:",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Quarto"
    ]
  },
  {
    "objectID": "resource/quarto.html#key-terms",
    "href": "resource/quarto.html#key-terms",
    "title": "Using Quarto",
    "section": "Key terms",
    "text": "Key terms\n\nDocument: A Markdown file where you type stuff\nChunk: A piece of R code that is included in your document. It looks like this:\n```{r}\n# Code goes here\n1 + 1\n```\nThere must be an empty line before and after the chunk. The final three backticks must be the only thing on the line—if you add more text, or if you forget to add the backticks, or accidentally delete the backticks, your document will not render correctly.\nRender: When you render a document, R runs each of the chunks sequentially and converts the output of each chunk into Markdown. R then runs the document through pandoc to convert it to HTML or PDF or Word (or whatever output you’ve selected).\nYou can render by clicking on the “Render” button at the top of the editor window, or by pressing ⌘⇧K on macOS or control + shift + K on Windows.",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Quarto"
    ]
  },
  {
    "objectID": "resource/quarto.html#add-chunks",
    "href": "resource/quarto.html#add-chunks",
    "title": "Using Quarto",
    "section": "Add chunks",
    "text": "Add chunks\nThere are three ways to insert chunks:\n\nPress ⌘⌥I on macOS or control + alt + I on Windows\nClick on the “Insert” button at the top of the editor window\n\n\n\nManually type all the backticks and curly braces (don’t do this)",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Quarto"
    ]
  },
  {
    "objectID": "resource/quarto.html#chunk-names",
    "href": "resource/quarto.html#chunk-names",
    "title": "Using Quarto",
    "section": "Chunk names",
    "text": "Chunk names\nYou can add names to chunks to make it easier to navigate your document. If you click on the little dropdown menu at the bottom of your editor in RStudio, you can see a table of contents that shows all the headings and chunks. If you name chunks, they’ll appear in the list. If you don’t include a name, the chunk will still show up, but you won’t know what it does.\n\nThere are two ways to add a chunk name:\n\nAs a special comment called label:, following #| at the top of the chunk (this is the preferred way):\n```{r}\n#| label: name-of-this-chunk\n\n1 + 1\n```\nImmediately after the {r in the first line of the chunk (this is the older way):\n```{r name-of-this-chunk}\n1 + 1\n```\n\nNames cannot contain spaces, but they can contain underscores and dashes. All chunk names in your document must be unique.",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Quarto"
    ]
  },
  {
    "objectID": "resource/quarto.html#chunk-options",
    "href": "resource/quarto.html#chunk-options",
    "title": "Using Quarto",
    "section": "Chunk options",
    "text": "Chunk options\nThere are a bunch of different options you can set for each chunk. You can see a complete list in the R Markdown Reference Guide or at {knitr}’s website.\nSet chunk options as special comments following #| at the top of the chunk (this is the preferred way):\n```{r}\n#| label: fig-some-plot\n#| fig-cap: \"Here's a caption for this plot\"\n#| fig-width: 6\n#| fig-height: 4\n#| echo: false\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n```\nTechnically you can also set these options inside the {r} section of the chunk—this is the old way to do it, but it gets really gross and long when you have lots of settings:\n{r fig-some-plot, fig.width=6, fig.height=4, echo=FALSE, fig.cap = \"Here's a caption for this plot\"}\nHere are some of the most common chunk options you’ll use in this class:\n\nlabel: fig-whatever: Try to always use chunk labels. If you want things to be cross-referenceable, use a fig- prefix on chunks that make figures and a tbl- prefix on chunks that make tables\ntbl-cap: \"Blah\": Add a caption to your table\nfig-cap: \"Blah\": Add a caption to your figure\nfig-width: 5 and fig-height: 3 (or whatever number you want): Set the dimensions for figures\necho: false: The code is not shown in the final document, but the results are\nmessage: false: Any messages that R generates (like all the notes that appear after you load a package) are omitted\nwarning: false: Any warnings that R generates are omitted\ninclude: false: The chunk still runs, but the code and results are not included in the final document",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Quarto"
    ]
  },
  {
    "objectID": "resource/quarto.html#inline-chunks",
    "href": "resource/quarto.html#inline-chunks",
    "title": "Using Quarto",
    "section": "Inline chunks",
    "text": "Inline chunks\nYou can also include R output directly in your text, which is really helpful if you want to report numbers from your analysis. To do this, use `r r_code_here`.\nIt’s generally easiest to calculate numbers in a regular chunk beforehand and then use an inline chunk to display the value in your text. For instance, this document…\n```{r}\n#| label: find-avg-mpg\n#| echo: false\n\navg_mpg &lt;- mean(mtcars$mpg)\n```\n\nThe average fuel efficiency for cars from 1974 was `r round(avg_mpg, 1)` miles per gallon.\n… would render to this:\n\nThe average fuel efficiency for cars from 1974 was 20.1 miles per gallon.",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Quarto"
    ]
  },
  {
    "objectID": "resource/quarto.html#output-formats",
    "href": "resource/quarto.html#output-formats",
    "title": "Using Quarto",
    "section": "Output formats",
    "text": "Output formats\nYou can specify what kind of document you create when you render in the YAML front matter.\ntitle: \"My document\"\nformat:\n  html: default\n  pdf: default\n  docx: default\nThe indentation of the YAML section matters, especially when you have settings nested under each output type. Here’s what a typical format section might look like:\n---\ntitle: \"My document\"\nauthor: \"My name\"\ndate: \"June 4, 2024\"\nformat: \n  html_document: \n    toc: yes\n  pdf_document: \n    toc: yes\n  word_document: \n    toc: yes\n---",
    "crumbs": [
      "Resources",
      "Guides",
      "Using Quarto"
    ]
  },
  {
    "objectID": "2024/weeks/week02/page.html",
    "href": "2024/weeks/week02/page.html",
    "title": "🗓️ Week 02 - Tidy Data and Visualization",
    "section": "",
    "text": "In this week, we dive into the concepts of tidy data and data visualization. You’ll learn how to organize your data in a format that is easy to manipulate and visualize. We will focus on transforming data into a “tidy” format where each variable is a column, each observation is a row, and each type of observational unit forms a table. Additionally, we’ll cover essential visualization techniques using ggplot2 to explore and communicate your findings effectively.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02"
    ]
  },
  {
    "objectID": "2024/weeks/week02/page.html#overview",
    "href": "2024/weeks/week02/page.html#overview",
    "title": "🗓️ Week 02 - Tidy Data and Visualization",
    "section": "",
    "text": "In this week, we dive into the concepts of tidy data and data visualization. You’ll learn how to organize your data in a format that is easy to manipulate and visualize. We will focus on transforming data into a “tidy” format where each variable is a column, each observation is a row, and each type of observational unit forms a table. Additionally, we’ll cover essential visualization techniques using ggplot2 to explore and communicate your findings effectively.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02"
    ]
  },
  {
    "objectID": "2024/weeks/week02/page.html#guiding-questions",
    "href": "2024/weeks/week02/page.html#guiding-questions",
    "title": "🗓️ Week 02 - Tidy Data and Visualization",
    "section": "Guiding Questions",
    "text": "Guiding Questions\n\n\n\n\n\n\nThese are optional!\n\n\n\nYou don’t need to answer all of these—or even any of them! They are here to help guide your thinking and reflection on the content. Feel free to explore whatever aspects you find most interesting.\n\n\n\nWhat are the key principles of tidy data, and why are they important?\nHow does the structure of your data impact the type of visualizations you can create?\nIn what ways can data visualization help in uncovering trends and patterns?",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02"
    ]
  },
  {
    "objectID": "2024/weeks/week02/page.html#readings",
    "href": "2024/weeks/week02/page.html#readings",
    "title": "🗓️ Week 02 - Tidy Data and Visualization",
    "section": "Readings",
    "text": "Readings\n\nNo readings for this session.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02"
    ]
  },
  {
    "objectID": "2024/weeks/week02/page.html#lesson-slides",
    "href": "2024/weeks/week02/page.html#lesson-slides",
    "title": "🗓️ Week 02 - Tidy Data and Visualization",
    "section": "👨‍🏫 Lesson Slides",
    "text": "👨‍🏫 Lesson Slides\nEither click on the slide area below or click here to view it in fullscreen. Use your keypad to navigate the slides.\n\n View all slides in new window  Download PDF of all slides\n\n\n\n\n\n```",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02"
    ]
  },
  {
    "objectID": "2024/weeks/week04/page.html",
    "href": "2024/weeks/week04/page.html",
    "title": "🗓️ Week 04 - Intro to Statistical Modeling in R",
    "section": "",
    "text": "In Construction!"
  },
  {
    "objectID": "2024/weeks/week04/page.html#overview",
    "href": "2024/weeks/week04/page.html#overview",
    "title": "🗓️ Week 04 - Intro to Statistical Modeling in R",
    "section": "",
    "text": "In Construction!"
  },
  {
    "objectID": "2024/weeks/week04/page.html#guiding-questions",
    "href": "2024/weeks/week04/page.html#guiding-questions",
    "title": "🗓️ Week 04 - Intro to Statistical Modeling in R",
    "section": "Guiding Questions",
    "text": "Guiding Questions\n\n\n\n\n\n\nThese are optional!\n\n\n\nYou don’t need to answer all of these—or even any of them! They are here to help guide your thinking and reflection on the content. Feel free to explore whatever aspects you find most interesting.\n\n\n\nQuestion 1\nQuestion 2"
  },
  {
    "objectID": "2024/weeks/week04/page.html#readings",
    "href": "2024/weeks/week04/page.html#readings",
    "title": "🗓️ Week 04 - Intro to Statistical Modeling in R",
    "section": "Readings",
    "text": "Readings\n\nNo readings for this session."
  },
  {
    "objectID": "2024/weeks/week04/page.html#lesson-slides",
    "href": "2024/weeks/week04/page.html#lesson-slides",
    "title": "🗓️ Week 04 - Intro to Statistical Modeling in R",
    "section": "👨‍🏫 Lesson Slides",
    "text": "👨‍🏫 Lesson Slides\nEither click on the slide area below or click here to view it in fullscreen. Use your keypad to navigate the slides.\n\n View all slides in new window  Download PDF of all slides"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule: Summer 2024",
    "section": "",
    "text": "Here’s your roadmap for the math camp!\nThe content for each week is organized into three sections, which you’ll follow in this order:\n\nLessons (): Begin with the Lesson section. These pages contain the slides for each topic. Make sure to read through them first to build your foundation for the week.\nHands-on Sessions (): Next, move on to the Hands-on Sessions. These pages include practical exercises that will help you apply what you’ve learned in the lessons. We’ll work on these together during the odd-numbered sessions each week.\nLabs (): Finally, explore the Lab section. These pages offer additional interactive components and lab exercises. You’ll complete these primarily on your own, and we’ll discuss them during the even-numbered sessions each week.\n\nEach week’s content is structured in this same way, so be sure to follow this sequence to get the most out of your learning experience.\n\n\n\n\ntl;dr: You should follow this general process for each session:\n\nRead the slides in the lesson page ()\nWork through the hands-on page ()\nDo the labs page ()\n\n\n\n\n\n\n\n\n\n\n\n\nSubscribe!\n\n\n\nYou can subscribe to this calendar URL in Outlook, Google Calendar, or Apple Calendar:\n\n\n\n Download\n\n\n\n\n\n\n\n\n\n\n\nMath Camp\n\n\n\n\n\n\nTitle\n\n\nLesson\n\n\nHands-on\n\n\nLab\n\n\n\n\n\n\nWeek 1\n\n\n\n\nAug 15\n\n\nIntro to Data Wrangling\n\n\n\n\n\n\n\n\n\n\n\n\n\nAug 16\n\n\nAnalyzing Olympic Data\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2\n\n\n\n\nAug 20\n\n\nTidy Data and Visualization\n\n\n\n\n\n\n\n\n\n\n\n\n\nAug 21\n\n\nVisualizing PISA Data\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 3\n\n\n\n\nAug 26\n\n\nReproducible Research and Automation\n\n\n\n\n\n\n\n\n\n\n\n\n\nAug 28\n\n\nYour Quarto Projects\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 4\n\n\n\n\nSep 2\n\n\nIntro to Statistical Modeling in R\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 4\n\n\nMath Camp Recap"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#plan-for-today",
    "href": "2024/weeks/week01/slides01.html#plan-for-today",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Plan for today",
    "text": "Plan for today\n\nGetting to know each other\nThe layout of this summer camp (just the R part)\nWhy R, RStudio, Positron?\nData manipulation in R"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#who-am-i",
    "href": "2024/weeks/week01/slides01.html#who-am-i",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Who am I?",
    "text": "Who am I?\n\n\nRony Rodriguez-Ramirez (G2)\n\n\n\n\nEd Policy (Economics of Education) Program\n\n\n\n\nPrevious exp: The World Bank (DIME; DECRG), IPA\n\n\n\n\nLike coding!"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#my-role",
    "href": "2024/weeks/week01/slides01.html#my-role",
    "title": "Week 01IntroductionData Wrangling",
    "section": "My role",
    "text": "My role\nWhat should you expect from me?\n\n\nMy job if that you feel confident in R.\nI should be there if you have any questions.\nReply to your emails or slack messages.\n\n\nAt the end of this summer camp?\n\n\nYou should be ready for the semester.\nKnow enough about R.\nKnow how to craft questions and where to look for answers.\nBe happy (?)"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#course-assistants-for-math-camp",
    "href": "2024/weeks/week01/slides01.html#course-assistants-for-math-camp",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Course assistants for Math Camp",
    "text": "Course assistants for Math Camp\n\n\nShan\n\n\n\n\n\n\n\nAyush\n\n\n\n\n\n\n\nSara"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#the-layout-1",
    "href": "2024/weeks/week01/slides01.html#the-layout-1",
    "title": "Week 01IntroductionData Wrangling",
    "section": "The layout",
    "text": "The layout\nWhat are we going during math camp (R Part)?\n8 sessions over the next weeks:\n\n4 Lessons (2 hours)\n\nI will discuss about coding, strategies, and implementation\n\n4 Labs (1.5 hours)\n\nIt will be a hands-on session. I will provide you with exercises and we will solve them together.\n\nOptional: Office hours"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#the-layout-2",
    "href": "2024/weeks/week01/slides01.html#the-layout-2",
    "title": "Week 01IntroductionData Wrangling",
    "section": "The layout",
    "text": "The layout\nThere is a website for this summer camp:\n\nWEBSITE\n\nIt is not up-to-date; but every week, you will have the materials for that respective week, i.e., you should have already your lab for tomorrow."
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#coding",
    "href": "2024/weeks/week01/slides01.html#coding",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Coding",
    "text": "Coding\n\nCoding is a Skill\nIt is most fun to practice a skill with people you know."
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#discussion-activity-archetypes",
    "href": "2024/weeks/week01/slides01.html#discussion-activity-archetypes",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Discussion Activity: Archetypes",
    "text": "Discussion Activity: Archetypes\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntros: Name, where you’re from, favorite midday snack or superhero.\nExperience: With statistics, programming, and/or R? (Yes/No)\nWhich quadrant describes you?"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#classroom-norms",
    "href": "2024/weeks/week01/slides01.html#classroom-norms",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Classroom Norms",
    "text": "Classroom Norms\nClass is a collective enterprise!\n\n\nAllow everyone the chance to speak.\nBe mindful of thoughts and actions.\nUnderstand differing levels of knowledge and experience.\nHelp others in your group!\nDon’t be afraid to ask questions!\nRespect others’ opinions and suggestions.\nTry questions on your own first, then come together.\nTake breaks and have fun!"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#using-ai-for-code-troubleshooting",
    "href": "2024/weeks/week01/slides01.html#using-ai-for-code-troubleshooting",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Using AI for Code Troubleshooting",
    "text": "Using AI for Code Troubleshooting\n\nAI assistants like ChatGPT and Claude can help debug code\nSteps to use AI for troubleshooting:\n\nPaste your code snippet and error message\nAsk for help identifying and fixing the issue\nReview AI’s suggestions critically\nTest proposed solutions in your environment\n\nBenefits:\n\nQuick identification of common errors\nExplanations of underlying issues\nSuggestions for best practices"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#why-r-rstudio-and-positron",
    "href": "2024/weeks/week01/slides01.html#why-r-rstudio-and-positron",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Why R, RStudio, and Positron?",
    "text": "Why R, RStudio, and Positron?\nWhy R?\n\nOpen-source and free.\nExtensive ecosystem for statistical analysis.\nWide range of packages for data manipulation and visualization.\nActive and supportive community."
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#rstudio-and-positron-the-ides-for-r",
    "href": "2024/weeks/week01/slides01.html#rstudio-and-positron-the-ides-for-r",
    "title": "Week 01IntroductionData Wrangling",
    "section": "RStudio and Positron: The IDEs for R",
    "text": "RStudio and Positron: The IDEs for R\nWhy RStudio?\n\n\nIntegrated development environment (IDE) that simplifies coding in R.\nBuilt-in tools for code development, debugging, and collaboration.\nSeamless integration with RMarkdown for dynamic report generation.\nPowerful tools for data visualization and manipulation.\n\n\nWhy Positron?\n\n\nNew, modern IDE designed to enhance the R programming experience.\nSleeker interface with enhanced performance and features.\nSupports the latest R packages and workflows.\nFocuses on integrating modern development tools and practices."
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#which-ide-should-you-use",
    "href": "2024/weeks/week01/slides01.html#which-ide-should-you-use",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Which IDE Should You Use?",
    "text": "Which IDE Should You Use?\nRStudio vs. Positron\n\nRStudio is well-established with a large user base and extensive support.\nPositron offers cutting-edge features for those looking to adopt the latest tools.\nConsider trying both to see which fits your workflow best.\nDuring the pre-summer assignment, we used Posit Cloud.\n\nFor those who haven’t installed, either RStudio nor Positron in your computer, there is a Posit Cloud Project here"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#the-tidyverse",
    "href": "2024/weeks/week01/slides01.html#the-tidyverse",
    "title": "Week 01IntroductionData Wrangling",
    "section": "The tidyverse",
    "text": "The tidyverse"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#original-plot",
    "href": "2024/weeks/week01/slides01.html#original-plot",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Original Plot",
    "text": "Original Plot"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#using-ggplot",
    "href": "2024/weeks/week01/slides01.html#using-ggplot",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Using ggplot",
    "text": "Using ggplot"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#data-manipulation-vs-data-wrangling",
    "href": "2024/weeks/week01/slides01.html#data-manipulation-vs-data-wrangling",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Data Manipulation vs Data Wrangling",
    "text": "Data Manipulation vs Data Wrangling\n\n\nData Manipulation\n\n\nFocused on changing data structure\nOften uses specific functions or methods\nUsually works with structured data\nExamples: sorting, filtering, aggregating\nTypically a part of data wrangling\nMore straightforward, less time-consuming\n\n\n\nData Wrangling\n\n\nBroader process including cleaning and transformation\nMay involve multiple tools and techniques\nHandles both structured and unstructured data\nExamples: merging datasets, handling missing values, format conversion\nEncompasses the entire data preparation process\nCan be complex and time-intensive"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#advanced-data-wrangling",
    "href": "2024/weeks/week01/slides01.html#advanced-data-wrangling",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Advanced Data Wrangling",
    "text": "Advanced Data Wrangling\nMastering Data Manipulation in R\n\n\nAdvanced Filtering and Selection:\n\nUse of conditional filtering and dynamic column selection.\n\nComplex Mutate Operations:\n\nCreating conditional columns, using lag and lead.\n\nData Reshaping:\n\nPivoting data, advanced grouping.\n\nEfficient Data Handling:\n\nJoining datasets, parallel processing."
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#recap-the-tidyverse",
    "href": "2024/weeks/week01/slides01.html#recap-the-tidyverse",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Recap: The Tidyverse",
    "text": "Recap: The Tidyverse\nThe tidyverse is a collection of R packages designed for data science.\nThey share an underlying design philosophy, grammar, and data structures.\nCore Packages:\n\n\nggplot2 - Data visualization\ndplyr - Data manipulation\ntidyr - Data tidying\nreadr - Data import\npurrr - Functional programming\ntibble - Modern data frames\nstringr - String manipulation\nforcats - Categorical data"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#dplyr-key-functions",
    "href": "2024/weeks/week01/slides01.html#dplyr-key-functions",
    "title": "Week 01IntroductionData Wrangling",
    "section": "dplyr: Key Functions",
    "text": "dplyr: Key Functions\nCommonly Used Functions:\n\n\nfilter() - Subset rows based on conditions\nselect() - Choose columns by names\nmutate() - Create new columns or modify existing ones\narrange() - Reorder rows\nsummarize() - Aggregate data\ngroup_by() - Group data for summary operations"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#dplyr-example",
    "href": "2024/weeks/week01/slides01.html#dplyr-example",
    "title": "Week 01IntroductionData Wrangling",
    "section": "dplyr: Example",
    "text": "dplyr: Example\n\n\nlibrary(dplyr)\n\n# Filter and select\nfiltered_data &lt;- starwars |&gt; \n  filter(height &gt; 180) |&gt; \n  select(name, height, hair_color)\n\nfiltered_data\n\n\n# A tibble: 39 × 3\n   name              height hair_color   \n   &lt;chr&gt;              &lt;int&gt; &lt;chr&gt;        \n 1 Darth Vader          202 none         \n 2 Biggs Darklighter    183 black        \n 3 Obi-Wan Kenobi       182 auburn, white\n 4 Anakin Skywalker     188 blond        \n 5 Chewbacca            228 brown        \n 6 Boba Fett            183 black        \n 7 IG-88                200 none         \n 8 Bossk                190 none         \n 9 Qui-Gon Jinn         193 brown        \n10 Nute Gunray          191 none         \n# ℹ 29 more rows"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#dplyr-example-1",
    "href": "2024/weeks/week01/slides01.html#dplyr-example-1",
    "title": "Week 01IntroductionData Wrangling",
    "section": "dplyr: Example",
    "text": "dplyr: Example\n\n\n# Mutate\nstarwars |&gt;\n  mutate(\n    tatooine = ifelse(  #&lt;&lt;\n      homeworld == \"Tatooine\",  #&lt;&lt;\n      \"Tatooine\",  #&lt;&lt;\n      \"Others\"  #&lt;&lt;\n    ) #&lt;&lt;\n  ) |&gt; \n  group_by(tatooine) |&gt; \n  summarize(\n    mean = mean(height)\n  )\n\n\n# A tibble: 3 × 2\n  tatooine  mean\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Others    177.\n2 Tatooine  170.\n3 &lt;NA&gt;       NA"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#are-we-good-here",
    "href": "2024/weeks/week01/slides01.html#are-we-good-here",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Are we good here?",
    "text": "Are we good here?\nAs of now, you should have the tools to understand the last code. More resources are available in our website. Now, it’s time to make some mistakes!\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#sucking",
    "href": "2024/weeks/week01/slides01.html#sucking",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Sucking",
    "text": "Sucking\nOriginally from: Dr. Andrew Heiss\n\n“There is no way of knowing nothing about a subject to knowing something about a subject without going through a period of much frustration and suckiness.”\n“Push through. You’ll suck less.”\nHadley Wickham, author of {ggplot2}"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#sucking-1",
    "href": "2024/weeks/week01/slides01.html#sucking-1",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Sucking",
    "text": "Sucking"
  },
  {
    "objectID": "2024/weeks/week01/slides01.html#sucking-2",
    "href": "2024/weeks/week01/slides01.html#sucking-2",
    "title": "Week 01IntroductionData Wrangling",
    "section": "Sucking",
    "text": "Sucking\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "tutorial/01-content.html",
    "href": "tutorial/01-content.html",
    "title": "Tutorial 1: Introduction to R and Basic Data Types",
    "section": "",
    "text": "R is a powerful programming language widely used for statistical computing and data analysis. In this tutorial, we will cover the basics of R, including how to work with vectors and basic data types. By the end of this tutorial, you will be able to perform simple data operations in R and understand the fundamental data types.\n\n\nTo begin using R, you’ll need to install R and RStudio. RStudio is an integrated development environment (IDE) that makes it easier to write R code.\n\nInstalling R: Visit the CRAN website to download and install R.\nInstalling RStudio: Download and install RStudio from the RStudio website.\n\nOnce installed, open RStudio, and you’re ready to start coding in R!\n\n\n\nR has several basic data types that you will use frequently:\n\n\nVectors are the most basic data structure in R. A vector is a sequence of data elements of the same basic type.\n\n# Numeric vector\nscores &lt;- c(85, 90, 76, 88, 92)\n\n# Character vector\nstudents &lt;- c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\")\n\n# Logical vector\npassed &lt;- c(TRUE, TRUE, FALSE, TRUE, TRUE)\n\n\n\n\nR includes several fundamental data types:\n\nNumeric: Used for numbers. E.g., 1, 3.14, 42.\nCharacter: Used for text strings. E.g., \"apple\", \"R programming\".\nLogical: Used for TRUE or FALSE values. E.g., TRUE, FALSE.\nFactor: Used for categorical data. E.g., levels like \"low\", \"medium\", \"high\".\n\n\n# Example of different data types\nage &lt;- 25               # Numeric\nname &lt;- \"Alice\"         # Character\nis_student &lt;- TRUE      # Logical\n\n\n\n\n\nYou can perform arithmetic operations on numeric vectors and use indices to subset them.\n\n# Arithmetic operations\ntotal_score &lt;- scores + 5  # Adding 5 to each score\n\n# Subsetting vectors\ntop_student &lt;- students[which.max(scores)]  # Finding the student with the highest score\n\n\n\n\n\n\n\nCreate a numeric vector called ages that contains the ages of five students: 18, 21, 19, 22, 20.\nSubtract 2 from each element in the ages vector.\nFind the maximum age in the ages vector.\n\nSolution:\n\n# Step 1: Create the ages vector\nages &lt;- c(18, 21, 19, 22, 20)\n\n# Step 2: Subtract 2 from each element\nadjusted_ages &lt;- ages - 2\n\n# Step 3: Find the maximum age\nmax_age &lt;- max(adjusted_ages)\nmax_age\n\n[1] 20\n\n\nExpected output:\n[1] 20\n\n\n\n\nCreate a character vector called subjects that contains the names of three school subjects: \"Math\", \"History\", \"Biology\".\nAdd a new subject \"Physics\" to the subjects vector.\nExtract the second subject from the subjects vector.\n\nSolution:\n\n# Step 1: Create the subjects vector\nsubjects &lt;- c(\"Math\", \"History\", \"Biology\")\n\n# Step 2: Add a new subject\nsubjects &lt;- c(subjects, \"Physics\")\n\n# Step 3: Extract the second subject\nsecond_subject &lt;- subjects[2]\nsecond_subject\n\n[1] \"History\"\n\n\nExpected output:\n[1] \"History\"\n\n\n\n\nCreate a logical vector called attendance with values TRUE, FALSE, TRUE, TRUE, FALSE.\nCount how many students attended (i.e., how many TRUE values there are).\nFind out if all students attended by using the all() function.\n\nSolution:\n\n# Step 1: Create the attendance vector\nattendance &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE)\n\n# Step 2: Count how many students attended\ncount_attendance &lt;- sum(attendance)\ncount_attendance\n\n[1] 3\n\n# Step 3: Check if all students attended\nall_attended &lt;- all(attendance)\nall_attended\n\n[1] FALSE\n\n\n\n\n\n\nUsing the scores vector from earlier, calculate the average score of the students.\nDetermine how many students scored above 80 using the sum() function.\n\nSolution:\n\n# Step 1: Calculate the average score\naverage_score &lt;- mean(scores)\naverage_score\n\n[1] 86.2\n\n# Step 2: Count how many students scored above 80\nstudents_above_80 &lt;- sum(scores &gt; 80)\nstudents_above_80\n\n[1] 4\n\n\n\n\n\n\nCreate a factor variable grade_levels with the levels \"Freshman\", \"Sophomore\", \"Junior\", \"Senior\".\nAssign a grade level to each student in the students vector.\nDisplay the frequency of each grade level using the table() function.\n\nSolution:\n# Step 1: Create the grade_levels factor\ngrade_levels &lt;- factor(c(\"Freshman\", \"Sophomore\", \"Junior\", \"Senior\", \"Freshman\"),\n                       levels = c(\"Freshman\", \"Sophomore\", \"Junior\", \"Senior\"))\n\n# Step 2: Assign grade levels to students\nstudents_grade_levels &lt;- data.frame(students, grade_levels)\n\n# Step 3: Display the frequency of each grade level\ngrade_frequency &lt;- table(students_grade_levels$grade_levels)\ngrade_frequency",
    "crumbs": [
      "Tutorials",
      "1. Introduction to R and Basic Data Types"
    ]
  },
  {
    "objectID": "tutorial/01-content.html#setting-up-r-and-rstudio",
    "href": "tutorial/01-content.html#setting-up-r-and-rstudio",
    "title": "Tutorial 1: Introduction to R and Basic Data Types",
    "section": "",
    "text": "To begin using R, you’ll need to install R and RStudio. RStudio is an integrated development environment (IDE) that makes it easier to write R code.\n\nInstalling R: Visit the CRAN website to download and install R.\nInstalling RStudio: Download and install RStudio from the RStudio website.\n\nOnce installed, open RStudio, and you’re ready to start coding in R!",
    "crumbs": [
      "Tutorials",
      "1. Introduction to R and Basic Data Types"
    ]
  },
  {
    "objectID": "tutorial/01-content.html#basic-data-types-in-r",
    "href": "tutorial/01-content.html#basic-data-types-in-r",
    "title": "Tutorial 1: Introduction to R and Basic Data Types",
    "section": "",
    "text": "R has several basic data types that you will use frequently:\n\n\nVectors are the most basic data structure in R. A vector is a sequence of data elements of the same basic type.\n\n# Numeric vector\nscores &lt;- c(85, 90, 76, 88, 92)\n\n# Character vector\nstudents &lt;- c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\")\n\n# Logical vector\npassed &lt;- c(TRUE, TRUE, FALSE, TRUE, TRUE)\n\n\n\n\nR includes several fundamental data types:\n\nNumeric: Used for numbers. E.g., 1, 3.14, 42.\nCharacter: Used for text strings. E.g., \"apple\", \"R programming\".\nLogical: Used for TRUE or FALSE values. E.g., TRUE, FALSE.\nFactor: Used for categorical data. E.g., levels like \"low\", \"medium\", \"high\".\n\n\n# Example of different data types\nage &lt;- 25               # Numeric\nname &lt;- \"Alice\"         # Character\nis_student &lt;- TRUE      # Logical",
    "crumbs": [
      "Tutorials",
      "1. Introduction to R and Basic Data Types"
    ]
  },
  {
    "objectID": "tutorial/01-content.html#basic-operations-with-vectors",
    "href": "tutorial/01-content.html#basic-operations-with-vectors",
    "title": "Tutorial 1: Introduction to R and Basic Data Types",
    "section": "",
    "text": "You can perform arithmetic operations on numeric vectors and use indices to subset them.\n\n# Arithmetic operations\ntotal_score &lt;- scores + 5  # Adding 5 to each score\n\n# Subsetting vectors\ntop_student &lt;- students[which.max(scores)]  # Finding the student with the highest score",
    "crumbs": [
      "Tutorials",
      "1. Introduction to R and Basic Data Types"
    ]
  },
  {
    "objectID": "tutorial/01-content.html#exercises-and-solutions",
    "href": "tutorial/01-content.html#exercises-and-solutions",
    "title": "Tutorial 1: Introduction to R and Basic Data Types",
    "section": "",
    "text": "Create a numeric vector called ages that contains the ages of five students: 18, 21, 19, 22, 20.\nSubtract 2 from each element in the ages vector.\nFind the maximum age in the ages vector.\n\nSolution:\n\n# Step 1: Create the ages vector\nages &lt;- c(18, 21, 19, 22, 20)\n\n# Step 2: Subtract 2 from each element\nadjusted_ages &lt;- ages - 2\n\n# Step 3: Find the maximum age\nmax_age &lt;- max(adjusted_ages)\nmax_age\n\n[1] 20\n\n\nExpected output:\n[1] 20\n\n\n\n\nCreate a character vector called subjects that contains the names of three school subjects: \"Math\", \"History\", \"Biology\".\nAdd a new subject \"Physics\" to the subjects vector.\nExtract the second subject from the subjects vector.\n\nSolution:\n\n# Step 1: Create the subjects vector\nsubjects &lt;- c(\"Math\", \"History\", \"Biology\")\n\n# Step 2: Add a new subject\nsubjects &lt;- c(subjects, \"Physics\")\n\n# Step 3: Extract the second subject\nsecond_subject &lt;- subjects[2]\nsecond_subject\n\n[1] \"History\"\n\n\nExpected output:\n[1] \"History\"\n\n\n\n\nCreate a logical vector called attendance with values TRUE, FALSE, TRUE, TRUE, FALSE.\nCount how many students attended (i.e., how many TRUE values there are).\nFind out if all students attended by using the all() function.\n\nSolution:\n\n# Step 1: Create the attendance vector\nattendance &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE)\n\n# Step 2: Count how many students attended\ncount_attendance &lt;- sum(attendance)\ncount_attendance\n\n[1] 3\n\n# Step 3: Check if all students attended\nall_attended &lt;- all(attendance)\nall_attended\n\n[1] FALSE\n\n\n\n\n\n\nUsing the scores vector from earlier, calculate the average score of the students.\nDetermine how many students scored above 80 using the sum() function.\n\nSolution:\n\n# Step 1: Calculate the average score\naverage_score &lt;- mean(scores)\naverage_score\n\n[1] 86.2\n\n# Step 2: Count how many students scored above 80\nstudents_above_80 &lt;- sum(scores &gt; 80)\nstudents_above_80\n\n[1] 4\n\n\n\n\n\n\nCreate a factor variable grade_levels with the levels \"Freshman\", \"Sophomore\", \"Junior\", \"Senior\".\nAssign a grade level to each student in the students vector.\nDisplay the frequency of each grade level using the table() function.\n\nSolution:\n# Step 1: Create the grade_levels factor\ngrade_levels &lt;- factor(c(\"Freshman\", \"Sophomore\", \"Junior\", \"Senior\", \"Freshman\"),\n                       levels = c(\"Freshman\", \"Sophomore\", \"Junior\", \"Senior\"))\n\n# Step 2: Assign grade levels to students\nstudents_grade_levels &lt;- data.frame(students, grade_levels)\n\n# Step 3: Display the frequency of each grade level\ngrade_frequency &lt;- table(students_grade_levels$grade_levels)\ngrade_frequency",
    "crumbs": [
      "Tutorials",
      "1. Introduction to R and Basic Data Types"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html",
    "href": "2024/weeks/week02/hands-on.html",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "",
    "text": "In this hands-on session, we will explore the relationship between various state-level characteristics and the share of votes received by Donald Trump in the 2016 presidential election. We will build a visualization step by step, using the ggplot2 package in R. Throughout this session, you’ll learn how to manipulate data, create plots, and progressively add layers to enhance your visualizations.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#introduction",
    "href": "2024/weeks/week02/hands-on.html#introduction",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "",
    "text": "In this hands-on session, we will explore the relationship between various state-level characteristics and the share of votes received by Donald Trump in the 2016 presidential election. We will build a visualization step by step, using the ggplot2 package in R. Throughout this session, you’ll learn how to manipulate data, create plots, and progressively add layers to enhance your visualizations.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#note-on-the-data",
    "href": "2024/weeks/week02/hands-on.html#note-on-the-data",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Note on the Data",
    "text": "Note on the Data\nThe dataset we’ll be using contains various economic and demographic indicators for U.S. states during the 2016 presidential election. It includes information such as the percentage of the population that completed college (percoled), the share of votes received by Donald Trump (trumpshare), whether Trump won the state (trumpw), and more. Understanding the context of these variables will help you interpret the plots we create.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#data-preparation",
    "href": "2024/weeks/week02/hands-on.html#data-preparation",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nLoad Packages\nWe’ll begin by loading the necessary packages that will help us manipulate the data and create visualizations.\n\n# Load the necessary packages for data manipulation and visualization.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(hrbrthemes)\n\n\n\nLoad the Data\nNext, we’ll load the election dataset, which contains information about state-level turnout and various economic indicators during the 2016 presidential election.\n\n# Load the election dataset.\nelection &lt;- read_csv(\"https://www.dropbox.com/scl/fi/hv1cy5yrwrg2my97dtvly/election_turnout.csv?rlkey=4k44vg4781tv5zaac7cxkq8uf&dl=1\")\n\nRows: 51 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): state, region, division\ndbl (12): rownames, year, turnoutho, perhsed, percoled, gdppercap, ss, trump...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nInspect the Data\nIt’s always important to inspect your data before starting any analysis. This helps you understand the structure of the data and the types of variables you’re working with.\n\n# Use glimpse() to get a quick overview of the dataset.\nelection |&gt; \n  glimpse()\n\nRows: 51\nColumns: 15\n$ rownames    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ year        &lt;dbl&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016…\n$ state       &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", …\n$ region      &lt;chr&gt; \"South\", \"West\", \"West\", \"South\", \"West\", \"West\", \"Northea…\n$ division    &lt;chr&gt; \"East South Central\", \"Pacific\", \"Mountain\", \"West South C…\n$ turnoutho   &lt;dbl&gt; 59.0, 61.3, 55.0, 52.8, 56.7, 70.1, 65.2, 64.4, 60.9, 64.6…\n$ perhsed     &lt;dbl&gt; 84.3, 92.1, 86.0, 84.8, 81.8, 90.7, 89.9, 88.4, 89.3, 86.9…\n$ percoled    &lt;dbl&gt; 23.5, 28.0, 27.5, 21.1, 31.4, 38.1, 37.6, 30.0, 54.6, 27.3…\n$ gdppercap   &lt;dbl&gt; 42663, 81801, 43269, 41129, 61924, 58009, 72331, 69930, 18…\n$ ss          &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0…\n$ trumpw      &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0…\n$ trumpshare  &lt;dbl&gt; 0.62083092, 0.51281512, 0.48671616, 0.60574102, 0.31617107…\n$ sunempr     &lt;dbl&gt; 5.8, 6.9, 5.2, 3.8, 5.4, 2.9, 4.9, 4.5, 6.0, 4.7, 5.3, 2.8…\n$ sunempr12md &lt;dbl&gt; -0.2, 0.3, -0.6, -0.6, -0.3, -0.6, -0.7, -0.2, -0.5, -0.4,…\n$ gdp         &lt;dbl&gt; 203829.8, 49363.4, 311091.0, 120374.8, 2657797.6, 329368.3…",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#exercise-1-basic-scatter-plot",
    "href": "2024/weeks/week02/hands-on.html#exercise-1-basic-scatter-plot",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Exercise 1: Basic Scatter Plot",
    "text": "Exercise 1: Basic Scatter Plot\n\nObjective\nIn this exercise, we aim to create a basic scatter plot that visualizes the relationship between the share of the vote Trump received (trumpshare) and the percentage of the state that completed college (percoled). This is a straightforward way to explore potential correlations between education levels and voting behavior.\n\n\nInstructions\nUse the ggplot() function to initialize the plot, mapping percoled to the x-axis and trumpshare to the y-axis. Then, add points to the plot using geom_point().\n\n# Create a basic scatter plot.\nelection |&gt; \n  ggplot(\n    aes(\n      x = percoled,    # percoled on the x-axis\n      y = trumpshare   # trumpshare on the y-axis\n    )\n  ) +\n  geom_point() +          # Add points to represent each state\n  labs(\n    title = \"Relationship between Trump Vote Share and College Education\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExplanation\nIn this plot, each point represents a state, with the x-axis showing the percentage of the population with a college education and the y-axis showing the percentage of votes Trump received. This basic plot will help us identify any apparent trends or outliers.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#exercise-2-data-transformation",
    "href": "2024/weeks/week02/hands-on.html#exercise-2-data-transformation",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Exercise 2: Data Transformation",
    "text": "Exercise 2: Data Transformation\n\nObjective\nBefore enhancing our plot, we’ll transform some variables to better suit our analysis. Specifically, we’ll convert trumpw into a categorical variable (factor) and rescale percoled to represent it as a proportion (dividing by 100).\n\n\nInstructions\nUse the mutate() function to transform the data and then create a scatter plot with the transformed variables.\n\n# Transform the data.\nelection_transformed &lt;- election |&gt; \n  mutate(\n    trumpw = as_factor(trumpw),  # Convert trumpw to a factor\n    percoled = percoled / 100    # Rescale percoled to be a proportion\n  )\n\n# Plot using the transformed data.\nelection_transformed |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  labs(\n    title = \"Trump Vote Share vs. College Education (Transformed Data)\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExplanation\nBy converting trumpw to a factor, we make it easier to group the data by whether Trump won a state. Rescaling percoled to a proportion standardizes the variable, allowing for more intuitive interpretation, especially when we apply formatting later on.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#exercise-3-filtering-data",
    "href": "2024/weeks/week02/hands-on.html#exercise-3-filtering-data",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Exercise 3: Filtering Data",
    "text": "Exercise 3: Filtering Data\n\nObjective\nIn this exercise, we’ll filter out the District of Columbia from our dataset. D.C. is often an outlier in many analyses due to its unique characteristics, so excluding it can make patterns in the rest of the data clearer.\n\n\nInstructions\nUse the filter() function to remove D.C. from the dataset, then create a scatter plot with the filtered data.\n\n# Filter the data.\nelection_filtered &lt;- election_transformed |&gt; \n  filter(state != \"District of Columbia\")\n\n# Plot the filtered data.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  labs(\n    title = \"Trump Vote Share vs. College Education (Filtered Data)\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExplanation\nRemoving D.C. reduces the potential for this outlier to skew the visual representation of the data, allowing for a more accurate depiction of the relationship between education levels and Trump’s vote share in the other states.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#exercise-4-adding-a-regression-line",
    "href": "2024/weeks/week02/hands-on.html#exercise-4-adding-a-regression-line",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Exercise 4: Adding a Regression Line",
    "text": "Exercise 4: Adding a Regression Line\n\nObjective\nTo better understand the relationship between education and Trump’s vote share, we’ll add a linear regression line to our scatter plot. This line will help us see the overall trend in the data.\n\n\nInstructions\nUse geom_smooth() with the method = \"lm\" argument to add a linear regression line to your scatter plot.\n\n# Add a linear regression line to the plot.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n     \n\n x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +       # Add a linear regression line\n  labs(\n    title = \"Trump Vote Share vs. College Education with Regression Line\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nThe regression line provides a clear visual summary of the direction and strength of the relationship between the percentage of college-educated individuals and Trump’s vote share. The slope of the line will indicate whether there’s a positive or negative correlation.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#exercise-5-adding-a-horizontal-reference-line",
    "href": "2024/weeks/week02/hands-on.html#exercise-5-adding-a-horizontal-reference-line",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Exercise 5: Adding a Horizontal Reference Line",
    "text": "Exercise 5: Adding a Horizontal Reference Line\n\nObjective\nIn this exercise, we’ll add a horizontal reference line at 50% Trump vote share. This line represents a key threshold, indicating whether Trump received more or less than half of the votes in each state.\n\n\nInstructions\nUse geom_hline() to add a horizontal dashed line at y = 0.5.\n\n# Add a horizontal reference line at 50% Trump vote share.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"grey\") + # Add horizontal line at 50%\n  labs(\n    title = \"Trump Vote Share vs. College Education with Reference Line\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nThe 50% line is a critical point of reference, as it allows us to quickly see which states Trump won (above the line) and which he lost (below the line). This adds another layer of interpretation to the plot.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#exercise-6-adding-text-labels",
    "href": "2024/weeks/week02/hands-on.html#exercise-6-adding-text-labels",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Exercise 6: Adding Text Labels",
    "text": "Exercise 6: Adding Text Labels\n\nObjective\nTo make the plot more informative, we’ll add text labels to the points. This will allow us to see which state each point represents without having to hover over or refer to another source.\n\n\nInstructions\nUse geom_text() to add state labels to the points on your scatter plot.\n\n# Add text labels to the points.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"grey\") +\n  geom_text(aes(label = state), vjust = -0.5, size = 3, show.legend = FALSE) + # Add text labels\n  labs(\n    title = \"Trump Vote Share vs. College Education with State Labels\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nBy labeling each point with its corresponding state abbreviation, we can easily identify which states exhibit particular voting and education patterns. This is especially useful for recognizing outliers or regional trends.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#exercise-7-adjusting-axis-scales",
    "href": "2024/weeks/week02/hands-on.html#exercise-7-adjusting-axis-scales",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Exercise 7: Adjusting Axis Scales",
    "text": "Exercise 7: Adjusting Axis Scales\n\nObjective\nTo improve the readability of our plot, we’ll adjust the x and y axes to display percentages. We’ll also add a custom color scale to differentiate between states that Trump won and those he didn’t.\n\n\nInstructions\nUse scale_x_continuous() and scale_y_continuous() to format the axes as percentages, and scale_color_manual() to define custom colors for the trumpw variable.\n\n# Adjust axis scales and color scale.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare,\n      color = trumpw    # Color points by whether Trump won the state\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"grey\") +\n  geom_text(aes(label = state), vjust = -0.5, size = 3, show.legend = FALSE) +\n  scale_x_continuous(labels = scales::percent) +  # Format x-axis as percentage\n  scale_y_continuous(breaks = seq(0,1,.2), labels = scales::percent) +  # Format y-axis as percentage\n  scale_color_manual(labels = c(\"No\", \"Yes\"), values = c(\"blue\", \"red\")) + # Custom color scale\n  labs(\n    title = \"Trump Vote Share vs. College Education with Adjusted Scales\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\",\n    color = \"Did Trump win the State?\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nFormatting the axes as percentages makes the data more interpretable for viewers. The custom color scale enhances the plot by visually distinguishing states based on the election outcome, making patterns and trends easier to detect.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#exercise-8-adding-facets",
    "href": "2024/weeks/week02/hands-on.html#exercise-8-adding-facets",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Exercise 8: Adding Facets",
    "text": "Exercise 8: Adding Facets\n\nObjective\nFinally, we’ll use facets to create separate plots for each region. This allows us to compare trends across different parts of the country more effectively.\n\n\nInstructions\nUse facet_wrap(~ region) to create a separate plot for each region.\n\n# Add facets to create separate plots by region.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare,\n      color = trumpw\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"grey\") +\n  geom_text(aes(label = state), vjust = -0.5, size = 3, show.legend = FALSE) +\n  scale_x_continuous(labels = scales::percent) +  \n  scale_y_continuous(breaks = seq(0,1,.2), labels = scales::percent) +\n  scale_color_manual(labels = c(\"No\", \"Yes\"), values = c(\"blue\", \"red\")) +\n  coord_cartesian(clip = \"off\") + # Ensure labels are not clipped\n  facet_wrap(~ region) +          # Facet by region\n  labs(\n    title = \"Trump Vote Share vs. College Education by Region\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\",\n    color = \"Did Trump win the State?\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nFaceting allows us to see how the relationship between education and Trump’s vote share varies across different regions. This can reveal regional differences that might not be apparent when looking at the data as a whole.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "2024/weeks/week02/hands-on.html#recap",
    "href": "2024/weeks/week02/hands-on.html#recap",
    "title": "Hands-on: Tidy Data and Visualization",
    "section": "Recap",
    "text": "Recap\nIn this session, we’ve progressively built a complex ggplot2 visualization, starting from a basic scatter plot and adding layers such as regression lines, reference lines, text labels, custom scales, and facets. Each step has added more depth to our understanding of the data, demonstrating the power and flexibility of ggplot2 for exploring relationships within data.",
    "crumbs": [
      "Math Camp 2024",
      "🗓️ Weeks",
      "Week 02",
      "💻 Hands-on Session"
    ]
  },
  {
    "objectID": "tutorial/04-content.html",
    "href": "tutorial/04-content.html",
    "title": "Tutorial 4: Data Analysis with Tidyverse",
    "section": "",
    "text": "In this tutorial, we will delve deeper into data analysis using the Tidyverse, focusing on more advanced data manipulation techniques. We will explore grouping data, summarizing results, and transforming data into a tidy format. These techniques are crucial for conducting meaningful data analysis, particularly in the context of educational data. We will load the dplyr and tidyr packages from the tidyverse for this tutorial. Remember that if you haven’t installed the tidyverse, you can use install.packages().\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\n\n\n\nOne of the most powerful features of dplyr is the ability to group data by one or more variables and then summarize each group using a variety of summary statistics.\n\n\nThe group_by() function allows you to group data by one or more variables. This is often the first step in data analysis when you want to calculate summary statistics for different groups within your dataset.\n\n# Example data frame\nstudents_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"),\n  Major = c(\"Economics\", \"Economics\", \"History\", \"Biology\", \"History\"),\n  Score = c(85, 90, 78, 88, 92)\n)\n\n# Grouping by Major\ngrouped_df &lt;- students_df |&gt; \n  group_by(Major)\ngrouped_df\n\n# A tibble: 5 × 3\n# Groups:   Major [3]\n  Name    Major     Score\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 Alice   Economics    85\n2 Bob     Economics    90\n3 Charlie History      78\n4 David   Biology      88\n5 Eva     History      92\n\n\nExplanation: - group_by() creates a grouped data frame where operations can be applied separately to each group. - In this example, students are grouped by their Major.\n\n\n\nOnce the data is grouped, you can use the summarise() function to calculate summary statistics, such as the mean, median, count, etc., for each group.\n\n# Calculating the average score for each major\nsummary_df &lt;- grouped_df |&gt; \n  summarise(AverageScore = mean(Score))\nsummary_df\n\n# A tibble: 3 × 2\n  Major     AverageScore\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Biology           88  \n2 Economics         87.5\n3 History           85  \n\n\nExplanation: - summarise() creates a new data frame with summary statistics calculated for each group. Here, the mean score is calculated for each Major.\n\n\n\nYou can combine group_by() and summarise() to perform complex analyses on your data.\n\n# Calculating both the average score and the number of students in each major\nsummary_df &lt;- students_df |&gt;\n  group_by(Major) |&gt;\n  summarise(\n    AverageScore = mean(Score),\n    StudentCount = n()\n  )\nsummary_df\n\n# A tibble: 3 × 3\n  Major     AverageScore StudentCount\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;int&gt;\n1 Biology           88              1\n2 Economics         87.5            2\n3 History           85              2\n\n\nExplanation: - This example shows how to calculate multiple summary statistics at once. The n() function counts the number of observations in each group.\n\n\n\n\nThe mutate() function allows you to create new variables or modify existing ones, while transmute() does the same but only keeps the newly created variables.\n\n\n\n# Adding a new column for standardized scores\nstudents_df &lt;- students_df |&gt;\n  mutate(\n    StandardizedScore = (Score - mean(Score)) / sd(Score)\n  )\n\nstudents_df\n\n     Name     Major Score StandardizedScore\n1   Alice Economics    85        -0.2930973\n2     Bob Economics    90         0.6228318\n3 Charlie   History    78        -1.5753981\n4   David   Biology    88         0.2564602\n5     Eva   History    92         0.9892035\n\n\nExplanation: - mutate() creates a new column StandardizedScore, which standardizes the Score by subtracting the mean and dividing by the standard deviation.\n\n\n\nIf you only want to keep the newly created variables, use transmute().\n\n# Keeping only the standardized scores\nstandardized_df &lt;- students_df |&gt;\n  transmute(\n    Name, StandardizedScore = (Score - mean(Score)) / sd(Score)\n  )\n\nstandardized_df\n\n     Name StandardizedScore\n1   Alice        -0.2930973\n2     Bob         0.6228318\n3 Charlie        -1.5753981\n4   David         0.2564602\n5     Eva         0.9892035\n\n\nExplanation: - transmute() creates the StandardizedScore column and drops all other columns except Name.\n\n\n\n\nData often needs to be reshaped from wide to long format or vice versa. The pivot_longer() and pivot_wider() functions from the tidyr package are used for this purpose.\n\n\n\n# Example wide data frame\nwide_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  Math_Score = c(85, 90, 78),\n  History_Score = c(88, 80, 90)\n)\n\n# Converting to long format\nlong_df &lt;- wide_df |&gt;\n  pivot_longer(\n    cols = contains(\"Score\"), \n    names_to = \"Subject\", \n    values_to = \"Score\"\n  )\n\nlong_df\n\n# A tibble: 6 × 3\n  Name    Subject       Score\n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;\n1 Alice   Math_Score       85\n2 Alice   History_Score    88\n3 Bob     Math_Score       90\n4 Bob     History_Score    80\n5 Charlie Math_Score       78\n6 Charlie History_Score    90\n\n\nExplanation: - pivot_longer() converts the data from wide format (separate columns for each subject) to long format (one column for subjects and one for scores). - The cols argument specifies which columns to pivot, names_to specifies the name of the new variable that will contain the original column names, and values_to specifies the name of the variable that will contain the values.\n\n\n\n\n# Converting long format back to wide format\nwide_again_df &lt;- long_df |&gt;\n  pivot_wider(\n    names_from = Subject, \n    values_from = Score\n  )\n\nwide_again_df\n\n# A tibble: 3 × 3\n  Name    Math_Score History_Score\n  &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1 Alice           85            88\n2 Bob             90            80\n3 Charlie         78            90\n\n\nExplanation: - pivot_wider() is the opposite of pivot_longer(). It spreads key-value pairs across multiple columns, converting the data back to wide format.\n\n\n\n\n\n\n\nUsing the students_df data frame, group the data by Major.\nCalculate the total number of students and the maximum score for each Major.\n\nSolution:\n\n# Step 1: Grouping by Major\ngrouped_df &lt;- students_df |&gt; \n  group_by(Major)\n\n# Step 2: Summarising total students and maximum score\nsummary_df &lt;- grouped_df |&gt;\n  summarise(\n    TotalStudents = n(),\n    MaxScore = max(Score)\n  )\n\n\n\n\n\nCreate a new column in students_df called ScoreCategory that categorizes scores as “High” (&gt;= 85) or “Low” (&lt; 85).\nModify the ScoreCategory column to reflect “Very High” for scores &gt;= 90.\n\nSolution:\n\n# Step 1: Adding ScoreCategory column\nstudents_df &lt;- students_df |&gt;\n  mutate(\n    ScoreCategory = ifelse(Score &gt;= 85, \"High\", \"Low\")\n  )\n\n# Step 2: Modifying ScoreCategory for Very High scores\nstudents_df &lt;- students_df |&gt;\n  mutate(\n    ScoreCategory = ifelse(Score &gt;= 90, \"Very High\", ScoreCategory)\n  )\n\nstudents_df\n\n     Name     Major Score StandardizedScore ScoreCategory\n1   Alice Economics    85        -0.2930973          High\n2     Bob Economics    90         0.6228318     Very High\n3 Charlie   History    78        -1.5753981           Low\n4   David   Biology    88         0.2564602          High\n5     Eva   History    92         0.9892035     Very High\n\n\n\n\n\n\nConvert the wide_df data frame from wide to long format using pivot_longer().\nRename the Subject column to Course in the long data frame.\n\nSolution:\n\n# Step 1: Pivoting from wide to long format\nlong_df &lt;- wide_df |&gt;\n  pivot_longer(\n    cols = contains(\"Score\"), \n    names_to = \"Subject\", \n    values_to = \"Score\"\n  )\n\n# Step 2: Renaming Subject to Course\nlong_df &lt;- long_df |&gt;\n  rename(Course = Subject)\n\nlong_df\n\n# A tibble: 6 × 3\n  Name    Course        Score\n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;\n1 Alice   Math_Score       85\n2 Alice   History_Score    88\n3 Bob     Math_Score       90\n4 Bob     History_Score    80\n5 Charlie Math_Score       78\n6 Charlie History_Score    90\n\n\n\n\n\n\nUsing students_df, create a new column called AdjustedScore where each score is increased by 5%.\nGroup the data by Major and calculate the average AdjustedScore for each Major.\n\nSolution:\n\n# Step 1: Adding AdjustedScore column\nstudents_df &lt;- students_df |&gt;\n  mutate(AdjustedScore = Score * 1.05)\n\n# Step 2: Grouping by Major and calculating average AdjustedScore\nsummary_df &lt;- students_df |&gt;\n  group_by(Major) |&gt;\n  summarise(AverageAdjustedScore = mean(AdjustedScore))\n\n\n\n\n\nUsing long_df, convert the data back to wide format with pivot_wider().\nEnsure the resulting data frame has Name as rows and Course as columns with scores as values.\n\nSolution:\n\n# Pivoting from long to wide format\nwide_again_df &lt;- long_df |&gt;\n  pivot_wider(names_from = Course, values_from = Score)\n\nwide_again_df\n\n# A tibble: 3 × 3\n  Name    Math_Score History_Score\n  &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1 Alice           85            88\n2 Bob             90            80\n3 Charlie         78            90",
    "crumbs": [
      "Tutorials",
      "4. Data Analysis"
    ]
  },
  {
    "objectID": "tutorial/04-content.html#grouping-and-summarizing-data",
    "href": "tutorial/04-content.html#grouping-and-summarizing-data",
    "title": "Tutorial 4: Data Analysis with Tidyverse",
    "section": "",
    "text": "One of the most powerful features of dplyr is the ability to group data by one or more variables and then summarize each group using a variety of summary statistics.\n\n\nThe group_by() function allows you to group data by one or more variables. This is often the first step in data analysis when you want to calculate summary statistics for different groups within your dataset.\n\n# Example data frame\nstudents_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"),\n  Major = c(\"Economics\", \"Economics\", \"History\", \"Biology\", \"History\"),\n  Score = c(85, 90, 78, 88, 92)\n)\n\n# Grouping by Major\ngrouped_df &lt;- students_df |&gt; \n  group_by(Major)\ngrouped_df\n\n# A tibble: 5 × 3\n# Groups:   Major [3]\n  Name    Major     Score\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 Alice   Economics    85\n2 Bob     Economics    90\n3 Charlie History      78\n4 David   Biology      88\n5 Eva     History      92\n\n\nExplanation: - group_by() creates a grouped data frame where operations can be applied separately to each group. - In this example, students are grouped by their Major.\n\n\n\nOnce the data is grouped, you can use the summarise() function to calculate summary statistics, such as the mean, median, count, etc., for each group.\n\n# Calculating the average score for each major\nsummary_df &lt;- grouped_df |&gt; \n  summarise(AverageScore = mean(Score))\nsummary_df\n\n# A tibble: 3 × 2\n  Major     AverageScore\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Biology           88  \n2 Economics         87.5\n3 History           85  \n\n\nExplanation: - summarise() creates a new data frame with summary statistics calculated for each group. Here, the mean score is calculated for each Major.\n\n\n\nYou can combine group_by() and summarise() to perform complex analyses on your data.\n\n# Calculating both the average score and the number of students in each major\nsummary_df &lt;- students_df |&gt;\n  group_by(Major) |&gt;\n  summarise(\n    AverageScore = mean(Score),\n    StudentCount = n()\n  )\nsummary_df\n\n# A tibble: 3 × 3\n  Major     AverageScore StudentCount\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;int&gt;\n1 Biology           88              1\n2 Economics         87.5            2\n3 History           85              2\n\n\nExplanation: - This example shows how to calculate multiple summary statistics at once. The n() function counts the number of observations in each group.",
    "crumbs": [
      "Tutorials",
      "4. Data Analysis"
    ]
  },
  {
    "objectID": "tutorial/04-content.html#data-transformation-with-mutate-and-transmute",
    "href": "tutorial/04-content.html#data-transformation-with-mutate-and-transmute",
    "title": "Tutorial 4: Data Analysis with Tidyverse",
    "section": "",
    "text": "The mutate() function allows you to create new variables or modify existing ones, while transmute() does the same but only keeps the newly created variables.\n\n\n\n# Adding a new column for standardized scores\nstudents_df &lt;- students_df |&gt;\n  mutate(\n    StandardizedScore = (Score - mean(Score)) / sd(Score)\n  )\n\nstudents_df\n\n     Name     Major Score StandardizedScore\n1   Alice Economics    85        -0.2930973\n2     Bob Economics    90         0.6228318\n3 Charlie   History    78        -1.5753981\n4   David   Biology    88         0.2564602\n5     Eva   History    92         0.9892035\n\n\nExplanation: - mutate() creates a new column StandardizedScore, which standardizes the Score by subtracting the mean and dividing by the standard deviation.\n\n\n\nIf you only want to keep the newly created variables, use transmute().\n\n# Keeping only the standardized scores\nstandardized_df &lt;- students_df |&gt;\n  transmute(\n    Name, StandardizedScore = (Score - mean(Score)) / sd(Score)\n  )\n\nstandardized_df\n\n     Name StandardizedScore\n1   Alice        -0.2930973\n2     Bob         0.6228318\n3 Charlie        -1.5753981\n4   David         0.2564602\n5     Eva         0.9892035\n\n\nExplanation: - transmute() creates the StandardizedScore column and drops all other columns except Name.",
    "crumbs": [
      "Tutorials",
      "4. Data Analysis"
    ]
  },
  {
    "objectID": "tutorial/04-content.html#pivoting-data-with-pivot_longer-and-pivot_wider",
    "href": "tutorial/04-content.html#pivoting-data-with-pivot_longer-and-pivot_wider",
    "title": "Tutorial 4: Data Analysis with Tidyverse",
    "section": "",
    "text": "Data often needs to be reshaped from wide to long format or vice versa. The pivot_longer() and pivot_wider() functions from the tidyr package are used for this purpose.\n\n\n\n# Example wide data frame\nwide_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  Math_Score = c(85, 90, 78),\n  History_Score = c(88, 80, 90)\n)\n\n# Converting to long format\nlong_df &lt;- wide_df |&gt;\n  pivot_longer(\n    cols = contains(\"Score\"), \n    names_to = \"Subject\", \n    values_to = \"Score\"\n  )\n\nlong_df\n\n# A tibble: 6 × 3\n  Name    Subject       Score\n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;\n1 Alice   Math_Score       85\n2 Alice   History_Score    88\n3 Bob     Math_Score       90\n4 Bob     History_Score    80\n5 Charlie Math_Score       78\n6 Charlie History_Score    90\n\n\nExplanation: - pivot_longer() converts the data from wide format (separate columns for each subject) to long format (one column for subjects and one for scores). - The cols argument specifies which columns to pivot, names_to specifies the name of the new variable that will contain the original column names, and values_to specifies the name of the variable that will contain the values.\n\n\n\n\n# Converting long format back to wide format\nwide_again_df &lt;- long_df |&gt;\n  pivot_wider(\n    names_from = Subject, \n    values_from = Score\n  )\n\nwide_again_df\n\n# A tibble: 3 × 3\n  Name    Math_Score History_Score\n  &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1 Alice           85            88\n2 Bob             90            80\n3 Charlie         78            90\n\n\nExplanation: - pivot_wider() is the opposite of pivot_longer(). It spreads key-value pairs across multiple columns, converting the data back to wide format.",
    "crumbs": [
      "Tutorials",
      "4. Data Analysis"
    ]
  },
  {
    "objectID": "tutorial/04-content.html#exercises-and-solutions",
    "href": "tutorial/04-content.html#exercises-and-solutions",
    "title": "Tutorial 4: Data Analysis with Tidyverse",
    "section": "",
    "text": "Using the students_df data frame, group the data by Major.\nCalculate the total number of students and the maximum score for each Major.\n\nSolution:\n\n# Step 1: Grouping by Major\ngrouped_df &lt;- students_df |&gt; \n  group_by(Major)\n\n# Step 2: Summarising total students and maximum score\nsummary_df &lt;- grouped_df |&gt;\n  summarise(\n    TotalStudents = n(),\n    MaxScore = max(Score)\n  )\n\n\n\n\n\nCreate a new column in students_df called ScoreCategory that categorizes scores as “High” (&gt;= 85) or “Low” (&lt; 85).\nModify the ScoreCategory column to reflect “Very High” for scores &gt;= 90.\n\nSolution:\n\n# Step 1: Adding ScoreCategory column\nstudents_df &lt;- students_df |&gt;\n  mutate(\n    ScoreCategory = ifelse(Score &gt;= 85, \"High\", \"Low\")\n  )\n\n# Step 2: Modifying ScoreCategory for Very High scores\nstudents_df &lt;- students_df |&gt;\n  mutate(\n    ScoreCategory = ifelse(Score &gt;= 90, \"Very High\", ScoreCategory)\n  )\n\nstudents_df\n\n     Name     Major Score StandardizedScore ScoreCategory\n1   Alice Economics    85        -0.2930973          High\n2     Bob Economics    90         0.6228318     Very High\n3 Charlie   History    78        -1.5753981           Low\n4   David   Biology    88         0.2564602          High\n5     Eva   History    92         0.9892035     Very High\n\n\n\n\n\n\nConvert the wide_df data frame from wide to long format using pivot_longer().\nRename the Subject column to Course in the long data frame.\n\nSolution:\n\n# Step 1: Pivoting from wide to long format\nlong_df &lt;- wide_df |&gt;\n  pivot_longer(\n    cols = contains(\"Score\"), \n    names_to = \"Subject\", \n    values_to = \"Score\"\n  )\n\n# Step 2: Renaming Subject to Course\nlong_df &lt;- long_df |&gt;\n  rename(Course = Subject)\n\nlong_df\n\n# A tibble: 6 × 3\n  Name    Course        Score\n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;\n1 Alice   Math_Score       85\n2 Alice   History_Score    88\n3 Bob     Math_Score       90\n4 Bob     History_Score    80\n5 Charlie Math_Score       78\n6 Charlie History_Score    90\n\n\n\n\n\n\nUsing students_df, create a new column called AdjustedScore where each score is increased by 5%.\nGroup the data by Major and calculate the average AdjustedScore for each Major.\n\nSolution:\n\n# Step 1: Adding AdjustedScore column\nstudents_df &lt;- students_df |&gt;\n  mutate(AdjustedScore = Score * 1.05)\n\n# Step 2: Grouping by Major and calculating average AdjustedScore\nsummary_df &lt;- students_df |&gt;\n  group_by(Major) |&gt;\n  summarise(AverageAdjustedScore = mean(AdjustedScore))\n\n\n\n\n\nUsing long_df, convert the data back to wide format with pivot_wider().\nEnsure the resulting data frame has Name as rows and Course as columns with scores as values.\n\nSolution:\n\n# Pivoting from long to wide format\nwide_again_df &lt;- long_df |&gt;\n  pivot_wider(names_from = Course, values_from = Score)\n\nwide_again_df\n\n# A tibble: 3 × 3\n  Name    Math_Score History_Score\n  &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1 Alice           85            88\n2 Bob             90            80\n3 Charlie         78            90",
    "crumbs": [
      "Tutorials",
      "4. Data Analysis"
    ]
  },
  {
    "objectID": "tutorial/03-content.html",
    "href": "tutorial/03-content.html",
    "title": "Tutorial 3: Introduction to Tidyverse and the Base Pipe",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Tutorials",
      "3. Introduction to Tidyverse"
    ]
  },
  {
    "objectID": "tutorial/03-content.html#introduction-to-tidyverse",
    "href": "tutorial/03-content.html#introduction-to-tidyverse",
    "title": "Tutorial 3: Introduction to Tidyverse and the Base Pipe",
    "section": "3.1 Introduction to Tidyverse",
    "text": "3.1 Introduction to Tidyverse\nThe Tidyverse is a suite of R packages that work together to simplify data manipulation, exploration, and visualization. Key packages in the Tidyverse include dplyr, ggplot2, tidyr, readr, and more. In this tutorial, we’ll focus on dplyr, which is used for data manipulation.\n\n3.1.1 Installing and Loading Tidyverse\nBefore using Tidyverse functions, you need to install and load the package.\n\n# Install Tidyverse (if not already installed)\ninstall.packages(\"tidyverse\")\n\n# Load Tidyverse\nlibrary(tidyverse)\n\nExplanation: - The install.packages() function installs the Tidyverse package if it isn’t already installed on your system. - The library() function loads the Tidyverse, making its functions available for use.\n\n\n3.1.2 Introduction to the Base Pipe (|&gt;)\nThe base pipe operator |&gt; was introduced in R 4.1.0. It allows for cleaner, more readable code by enabling a sequence of operations to be chained together.\n\n# Example using base pipe to calculate the mean of a vector\nscores &lt;- c(85, 90, 78, 92, 88)\nmean_score &lt;- scores |&gt; mean()\nmean_score\n\n[1] 86.6\n\n\nExplanation: - The |&gt; operator takes the output of the left-hand expression and passes it as the first argument to the function on the right-hand side. - In this example, scores is passed to the mean() function to calculate the mean score.",
    "crumbs": [
      "Tutorials",
      "3. Introduction to Tidyverse"
    ]
  },
  {
    "objectID": "tutorial/03-content.html#dplyr-basics",
    "href": "tutorial/03-content.html#dplyr-basics",
    "title": "Tutorial 3: Introduction to Tidyverse and the Base Pipe",
    "section": "3.2 dplyr Basics",
    "text": "3.2 dplyr Basics\ndplyr is the main package within the Tidyverse for data manipulation. It provides a set of intuitive functions for working with data frames.\n\n3.2.1 select(): Selecting Columns\nThe select() function allows you to choose specific columns from a data frame.\n\n# Example data frame\nstudents_df &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  Age = c(20, 21, 19),\n  Score = c(85, 90, 78),\n  Major = c(\"Economics\", \"History\", \"Biology\")\n)\n\n# Selecting Name and Score columns\nselected_df &lt;- students_df |&gt; select(Name, Score)\nselected_df\n\n     Name Score\n1   Alice    85\n2     Bob    90\n3 Charlie    78\n\n\nExplanation: - select() is used to pick specific columns from the data frame. - The base pipe |&gt; passes students_df to the select() function.\n\n\n3.2.2 filter(): Filtering Rows\nThe filter() function allows you to filter rows based on specific conditions.\n\n# Filtering students with a score greater than 80\nfiltered_df &lt;- students_df |&gt; filter(Score &gt; 80)\nfiltered_df\n\n   Name Age Score     Major\n1 Alice  20    85 Economics\n2   Bob  21    90   History\n\n\nExplanation: - filter() is used to select rows that meet a condition. Here, only students with a score greater than 80 are included.\n\n\n3.2.3 arrange(): Arranging Rows\nThe arrange() function orders the rows of a data frame based on the values of specified columns.\n\n# Arranging students by score in descending order\narranged_df &lt;- students_df |&gt; arrange(desc(Score))\narranged_df\n\n     Name Age Score     Major\n1     Bob  21    90   History\n2   Alice  20    85 Economics\n3 Charlie  19    78   Biology\n\n\nExplanation: - arrange() orders the rows based on the specified column. desc() is used to sort in descending order.\n\n\n3.2.4 mutate(): Creating New Variables\nThe mutate() function creates new variables or modifies existing ones within a data frame.\n\n# Adding a new column for grade based on score\nstudents_df &lt;- students_df |&gt; mutate(Grade = ifelse(Score &gt;= 85, \"A\", \"B\"))\nstudents_df\n\n     Name Age Score     Major Grade\n1   Alice  20    85 Economics     A\n2     Bob  21    90   History     A\n3 Charlie  19    78   Biology     B\n\n\nExplanation: - mutate() adds a new column Grade, where students with a score of 85 or higher receive an “A” grade, and others receive a “B”.\n\n\n3.2.5 summarise() and group_by(): Summarizing Data\nThe summarise() function, used in conjunction with group_by(), allows you to compute summary statistics for groups of data.\n\n# Grouping by Major and calculating the average score for each group\nsummary_df &lt;- students_df |&gt;\n  group_by(Major) |&gt;\n  summarise(AverageScore = mean(Score))\nsummary_df\n\n# A tibble: 3 × 2\n  Major     AverageScore\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Biology             78\n2 Economics           85\n3 History             90\n\n\nExplanation: - group_by() groups the data by a specific variable (Major in this case). - summarise() calculates the mean score for each group.",
    "crumbs": [
      "Tutorials",
      "3. Introduction to Tidyverse"
    ]
  },
  {
    "objectID": "tutorial/03-content.html#exercises-and-solutions",
    "href": "tutorial/03-content.html#exercises-and-solutions",
    "title": "Tutorial 3: Introduction to Tidyverse and the Base Pipe",
    "section": "Exercises and Solutions",
    "text": "Exercises and Solutions\n\nExercise 1: Selecting and Filtering Data\n\nUsing the students_df data frame, select only the Name and Major columns.\nFilter the data to include only students who are majoring in “Economics”.\n\nSolution:\n\n# Step 1: Selecting Name and Major columns\nselected_df &lt;- students_df |&gt; \n  select(Name, Major)\n\n# Step 2: Filtering students majoring in Economics\neconomics_students_df &lt;- selected_df |&gt; \n  filter(Major == \"Economics\")\n\neconomics_students_df\n\n   Name     Major\n1 Alice Economics\n\n\n\n\nExercise 2: Arranging and Mutating Data\n\nArrange the students_df data frame by Age in ascending order.\nAdd a new column called AgeGroup that categorizes students as “Young” (Age &lt;= 20) or “Mature” (Age &gt; 20).\n\nSolution:\n\n# Step 1: Arranging by Age\narranged_df &lt;- students_df |&gt; \n  arrange(Age)\n\n# Step 2: Adding AgeGroup column\nstudents_df &lt;- students_df |&gt;\n  mutate(AgeGroup = ifelse(Age &lt;= 20, \"Young\", \"Mature\"))\n\n\n\nExercise 3: Summarizing Data by Group\n\nGroup the students_df data frame by Major.\nCalculate the total number of students and the average score for each Major.\n\nSolution:\n\n# Step 1: Grouping by Major\ngrouped_df &lt;- students_df |&gt; \n  group_by(Major)\n\n# Step 2: Summarising total students and average score\nsummary_df &lt;- grouped_df |&gt;\n  summarise(\n    TotalStudents = n(),\n    AverageScore = mean(Score)\n  )\n\n\n\nExercise 4: Combining dplyr Functions\n\nUsing students_df, filter for students with a score greater than 80, then select their Name and Score.\nArrange the result by Score in descending order.\n\nSolution:\n\n# Combining filter, select, and arrange\nresult_df &lt;- students_df |&gt;\n  filter(Score &gt; 80) |&gt;\n  select(Name, Score) |&gt;\n  arrange(desc(Score))\n\n\n\nExercise 5: Applying Multiple Transformations\n\nCreate a new data frame by selecting Name, Score, and Major from students_df.\nFilter out students with a score less than 80.\nAdd a column Pass indicating whether the student passed (Score &gt;= 85).\nArrange the result by Major and Score.\n\nSolution:\n\n# Applying multiple transformations\nfinal_df &lt;- students_df |&gt;\n  select(Name, Score, Major) |&gt;\n  filter(Score &gt;= 80) |&gt;\n  mutate(Pass = Score &gt;= 85) |&gt;\n  arrange(Major, desc(Score))",
    "crumbs": [
      "Tutorials",
      "3. Introduction to Tidyverse"
    ]
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#wrangling-your-data-recap",
    "href": "2024/weeks/week02/slides02.html#wrangling-your-data-recap",
    "title": "Week 02Tidy Data and Visualization",
    "section": "Wrangling your data {Recap}",
    "text": "Wrangling your data {Recap}\n\n\nYou are highly encouraged to read through Hadley Wickham’s chapter. It’s clear and concise.\nAlso check out this great “cheatsheet” here.\nThe package is organized around a set of verbs, i.e. actions to be taken.\nAll verbs work as follows:\n\n\\[\\text{verb}(\\underbrace{\\text{data.frame}}_{\\text{1st argument}}, \\underbrace{\\text{what to do}}_\\text{2nd argument})\\]\n\nAlternatively you can (should) use the pipe operator %&gt;%:\n\n\\[\\underbrace{\\text{data.frame}}_{\\text{1st argument}} \\underbrace{\\text{ %&gt;% }}_{\\text{\"pipe\" operator}} \\text{verb}(\\underbrace{\\text{what to do}}_\\text{2nd argument})\\]"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#tidy-data",
    "href": "2024/weeks/week02/slides02.html#tidy-data",
    "title": "Week 02Tidy Data and Visualization",
    "section": "Tidy data",
    "text": "Tidy data\n\nIn most cases, your datasets won’t be tidy.\n\n\nTidy data: A dataset is said to be tidy if it satisfies the following conditions:"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#untidy-data-is-pretty-common",
    "href": "2024/weeks/week02/slides02.html#untidy-data-is-pretty-common",
    "title": "Week 02Tidy Data and Visualization",
    "section": "Untidy data is pretty common",
    "text": "Untidy data is pretty common\n\n\n\n\n\nHowever, storing data in wide form is easier to display in a printed table."
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section",
    "href": "2024/weeks/week02/slides02.html#section",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "Tidy datais data inlong format"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#what-makes-a-great-visualization",
    "href": "2024/weeks/week02/slides02.html#what-makes-a-great-visualization",
    "title": "Week 02Tidy Data and Visualization",
    "section": "What makes a great visualization?",
    "text": "What makes a great visualization?\n\nTruthful\nFunctional\nBeautiful\nInsightful\nEnlightening\nAlberto Cairo, The Truthful Art"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#how-do-we-express-visuals-in-words",
    "href": "2024/weeks/week02/slides02.html#how-do-we-express-visuals-in-words",
    "title": "Week 02Tidy Data and Visualization",
    "section": "How do we express visuals in words?",
    "text": "How do we express visuals in words?\n\nData to be visualized\nGeometric objects that appear on the plot\nAesthetic mappings from data to visual component\nStatistics transform data on the way to visualization\nCoordinates organize location of geometric objects\nScales define the range of values for aesthetics\nFacets group into subplots"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#what-makes-a-great-visualization-1",
    "href": "2024/weeks/week02/slides02.html#what-makes-a-great-visualization-1",
    "title": "Week 02Tidy Data and Visualization",
    "section": "What makes a great visualization?",
    "text": "What makes a great visualization?\n\nGood aesthetics\nNo substantive issues\nNo perceptual issues\nHonesty + good judgment\nKieran Healy, Data Visualization: A Practical Introduction"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#you-see-bad-plots-everywhere-whats-wrong",
    "href": "2024/weeks/week02/slides02.html#you-see-bad-plots-everywhere-whats-wrong",
    "title": "Week 02Tidy Data and Visualization",
    "section": "You see bad plots everywhere: What’s wrong?",
    "text": "You see bad plots everywhere: What’s wrong?"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#is-this-right",
    "href": "2024/weeks/week02/slides02.html#is-this-right",
    "title": "Week 02Tidy Data and Visualization",
    "section": "Is this right?",
    "text": "Is this right?"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#ggplot",
    "href": "2024/weeks/week02/slides02.html#ggplot",
    "title": "Week 02Tidy Data and Visualization",
    "section": "ggplot",
    "text": "ggplot\n\n\n\nFor this session, you’ll use the ggplot2 package from the tidyverse meta-package.\n\nSo, you can just load the tidyverse package when using ggplot.\n\n\n\n\n\nConsistency with the Grammar of Graphics\n\nThis book is the foundation of several data viz applications: ggplot2, polaris-tableau, vega-lite\n\nFlexibility\nLayering and theme customization\nCommunity\n\nIt is a powerful and easy to use tool (once you understand its logic) that produces complex and multifaceted plots."
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#ggplot2-basic-structure-template",
    "href": "2024/weeks/week02/slides02.html#ggplot2-basic-structure-template",
    "title": "Week 02Tidy Data and Visualization",
    "section": "ggplot2: basic structure (template)",
    "text": "ggplot2: basic structure (template)\nThe basic ggplot structure is:\nggplot(data = DATA) +\n  GEOM_FUNCTION(mapping = aes(AESTHETIC MAPPINGS))\n\nMapping data to aesthetics\n\n\nThink about colors, sizes, x and y references\n\n\nWe are going to learn how we connect our data to the components of a ggplot.\n\n\nI usually code like this:\nDATA |&gt; \n  ggplot(aes(AESTHETIC MAPPINGS)) +\n  GEOM_FUNCTION()"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#mapping",
    "href": "2024/weeks/week02/slides02.html#mapping",
    "title": "Week 02Tidy Data and Visualization",
    "section": "Mapping",
    "text": "Mapping\n\nMappings do not directly specify the particular, e.g., colors, shapes, or line styles that will appear on the plot.\nRather, they establish which variables in the data will be represented by which visible elements on the plot."
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#ggplot2-full-structure",
    "href": "2024/weeks/week02/slides02.html#ggplot2-full-structure",
    "title": "Week 02Tidy Data and Visualization",
    "section": "ggplot2: full structure",
    "text": "ggplot2: full structure\n\n\nggplot(data = &lt;DATA&gt;) +\n  &lt;GEOM_FUNCTION&gt;(\n     mapping = aes(&lt;MAPPINGS&gt;),\n     stat = &lt;STAT&gt;,\n     position = &lt;POSITION&gt;\n  ) +z\n  &lt;COORDINATE_FUNCTION&gt; +\n  &lt;FACET_FUNCTION&gt; +\n  &lt;SCALE_FUNTION&gt; +\n  &lt;THEME_FUNCTION&gt;\n\n\n\n\nData: The data that you want to visualize\nLayers: geom_ and stat_ → The geometric shapes and statistical summaries representing the data\nAesthetics: aes() → Aesthetic mappings of the geometric and statistical objects\nScales: scale_ → Maps between the data and the aesthetic dimensions\nCoordinate system: coord_ → Maps data into the plane of the data rectangle\nFacets: facet_ → The arrangement of the data into a grid of plots\nVisual themes: theme() and theme_ → The overall visual defaults of a plot"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#ggplot2-decomposition",
    "href": "2024/weeks/week02/slides02.html#ggplot2-decomposition",
    "title": "Week 02Tidy Data and Visualization",
    "section": "ggplot2: decomposition",
    "text": "ggplot2: decomposition\n\n\nThere are multiple ways to structure plots with ggplot\n\nFor this presentation, I will stick to Thomas Lin Pedersen’s decomposition who is one of most prominent developers of the ggplot and gganimate package.These components can be seen as layers, this is why we use the + sign in our ggplot syntax."
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#exploratory-analysis",
    "href": "2024/weeks/week02/slides02.html#exploratory-analysis",
    "title": "Week 02Tidy Data and Visualization",
    "section": "Exploratory Analysis",
    "text": "Exploratory Analysis\nThe most common geoms are:\n\n\ngeom_bar(), geom_col(): bar charts.\ngeom_boxplot(): box and whiskers plots.\ngeom_density(): density estimates.\ngeom_jitter(): jittered points.\ngeom_line(): line plots.\ngeom_point(): scatter plots.\n\n\n\nIf you want to know more about layers, you can refer to this."
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#step-by-step-from-garrick-aden-buies-gentle-guide",
    "href": "2024/weeks/week02/slides02.html#step-by-step-from-garrick-aden-buies-gentle-guide",
    "title": "Week 02Tidy Data and Visualization",
    "section": "Step by step from Garrick Aden-Buie’s gentle guide",
    "text": "Step by step from Garrick Aden-Buie’s gentle guide\nUsing the gapminder package, let’s start with lifeExp vs gdpPercap\n\nglimpse(gapminder)\n\nRows: 1,704\nColumns: 6\n$ country   &lt;fct&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", …\n$ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, …\n$ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, …\n$ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8…\n$ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12…\n$ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, …"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-2",
    "href": "2024/weeks/week02/slides02.html#section-2",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) \n\n\n\n\n\n\n\n\n\nThe Canvas"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-3",
    "href": "2024/weeks/week02/slides02.html#section-3",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = gdpPercap\n  )\n\n\n\n\n\n\n\n\n\nThe Canvas"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-4",
    "href": "2024/weeks/week02/slides02.html#section-4",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = gdpPercap,\n    y = lifeExp\n  )\n\n\n\n\n\n\n\n\n\nLet’s add points…"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-5",
    "href": "2024/weeks/week02/slides02.html#section-5",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = gdpPercap,\n    y = lifeExp\n  ) + \n  geom_point() \n\n\n\n\n\n\n\n\n\nHow can I tell countries apart? GDP is squished together on the left"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-6",
    "href": "2024/weeks/week02/slides02.html#section-6",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = gdpPercap,\n    y = lifeExp\n  ) + \n  geom_point() +\n  scale_x_log10()\n\n\n\n\n\n\n\n\n\nStill lots of overlap in the countries…"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-7",
    "href": "2024/weeks/week02/slides02.html#section-7",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = gdpPercap,\n    y = lifeExp,\n    color = continent\n  ) +\n  geom_point() +\n  scale_x_log10() +\n  facet_wrap(~ continent) +\n  guides(color = FALSE)    \n\n\n\n\n\n\n\n\n\nNo need for color legend thanks to facet titles.\nLots of overplotting due to point size."
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-8",
    "href": "2024/weeks/week02/slides02.html#section-8",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = gdpPercap,\n    y = lifeExp,\n    color = continent\n  ) +\n  geom_point(size = 0.25) + \n  scale_x_log10() +\n  facet_wrap(~ continent) +\n  guides(color = FALSE)\n\n\n\n\n\n\n\n\n\nIs there a trend?"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-9",
    "href": "2024/weeks/week02/slides02.html#section-9",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = gdpPercap,\n    y = lifeExp,\n    color = continent\n  ) +\n  geom_line() + #&lt;&lt;\n  geom_point(size = 0.25) +\n  scale_x_log10() +\n  facet_wrap(~ continent) +\n  guides(color = FALSE)\n\n\n\n\n\n\n\n\n\nOkay, that line just connected all of the points sequentially…"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-10",
    "href": "2024/weeks/week02/slides02.html#section-10",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = gdpPercap,\n    y = lifeExp,\n    color = continent\n  ) +\n  geom_line(\n    aes(group = country)\n  ) +\n  geom_point(size = 0.25) +\n  scale_x_log10() +\n  facet_wrap(~ continent) +\n  guides(color = FALSE)\n\n\n\n\n\n\n\n\n\nOh no! Too confusing!"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#section-11",
    "href": "2024/weeks/week02/slides02.html#section-11",
    "title": "Week 02Tidy Data and Visualization",
    "section": "",
    "text": "ggplot(gapminder) +\n  aes(\n    x = year,\n    y = lifeExp,\n    color = continent\n  ) +\n  geom_line(\n    aes(group = country)\n  ) +\n  geom_point(size = 0.25) +\n  scale_y_log10() +\n  facet_wrap(~ continent) +\n  guides(color = FALSE)\n\n\n\n\n\n\n\n\n\nLet’s add year in our x-axis instead of gdp!"
  },
  {
    "objectID": "2024/weeks/week02/slides02.html#our-goal",
    "href": "2024/weeks/week02/slides02.html#our-goal",
    "title": "Week 02Tidy Data and Visualization",
    "section": "Our goal",
    "text": "Our goal"
  }
]