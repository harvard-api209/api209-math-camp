[
  {
    "objectID": "labs/02-labs.html",
    "href": "labs/02-labs.html",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "",
    "text": "In this lab session, you’ll work with a dataset containing information about PISA data. The data comes from the learningtower package. Throughout the lab, you will use the following R functions to achieve the final visualization: filter(), group_by(), summarise(), pivot_longer(), mutate(), ggplot(), aes(), geom_line(), geom_point(), facet_wrap(), scale_y_continuous(), labs(), and theme_minimal().\n\n\nThe dataset contains the following variables:\n\nyear: Year of the PISA data. Factor.\ncountry: Country 3-character code. Note that some regions/territories are coded as country for ease of input. Factor.\nschool_id: The school identification number, unique for each country and year combination. Factor.\nstudent_id: The student identification number, unique for each school, country, and year combination. Factor.\nmother_educ: Highest level of mother’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\nfather_educ: Highest level of father’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\ngender: Gender of the student. Only “male” and “female” are recorded. Factor. Note that we call this variable gender and not sex as this term was used in the OECD PISA database.\ncomputer: Possession of a computer. Only “yes” and “no” are recorded. Factor.\ninternet: Access to the internet. Only “yes” and “no” are recorded. Factor.\nmath: Simulated score in mathematics. Numeric.\nread: Simulated score in reading. Numeric.\nscience: Simulated score in science. Numeric.\nstu_wgt: The final survey weight score for the student. Numeric.\ndesk: Possession of a desk to study at. Only “yes” and “no” are recorded. Factor.\nroom: Possession of a room of your own. Only “yes” and “no” are recorded. Factor.\ndishwasher: Possession of a dishwasher. Only “yes” and “no” are recorded. Factor. Note that in 2015 and 2018, all entries are missing.\ntelevision: Number of televisions. “0”, “1”, “2” are coded for no, one, and two TVs in the house. “3+” codes for three or more TVs. Factor. Note that in 2003, all entries are missing.\ncomputer_n: Number of computers. “0”, “1”, “2” are coded for no, one, and two computers in the house. “3+” codes for three or more computers. Factor. Note that in 2003, all entries are missing.\ncar: Number of cars. “0”, “1”, “2” are coded for no, one, and two cars in the house. “3+” codes for three or more cars. Factor. Note that in 2003, all entries are missing.\nbook: Number of books. Factor. Note that encoding is different in the years 2000 and 2003 compared to all other years. Evaluate table(student$book, student$year) for a demo.\nwealth: Family wealth. Numeric. Note that in 2003, all entries are missing.\nescs: Index of economic, social, and cultural status. Numeric.",
    "crumbs": [
      "Labs",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "labs/02-labs.html#description-of-the-dataset",
    "href": "labs/02-labs.html#description-of-the-dataset",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "",
    "text": "The dataset contains the following variables:\n\nyear: Year of the PISA data. Factor.\ncountry: Country 3-character code. Note that some regions/territories are coded as country for ease of input. Factor.\nschool_id: The school identification number, unique for each country and year combination. Factor.\nstudent_id: The student identification number, unique for each school, country, and year combination. Factor.\nmother_educ: Highest level of mother’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\nfather_educ: Highest level of father’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\ngender: Gender of the student. Only “male” and “female” are recorded. Factor. Note that we call this variable gender and not sex as this term was used in the OECD PISA database.\ncomputer: Possession of a computer. Only “yes” and “no” are recorded. Factor.\ninternet: Access to the internet. Only “yes” and “no” are recorded. Factor.\nmath: Simulated score in mathematics. Numeric.\nread: Simulated score in reading. Numeric.\nscience: Simulated score in science. Numeric.\nstu_wgt: The final survey weight score for the student. Numeric.\ndesk: Possession of a desk to study at. Only “yes” and “no” are recorded. Factor.\nroom: Possession of a room of your own. Only “yes” and “no” are recorded. Factor.\ndishwasher: Possession of a dishwasher. Only “yes” and “no” are recorded. Factor. Note that in 2015 and 2018, all entries are missing.\ntelevision: Number of televisions. “0”, “1”, “2” are coded for no, one, and two TVs in the house. “3+” codes for three or more TVs. Factor. Note that in 2003, all entries are missing.\ncomputer_n: Number of computers. “0”, “1”, “2” are coded for no, one, and two computers in the house. “3+” codes for three or more computers. Factor. Note that in 2003, all entries are missing.\ncar: Number of cars. “0”, “1”, “2” are coded for no, one, and two cars in the house. “3+” codes for three or more cars. Factor. Note that in 2003, all entries are missing.\nbook: Number of books. Factor. Note that encoding is different in the years 2000 and 2003 compared to all other years. Evaluate table(student$book, student$year) for a demo.\nwealth: Family wealth. Numeric. Note that in 2003, all entries are missing.\nescs: Index of economic, social, and cultural status. Numeric.",
    "crumbs": [
      "Labs",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "labs/02-labs.html#extra-exercises",
    "href": "labs/02-labs.html#extra-exercises",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "Extra exercises",
    "text": "Extra exercises\n\nExercise 8: Customizing the Plot\nExperiment with different themes and color palettes to make the plot more visually appealing.\n\n\nExercise 9: Adding Context to the Visualization\nAdd annotations or text to the plot to highlight significant events or changes in the data.",
    "crumbs": [
      "Labs",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "resource/colors.html",
    "href": "resource/colors.html",
    "title": "Color palettes",
    "section": "",
    "text": "When choosing colors, you need to make sure you work with a palette that mathches the nature of your data. There are three broad categories of color-able data: sequential, diverging, and qualitative.\nHere’s are three plots I’ll use throughout this page to illustrate their differences (and show off different colors). The code is hidden to save space—you can show the code and copy/paste it if you want to follow along:\n\n\nCode\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(palmerpenguins)\nlibrary(ggokabeito)\nlibrary(scico)\nlibrary(rcartocolor)\nlibrary(MetBrewer)\nlibrary(MoMAColors)\nlibrary(patchwork)\n\nplot_diverging &lt;- tribble(\n  ~category, ~pct,\n  \"Strongly disagree\", 0.12,\n  \"Disagree\", 0.18,\n  \"Neutral\", 0.15,\n  \"Agree\", 0.27,\n  \"Strongly agree\", 0.28\n) |&gt;\n  mutate(category = fct_inorder(category)) |&gt;\n  ggplot(aes(x = pct, y = category, fill = category)) +\n  geom_col() +\n  guides(fill = \"none\") +\n  theme_bw() +\n  theme(plot.title = element_text(face = \"bold\"))\n\nplot_sequential &lt;- penguins |&gt;\n  drop_na(sex) |&gt;\n  ggplot(aes(x = bill_length_mm, y = body_mass_g, color = flipper_length_mm)) +\n  geom_point() +\n  theme_bw() +\n  theme(plot.title = element_text(face = \"bold\"))\n\nplot_qualitative &lt;- gapminder |&gt;\n  filter(year %in% c(1967, 1987, 2007)) |&gt;\n  group_by(year, continent) |&gt;\n  summarize(avg_lifexp = mean(lifeExp)) |&gt;\n  mutate(year = factor(year)) |&gt;\n  ggplot(aes(x = year, y = avg_lifexp, fill = continent)) +\n  geom_col(position = \"dodge\") +\n  theme_bw() +\n  theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\nWith sequential data, colors represent a range from low value to a high value, so the colors either stay within one shade or hue of a color, or use multiple related hues\n\nDefault single blue hueMultiple red-purple hues (RdPu from ColorBrewer)\n\n\n\nplot_sequential\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\n\nplot_sequential +\n  scale_color_distiller(palette = \"RdPu\", direction = 1)\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\n\n\n\n\n\nWith diverging data, colors represent values above and below some central value, like negative to zero to positive; disagree to neutral to agree; etc. These palettes typically involve three colors: two for the extremes and one for the middle\n\nDefault ggplot colorsDiverging red-yellow-blue palette (RdYlBu from ColorBrewer)\n\n\nBy default, ggplot doesn’t actually do anything with diverging scales. If you have numeric data, it’ll use a blue gradient; if you have categorical data, it’ll use distinct colors. You’re in charge of applying a diverging palette.\n\n# This doesn't show up as diverging\nplot_diverging\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\n\nplot_diverging +\n  scale_fill_brewer(palette = \"RdYlBu\", direction = 1)\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDon’t use diverging palettes for non-diverging data!\n\n\n\nPeople will often throw diverging palettes onto plots that aren’t actually diverging, like this:\n\nplot_sequential +\n  scale_color_distiller(palette = \"RdBu\", direction = 1)\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\nDon’t do this! It looks weird having 200 be a super-faded middle color. Flipper length here ranges from a low number to a high number—the colors should reflect that.\n\n\n\n\n\nWith qualitative data, colors represent distinct categories and don’t have an inherent order. The colors shouldn’t look like they have a natural progression.\n\nDefault ggplot colorsviridis colors\n\n\n\nplot_qualitative\n\n\n\n\n\n\n\nFigure 6\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\nFigure 7",
    "crumbs": [
      "Resources",
      "Color palettes"
    ]
  },
  {
    "objectID": "resource/colors.html#categories-of-color-palettes",
    "href": "resource/colors.html#categories-of-color-palettes",
    "title": "Color palettes",
    "section": "",
    "text": "When choosing colors, you need to make sure you work with a palette that mathches the nature of your data. There are three broad categories of color-able data: sequential, diverging, and qualitative.\nHere’s are three plots I’ll use throughout this page to illustrate their differences (and show off different colors). The code is hidden to save space—you can show the code and copy/paste it if you want to follow along:\n\n\nCode\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(palmerpenguins)\nlibrary(ggokabeito)\nlibrary(scico)\nlibrary(rcartocolor)\nlibrary(MetBrewer)\nlibrary(MoMAColors)\nlibrary(patchwork)\n\nplot_diverging &lt;- tribble(\n  ~category, ~pct,\n  \"Strongly disagree\", 0.12,\n  \"Disagree\", 0.18,\n  \"Neutral\", 0.15,\n  \"Agree\", 0.27,\n  \"Strongly agree\", 0.28\n) |&gt;\n  mutate(category = fct_inorder(category)) |&gt;\n  ggplot(aes(x = pct, y = category, fill = category)) +\n  geom_col() +\n  guides(fill = \"none\") +\n  theme_bw() +\n  theme(plot.title = element_text(face = \"bold\"))\n\nplot_sequential &lt;- penguins |&gt;\n  drop_na(sex) |&gt;\n  ggplot(aes(x = bill_length_mm, y = body_mass_g, color = flipper_length_mm)) +\n  geom_point() +\n  theme_bw() +\n  theme(plot.title = element_text(face = \"bold\"))\n\nplot_qualitative &lt;- gapminder |&gt;\n  filter(year %in% c(1967, 1987, 2007)) |&gt;\n  group_by(year, continent) |&gt;\n  summarize(avg_lifexp = mean(lifeExp)) |&gt;\n  mutate(year = factor(year)) |&gt;\n  ggplot(aes(x = year, y = avg_lifexp, fill = continent)) +\n  geom_col(position = \"dodge\") +\n  theme_bw() +\n  theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\nWith sequential data, colors represent a range from low value to a high value, so the colors either stay within one shade or hue of a color, or use multiple related hues\n\nDefault single blue hueMultiple red-purple hues (RdPu from ColorBrewer)\n\n\n\nplot_sequential\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\n\nplot_sequential +\n  scale_color_distiller(palette = \"RdPu\", direction = 1)\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\n\n\n\n\n\nWith diverging data, colors represent values above and below some central value, like negative to zero to positive; disagree to neutral to agree; etc. These palettes typically involve three colors: two for the extremes and one for the middle\n\nDefault ggplot colorsDiverging red-yellow-blue palette (RdYlBu from ColorBrewer)\n\n\nBy default, ggplot doesn’t actually do anything with diverging scales. If you have numeric data, it’ll use a blue gradient; if you have categorical data, it’ll use distinct colors. You’re in charge of applying a diverging palette.\n\n# This doesn't show up as diverging\nplot_diverging\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\n\nplot_diverging +\n  scale_fill_brewer(palette = \"RdYlBu\", direction = 1)\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDon’t use diverging palettes for non-diverging data!\n\n\n\nPeople will often throw diverging palettes onto plots that aren’t actually diverging, like this:\n\nplot_sequential +\n  scale_color_distiller(palette = \"RdBu\", direction = 1)\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\nDon’t do this! It looks weird having 200 be a super-faded middle color. Flipper length here ranges from a low number to a high number—the colors should reflect that.\n\n\n\n\n\nWith qualitative data, colors represent distinct categories and don’t have an inherent order. The colors shouldn’t look like they have a natural progression.\n\nDefault ggplot colorsviridis colors\n\n\n\nplot_qualitative\n\n\n\n\n\n\n\nFigure 6\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\nFigure 7",
    "crumbs": [
      "Resources",
      "Color palettes"
    ]
  },
  {
    "objectID": "resource/colors.html#using-custom-colors",
    "href": "resource/colors.html#using-custom-colors",
    "title": "Color palettes",
    "section": "Using custom colors",
    "text": "Using custom colors\nYou can use any custom colors with scale_fill_manual()/scale_color_manual() (for qualitative/categorical colors) or scale_fill_gradident()/scale_color_gradient() (for sequential/continuous colors).\nFeed these functions a vector of colors, either as named colors like ■red, ■goldenrod3, ■midnightblue, and so on (see here for R’s huge list of built-in color names), or as hex codes like ■#FF4136, ■#0074D9, and ■#FF851B.\n\nHex colorsNamed colors in a gradient\n\n\nI copied these colors from clrs.cc.\n\nplot_qualitative +\n  scale_fill_manual(\n    values = c(\"#0074D9\", \"#B10DC9\", \"#85144b\", \"#FF4136\", \"#FF851B\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nplot_sequential +\n  scale_color_gradient(low = \"chocolate1\", high = \"chocolate4\")\n\n\n\n\n\n\n\n\n\n\n\nOften organizations have specific color palettes that you’re supposed to use. For instance, GSU has a special “Georgia State Blue” (■#0039A6) and a red accent (■#CC0000). The Urban Institute has a specific organizational color palette with all sorts of guidelines for comparing two groups, three groups, sequential data, diverging data, and other special situations. They have specific red and blue colors to use for political parties too, like ■#1696d2 for Democrats and ■#db2b27 for Republicans.\nI often find it helpful to make a little object that contains all the custom colors I want to use so I don’t have to remember what the cryptic hex codes mean. Here’s GSU’s full palette:\n\ngsu_colors &lt;- c(\n  \"#0039A6\", \"#CC0000\", \"#374057\", \"#0071CE\",\n  \"#00AEEF\", \"#97CAEB\", \"#EEEEEE\", \"#CCCCCC\", \"#767679\"\n)\n\nYou can access these colors by number:\n\ngsu_colors[1:2]\n## [1] \"#0039A6\" \"#CC0000\"\ngsu_colors[5]\n## [1] \"#00AEEF\"\ngsu_colors[c(3, 5, 9)]\n## [1] \"#374057\" \"#00AEEF\" \"#767679\"\n\nAnd you can use the show_col() function from the {scales} library to show them all:\n\nscales::show_col(gsu_colors)\n\n\n\n\n\n\n\n\nYou can use them in scale_fill_manual()/scale_color_manual() too:\n\nplot_qualitative +\n  scale_fill_manual(\n    values = gsu_colors[1:5]\n  )\n\n\n\n\n\n\n\n\nIf you want to be extra fancy, you can create more official custom color palettes like scale_fill_gsu().",
    "crumbs": [
      "Resources",
      "Color palettes"
    ]
  },
  {
    "objectID": "resource/colors.html#perceptually-uniform-and-scientifically-calibrated-palettes",
    "href": "resource/colors.html#perceptually-uniform-and-scientifically-calibrated-palettes",
    "title": "Color palettes",
    "section": "Perceptually uniform and scientifically calibrated palettes",
    "text": "Perceptually uniform and scientifically calibrated palettes\nYou aren’t limited to just the default ggplot color palettes, or even the default viridis palettes. There are lots of other perceptually uniform palettes that use special ranges of color that can either (1) be used as a sequential gradient or (2) be chopped up into equal distances to create recognizable distinct colors.\n\nThe Okabe-Ito palette\nMasataka Okabe and Kei Ito developed a qualitative color palette for all types of color-vision deficiencies in 2008, and Claus Wilke uses it throughout his Fundamentals of Data Visualization book that we use in this class (he explains why here).\n\nYou can use it with the {ggokabeito} package and scale_fill_okabe_ito()/scale_color_okabe_ito():\n\nplot_qualitative +\n  scale_fill_okabe_ito()\n\n\n\n\n\n\n\n\n\n\nviridis\nYou’ve seen the regular green/blue/yellow viridis palette throughout the class, but there are are a bunch of other palettes within viridis like magma, plasma, inferno, mako, rocket, and turbo.\n\n\n\n\n\nNone of the viridis palettes are diverging, but they work great for both sequential and qualitative data.\nThe viridis palettes come with {ggplot2} and you can use them with scale_fill_viridis_d()/scale_color_viridis_d() for discrete data and scale_fill_viridis_c()/scale_color_viridis_c() for continuous data.\n\nplasmainfernomakoturbo\n\n\n\nplot_qualitative +\n  scale_fill_viridis_d(option = \"plasma\")\n\n\n\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_viridis_d(option = \"inferno\")\n\n\n\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_viridis_d(option = \"mako\")\n\n\n\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_viridis_d(option = \"turbo\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nScientific colour maps\nThe {scico} package provides a ton of other similar well-designed palettes from the Scientific Colour Maps project. The project includes sequential, diverging, and qualitative palettes and even has multi-sequential and cyclic palettes.\n\nAfter loading the {scico} package, you can use these palettes with scale_fill_scico_d()/scale_color_scico_d() for discrete data and scale_fill_scico_c()/scale_color_scico_c() for continuous data.\n\nbatlowbamakohawaiiroma (diverging)broc (diverging)\n\n\n\nplot_qualitative +\n  scale_fill_scico_d(palette = \"batlow\")\n\n\n\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_scico_d(palette = \"bamako\")\n\n\n\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_scico_d(palette = \"hawaii\")\n\n\n\n\n\n\n\n\n\n\n\nplot_diverging +\n  scale_fill_scico_d(palette = \"roma\")\n\n\n\n\n\n\n\n\n\n\n\nplot_diverging +\n  scale_fill_scico_d(palette = \"broc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nColorBrewer\nGeographer Cynthia Brewer developed a set of color palettes designed specifically for improving the readability of maps, but her palettes work incredibly well for regular plots too. There’s also a fantastic companion website for exploring all the different palettes, categories by sequential/diverging/qualitatitve, with options to filter by colorblind friendliness and print friendliness.\n\nTo use one of the palettes, note what it’s called at the website and use that name as the palette argument. The ColorBrewer palettes come with {ggplot2} and you can use them with scale_fill_brewer()/scale_color_brewer() for discrete data and scale_fill_distiller()/scale_color_distiller() for continuous data.\n\nYlOrRd (sequential)PuOr (diverging)Set1 (qualitative)\n\n\n\nplot_sequential +\n  scale_color_distiller(palette = \"YlOrRd\")\n\n\n\n\n\n\n\n\n\n\n\nplot_diverging +\n  scale_fill_brewer(palette = \"PuOr\")\n\n\n\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCARTOColors\nThe commerical GIS service CARTO created CARTOColors: a set of open source geographic-like colors just like ColorBrewer. Again, these were originally designed for maps, but they work great for regular data visualization too.\n\n\n\n\n\nYou’ll need to install the {rcartocolor} package to use them. After loading {rcartocolor}, you can use any of the palettes with scale_fill_carto_d()/scale_color_carto_d() for discrete data and scale_fill_carto_c()/scale_color_carto_c() for continuous data. Use the name of the palette at the CARTOColors website in the palette argument.\n\nPurpOr (sequential)Temps (diverging)Prism (qualitative)\n\n\n\nplot_sequential +\n  scale_color_carto_c(palette = \"PurpOr\")\n\n\n\n\n\n\n\n\n\n\n\nplot_diverging +\n  scale_fill_carto_d(palette = \"Temps\", direction = -1)\n\n\n\n\n\n\n\n\n\n\n\n# Extract 5 colors from the Prism palette and use them with scale_fill_manual()\nclrs &lt;- carto_pal(12, \"Prism\")\n\nplot_qualitative +\n  scale_fill_manual(values = clrs[c(1, 4, 6, 7, 8)])",
    "crumbs": [
      "Resources",
      "Color palettes"
    ]
  },
  {
    "objectID": "resource/colors.html#fun-and-artsy-but-still-useful-palettes",
    "href": "resource/colors.html#fun-and-artsy-but-still-useful-palettes",
    "title": "Color palettes",
    "section": "Fun and artsy (but still useful!) palettes",
    "text": "Fun and artsy (but still useful!) palettes\nThere are also palettes that are hand-picked for beauty and/or fun. Not all of these are perceptually uniform or colorblind friendly, but they’re great for when you want to have pretty graphics that fit a certain vibe.\n\nLiteral art: {MetBrewer} and {MoMAColors}\nUse palettes inspired by works in the Metropolitan Museum of Art and the Museum of Modern Art in New York. There are sequential, diverging, and qualitative palettes, and many are marked as colorblind friendly in {MetBrewer} and {MoMAColors}\nUse them by putting met.brewer() or moma.colors() inside scale_fill_manual()/scale_color_manual() or scale_fill_gradientn()/scale_color_gradientn():\n\n{MetBrewer}\n\nOKeeffe2 (sequential)Hiroshige (diverging)Johnson (qualitative)\n\n\n\nplot_sequential +\n  scale_color_gradientn(colors = met.brewer(\"OKeeffe2\"))\n\n\n\n\n\n\n\n\n\n\n\n\n# Grab 5 of the middle colors from the palette\nclrs &lt;- met.brewer(\"Hiroshige\")\n\nplot_diverging +\n  scale_fill_manual(values = clrs[3:7])\n\n\n\n\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_manual(values = met.brewer(\"Johnson\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{MoMAColors}\n\nVanGogh (sequential)Kippenberger (diverging)ustwo (qualitative)\n\n\n\nplot_sequential +\n  scale_color_gradientn(colors = moma.colors(\"VanGogh\")[2:7])\n\n\n\n\n\n\n\n\n\n\n\n\n# Grab 5 of the middle colors from the palette\nclrs &lt;- moma.colors(\"Kippenberger\")\n\nplot_diverging +\n  scale_fill_manual(values = clrs[c(2, 4, 6, 8, 10)])\n\n\n\n\n\n\n\n\n\n\n\n\nplot_qualitative +\n  scale_fill_manual(values = moma.colors(\"ustwo\", 5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOther fun things\nThere are so many others. The {paletteer} package contains thousands of others—it’s like a central collection of every possible palette.\nYou can also access individual palettes without using {paletteer}, including these:\nMusic\n\n{tayloRswift}: Colors from all albums up through “The Tortured Poets Department”\n{beyonce}: 130 different palettes from beyoncepalettes.tumblr.com\n{rockthemes}: Janelle Monae, Muse, No Doubt, Red Hot Chili Peppers, etc.\n{popthemes}: Spice Girls, Aqua, No Doubt, etc.\n\nNational parks\n\n{nationalparkcolors}: Colors from 25 different US national parks\n{NatParksPalettes}: Colors from 30 different US and international national parks\n\nHistory\n\n{suffrager}: Colors from old suffragette posters\n{inauguration}: Colors from the 2021 presidential inauguration\n{ggpomological}: Colors from old drawings of fruit\n\nTV and movies\n\n{tvthemes}: Colors from a ton of TV shows, including The Simpsons, Parks & Recreation, Spongebob Squarepants, Game of Thrones, etc.\n{wesanderson}: Colors from Wes Anderson movies\n{trekcolors}: Colors from Star Trek\n{severance}: Colors from the Apple TV show Severance\n{ghibli}: Colors from Studio Ghibli movies\n{harrypotter}: Colors from Harry Potter movies\n\nOther things\n\n{nbapalettes}: Colors from NBA teams\n{LaCroixColoR}: Colors from La Croix cans",
    "crumbs": [
      "Resources",
      "Color palettes"
    ]
  },
  {
    "objectID": "resource/style.html",
    "href": "resource/style.html",
    "title": "R style suggestions",
    "section": "",
    "text": "R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\n\nmpg |&gt; \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg |&gt; filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg |&gt; \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\nBut you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times.",
    "crumbs": [
      "Resources",
      "R style suggestions"
    ]
  },
  {
    "objectID": "resource/style.html#r-style-conventions",
    "href": "resource/style.html#r-style-conventions",
    "title": "R style suggestions",
    "section": "",
    "text": "R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\n\nmpg |&gt; \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg |&gt; filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg |&gt; \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\nBut you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times.",
    "crumbs": [
      "Resources",
      "R style suggestions"
    ]
  },
  {
    "objectID": "resource/style.html#main-style-things-to-pay-attention-to-for-this-class",
    "href": "resource/style.html#main-style-things-to-pay-attention-to-for-this-class",
    "title": "R style suggestions",
    "section": "Main style things to pay attention to for this class",
    "text": "Main style things to pay attention to for this class\n\nImportant note: I won’t ever grade you on any of this! If you submit something like filter(mpg,cty&gt;10,class==\"compact\"), I might recommend adding spaces, but it won’t affect your grade or points or anything.\n\n\nSpacing\n\nSee the “Spacing” section in the tidyverse style guide.\n\nPut spaces after commas (like in regular English):\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter(mpg , cty &gt; 10)\nfilter(mpg ,cty &gt; 10)\nfilter(mpg,cty &gt; 10)\n\nPut spaces around operators like +, -, &gt;, =, etc.:\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter(mpg, cty&gt;10)\nfilter(mpg, cty&gt; 10)\nfilter(mpg, cty &gt;10)\n\nDon’t put spaces around parentheses that are parts of functions:\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter (mpg, cty &gt; 10)\nfilter ( mpg, cty &gt; 10)\nfilter( mpg, cty &gt; 10 )\n\n\n\nLong lines\n\nSee the “Long lines” section in the tidyverse style guide.\n\nIt’s generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters. Instead of counting characters by hand (ew), in RStudio go to “Tools” &gt; “Global Options” &gt; “Code” &gt; “Display” and check the box for “Show margin”. You should now see a really thin line indicating 80 characters. Again, you can go beyond this—that’s fine. It’s just good practice to avoid going too far past it.\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n\n# Good\nfilter(mpg, cty &gt; 10, class == \"compact\")\n\n# Good\nfilter(mpg, cty &gt; 10, \n       class == \"compact\")\n\n# Good\nfilter(mpg,\n       cty &gt; 10,\n       class == \"compact\")\n\n# Bad\nfilter(mpg, cty &gt; 10, class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \"suv\", \"2seater\", \"minivan\"))\n\n# Good\nfilter(mpg, \n       cty &gt; 10, \n       class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \n                    \"suv\", \"2seater\", \"minivan\"))\n\n\n\nPipes (|&gt;) and ggplot layers (+)\nPut each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n\n# Good\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth() +\n  theme_bw()\n\n# Bad\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() + geom_smooth() +\n  theme_bw()\n\n# Super bad\nggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw()\n\n# Super bad and won't even work\nggplot(mpg, aes(x = cty, y = hwy, color = class))\n  + geom_point()\n  + geom_smooth() \n  + theme_bw()\n\nPut each step in a dplyr pipeline on separate lines, with the |&gt; at the end of the line, indented with two spaces:\n\n# Good\nmpg |&gt; \n  filter(cty &gt; 10) |&gt; \n  group_by(class) |&gt; \n  summarize(avg_hwy = mean(hwy))\n\n# Bad\nmpg |&gt; filter(cty &gt; 10) |&gt; group_by(class) |&gt; \n  summarize(avg_hwy = mean(hwy))\n\n# Super bad\nmpg |&gt; filter(cty &gt; 10) |&gt; group_by(class) |&gt; summarize(avg_hwy = mean(hwy))\n\n# Super bad and won't even work\nmpg |&gt; \n  filter(cty &gt; 10)\n  |&gt; group_by(class)\n  |&gt; summarize(avg_hwy = mean(hwy))\n\n\n\nComments\n\nSee the “Comments” section in the tidyverse style guide.\n\nComments should start with a comment symbol and a single space: #\n\n# Good\n\n#Bad\n\n    #Bad\n\nIf the comment is really short (and won’t cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\n\nmpg |&gt; \n  filter(cty &gt; 10) |&gt;  # Only rows where cty is 10 +\n  group_by(class) |&gt;  # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\n\nYou can add extra spaces to get inline comments to align, if you want:\n\nmpg |&gt; \n  filter(cty &gt; 10) |&gt;            # Only rows where cty is 10 +\n  group_by(class) |&gt;             # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\n\nIf the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to “Code” &gt; “Reflow comment”\n\n# Good\n# Happy families are all alike; every unhappy family is unhappy in its own way.\n# Everything was in confusion in the Oblonskys’ house. The wife had discovered\n# that the husband was carrying on an intrigue with a French girl, who had been\n# a governess in their family, and she had announced to her husband that she\n# could not go on living in the same house with him. This position of affairs\n# had now lasted three days, and not only the husband and wife themselves, but\n# all the members of their family and household, were painfully conscious of it.\n\n# Bad\n# Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it.\n\nThough, if you’re dealing with comments that are that long, consider putting the text in Quarto instead and having it be actual prose.",
    "crumbs": [
      "Resources",
      "R style suggestions"
    ]
  },
  {
    "objectID": "example/02-lab-sol.html",
    "href": "example/02-lab-sol.html",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "",
    "text": "In this lab session, you’ll work with a dataset containing information about PISA data. The data comes from the learningtower package. Throughout the lab, you will use the following R functions to achieve the final visualization: filter(), group_by(), summarise(), pivot_longer(), mutate(), ggplot(), aes(), geom_line(), geom_point(), facet_wrap(), scale_y_continuous(), labs(), and theme_minimal().\n\n\nThe dataset contains the following variables:\n\nyear: Year of the PISA data. Factor.\ncountry: Country 3-character code. Note that some regions/territories are coded as country for ease of input. Factor.\nschool_id: The school identification number, unique for each country and year combination. Factor.\nstudent_id: The student identification number, unique for each school, country, and year combination. Factor.\nmother_educ: Highest level of mother’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\nfather_educ: Highest level of father’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\ngender: Gender of the student. Only “male” and “female” are recorded. Factor. Note that we call this variable gender and not sex as this term was used in the OECD PISA database.\ncomputer: Possession of a computer. Only “yes” and “no” are recorded. Factor.\ninternet: Access to the internet. Only “yes” and “no” are recorded. Factor.\nmath: Simulated score in mathematics. Numeric.\nread: Simulated score in reading. Numeric.\nscience: Simulated score in science. Numeric.\nstu_wgt: The final survey weight score for the student. Numeric.\ndesk: Possession of a desk to study at. Only “yes” and “no” are recorded. Factor.\nroom: Possession of a room of your own. Only “yes” and “no” are recorded. Factor.\ndishwasher: Possession of a dishwasher. Only “yes” and “no” are recorded. Factor. Note that in 2015 and 2018, all entries are missing.\ntelevision: Number of televisions. “0”, “1”, “2” are coded for no, one, and two TVs in the house. “3+” codes for three or more TVs. Factor. Note that in 2003, all entries are missing.\ncomputer_n: Number of computers. “0”, “1”, “2” are coded for no, one, and two computers in the house. “3+” codes for three or more computers. Factor. Note that in 2003, all entries are missing.\ncar: Number of cars. “0”, “1”, “2” are coded for no, one, and two cars in the house. “3+” codes for three or more cars. Factor. Note that in 2003, all entries are missing.\nbook: Number of books. Factor. Note that encoding is different in the years 2000 and 2003 compared to all other years. Evaluate table(student$book, student$year) for a demo.\nwealth: Family wealth. Numeric. Note that in 2003, all entries are missing.\nescs: Index of economic, social, and cultural status. Numeric."
  },
  {
    "objectID": "example/02-lab-sol.html#description-of-the-dataset",
    "href": "example/02-lab-sol.html#description-of-the-dataset",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "",
    "text": "The dataset contains the following variables:\n\nyear: Year of the PISA data. Factor.\ncountry: Country 3-character code. Note that some regions/territories are coded as country for ease of input. Factor.\nschool_id: The school identification number, unique for each country and year combination. Factor.\nstudent_id: The student identification number, unique for each school, country, and year combination. Factor.\nmother_educ: Highest level of mother’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\nfather_educ: Highest level of father’s education. Ranges from “less than ISCED1” to “ISCED 3A”. Factor. Note that in 2000, all entries are missing.\ngender: Gender of the student. Only “male” and “female” are recorded. Factor. Note that we call this variable gender and not sex as this term was used in the OECD PISA database.\ncomputer: Possession of a computer. Only “yes” and “no” are recorded. Factor.\ninternet: Access to the internet. Only “yes” and “no” are recorded. Factor.\nmath: Simulated score in mathematics. Numeric.\nread: Simulated score in reading. Numeric.\nscience: Simulated score in science. Numeric.\nstu_wgt: The final survey weight score for the student. Numeric.\ndesk: Possession of a desk to study at. Only “yes” and “no” are recorded. Factor.\nroom: Possession of a room of your own. Only “yes” and “no” are recorded. Factor.\ndishwasher: Possession of a dishwasher. Only “yes” and “no” are recorded. Factor. Note that in 2015 and 2018, all entries are missing.\ntelevision: Number of televisions. “0”, “1”, “2” are coded for no, one, and two TVs in the house. “3+” codes for three or more TVs. Factor. Note that in 2003, all entries are missing.\ncomputer_n: Number of computers. “0”, “1”, “2” are coded for no, one, and two computers in the house. “3+” codes for three or more computers. Factor. Note that in 2003, all entries are missing.\ncar: Number of cars. “0”, “1”, “2” are coded for no, one, and two cars in the house. “3+” codes for three or more cars. Factor. Note that in 2003, all entries are missing.\nbook: Number of books. Factor. Note that encoding is different in the years 2000 and 2003 compared to all other years. Evaluate table(student$book, student$year) for a demo.\nwealth: Family wealth. Numeric. Note that in 2003, all entries are missing.\nescs: Index of economic, social, and cultural status. Numeric."
  },
  {
    "objectID": "example/02-lab-sol.html#extra-exercises",
    "href": "example/02-lab-sol.html#extra-exercises",
    "title": "Lab 2: Tidy Data and Visualization in R – PISA",
    "section": "Extra exercises",
    "text": "Extra exercises\n\nExercise 8: Customizing the Plot\nExperiment with different themes and color palettes to make the plot more visually appealing.\n\n\nExercise 9: Adding Context to the Visualization\nAdd annotations or text to the plot to highlight significant events or changes in the data.\n\n\nExtra: Creating functions\n\nplot_pisa_scores &lt;- function(data, countries) {\n  data |&gt;\n    filter(country %in% countries) |&gt;\n    group_by(year, country) |&gt; \n    summarise(\n      math = weighted.mean(math, stu_wgt, na.rm = TRUE),\n      read = weighted.mean(read, stu_wgt, na.rm = TRUE),\n      science = weighted.mean(science, stu_wgt, na.rm = TRUE)\n    ) |&gt; \n    pivot_longer(cols = -c(year, country), values_to = \"score\", names_to = \"test\") |&gt;\n    mutate(test = str_to_title(test)) |&gt; \n    ggplot(\n      aes(\n        x = year, \n        y = score, \n        group = country, \n        color = country\n      )\n    ) + \n    geom_line() +\n    geom_point() + \n    facet_wrap(~ test) + \n    scale_y_continuous(limits = c(250, 800)) +\n    labs(\n      x = \"Year\",\n      y = \"Score\",\n      title = \"PISA Scores from 2000 - 2018\",\n      caption = \"Source: OECD\",\n      color = NULL\n    ) +\n    theme_minimal() +  \n    theme(\n      text = element_text(size = 12),\n      legend.position = \"bottom\",\n      axis.text.x = element_text(size = 8)\n    )\n}\n\n# Example usage:\nplot_pisa_scores(pisa_df, c(\"CAN\", \"USA\", \"MEX\"))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "handson/02-handson.html",
    "href": "handson/02-handson.html",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "",
    "text": "STOP: Super important warning!\n\n\n\n\nIf you didn’t complete the summer assignments, you should definitely make time to do complete the following primers. The original content is coming from RStudio and was adapted by Prof. Andrew Heiss.\n\nFor the first part of this week’s lesson, you need to work through a few of Posit’s introductory primers. You’ll do these in your browser, where you can type code and see results immediately.\nYou’ll learn some of the basics of R, as well as some powerful methods for manipulating data with the {dplyr} package.\nComplete these primers. It may seem like there are a lot, but they’re short and go fairly quickly, especially as you get the hang of the syntax. Also, I have no way of seeing what you do or what you get wrong or right, and that’s totally fine! If you get stuck or want to skip some (or if it gets too easy), feel free to move on!\n\nThe Basics\n\nVisualization basics\nProgramming basics\n\nWork with Data\n\nWorking with tibbles\nIsolating data with {dplyr}\nDeriving information with {dplyr}\n\n\nThe content from these primers comes from the (free and online!) book R for Data Science by Garrett Grolemund and Hadley Wickham. I highly recommend the book as a reference and for continuing to learn and use R in the future (like running regression models and other types of statistical analysis).",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#introduction",
    "href": "handson/02-handson.html#introduction",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Introduction",
    "text": "Introduction\nIn this hands-on session, we will explore the relationship between various state-level characteristics and the share of votes received by Donald Trump in the 2016 presidential election. We will build a visualization step by step, using the ggplot2 package in R. Throughout this session, you’ll learn how to manipulate data, create plots, and progressively add layers to enhance your visualizations.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#note-on-the-data",
    "href": "handson/02-handson.html#note-on-the-data",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Note on the Data",
    "text": "Note on the Data\nThe dataset we’ll be using contains various economic and demographic indicators for U.S. states during the 2016 presidential election. It includes information such as the percentage of the population that completed college (percoled), the share of votes received by Donald Trump (trumpshare), whether Trump won the state (trumpw), and more. Understanding the context of these variables will help you interpret the plots we create.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#data-preparation",
    "href": "handson/02-handson.html#data-preparation",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nLoad Packages\nWe’ll begin by loading the necessary packages that will help us manipulate the data and create visualizations.\n\n# Load the necessary packages for data manipulation and visualization.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(hrbrthemes)\n\n\n\nLoad the Data\nNext, we’ll load the election dataset, which contains information about state-level turnout and various economic indicators during the 2016 presidential election.\n\n# Load the election dataset.\nelection &lt;- read_csv(\"../files/data/external_data/election_turnout.csv\")\n\nRows: 51 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): state, region, division\ndbl (12): rownames, year, turnoutho, perhsed, percoled, gdppercap, ss, trump...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nInspect the Data\nIt’s always important to inspect your data before starting any analysis. This helps you understand the structure of the data and the types of variables you’re working with.\n\n# Use glimpse() to get a quick overview of the dataset.\nelection |&gt; glimpse()\n\nRows: 51\nColumns: 15\n$ rownames    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ year        &lt;dbl&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016…\n$ state       &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", …\n$ region      &lt;chr&gt; \"South\", \"West\", \"West\", \"South\", \"West\", \"West\", \"Northea…\n$ division    &lt;chr&gt; \"East South Central\", \"Pacific\", \"Mountain\", \"West South C…\n$ turnoutho   &lt;dbl&gt; 59.0, 61.3, 55.0, 52.8, 56.7, 70.1, 65.2, 64.4, 60.9, 64.6…\n$ perhsed     &lt;dbl&gt; 84.3, 92.1, 86.0, 84.8, 81.8, 90.7, 89.9, 88.4, 89.3, 86.9…\n$ percoled    &lt;dbl&gt; 23.5, 28.0, 27.5, 21.1, 31.4, 38.1, 37.6, 30.0, 54.6, 27.3…\n$ gdppercap   &lt;dbl&gt; 42663, 81801, 43269, 41129, 61924, 58009, 72331, 69930, 18…\n$ ss          &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0…\n$ trumpw      &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0…\n$ trumpshare  &lt;dbl&gt; 0.62083092, 0.51281512, 0.48671616, 0.60574102, 0.31617107…\n$ sunempr     &lt;dbl&gt; 5.8, 6.9, 5.2, 3.8, 5.4, 2.9, 4.9, 4.5, 6.0, 4.7, 5.3, 2.8…\n$ sunempr12md &lt;dbl&gt; -0.2, 0.3, -0.6, -0.6, -0.3, -0.6, -0.7, -0.2, -0.5, -0.4,…\n$ gdp         &lt;dbl&gt; 203829.8, 49363.4, 311091.0, 120374.8, 2657797.6, 329368.3…",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#exercise-1-basic-scatter-plot",
    "href": "handson/02-handson.html#exercise-1-basic-scatter-plot",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Exercise 1: Basic Scatter Plot",
    "text": "Exercise 1: Basic Scatter Plot\n\nObjective\nIn this exercise, we aim to create a basic scatter plot that visualizes the relationship between the share of the vote Trump received (trumpshare) and the percentage of the state that completed college (percoled). This is a straightforward way to explore potential correlations between education levels and voting behavior.\n\n\nInstructions\nUse the ggplot() function to initialize the plot, mapping percoled to the x-axis and trumpshare to the y-axis. Then, add points to the plot using geom_point().\n\n# Create a basic scatter plot.\nelection |&gt; \n  ggplot(\n    aes(\n      x = percoled,    # percoled on the x-axis\n      y = trumpshare   # trumpshare on the y-axis\n    )\n  ) +\n  geom_point() +          # Add points to represent each state\n  labs(\n    title = \"Relationship between Trump Vote Share and College Education\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExplanation\nIn this plot, each point represents a state, with the x-axis showing the percentage of the population with a college education and the y-axis showing the percentage of votes Trump received. This basic plot will help us identify any apparent trends or outliers.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#exercise-2-data-transformation",
    "href": "handson/02-handson.html#exercise-2-data-transformation",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Exercise 2: Data Transformation",
    "text": "Exercise 2: Data Transformation\n\nObjective\nBefore enhancing our plot, we’ll transform some variables to better suit our analysis. Specifically, we’ll convert trumpw into a categorical variable (factor) and rescale percoled to represent it as a proportion (dividing by 100).\n\n\nInstructions\nUse the mutate() function to transform the data and then create a scatter plot with the transformed variables.\n\n# Transform the data.\nelection_transformed &lt;- election |&gt; \n  mutate(\n    trumpw = as_factor(trumpw),  # Convert trumpw to a factor\n    percoled = percoled / 100    # Rescale percoled to be a proportion\n  )\n\n# Plot using the transformed data.\nelection_transformed |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  labs(\n    title = \"Trump Vote Share vs. College Education (Transformed Data)\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExplanation\nBy converting trumpw to a factor, we make it easier to group the data by whether Trump won a state. Rescaling percoled to a proportion standardizes the variable, allowing for more intuitive interpretation, especially when we apply formatting later on.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#exercise-3-filtering-data",
    "href": "handson/02-handson.html#exercise-3-filtering-data",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Exercise 3: Filtering Data",
    "text": "Exercise 3: Filtering Data\n\nObjective\nIn this exercise, we’ll filter out the District of Columbia from our dataset. D.C. is often an outlier in many analyses due to its unique characteristics, so excluding it can make patterns in the rest of the data clearer.\n\n\nInstructions\nUse the filter() function to remove D.C. from the dataset, then create a scatter plot with the filtered data.\n\n# Filter the data.\nelection_filtered &lt;- election_transformed |&gt; \n  filter(state != \"District of Columbia\")\n\n# Plot the filtered data.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  labs(\n    title = \"Trump Vote Share vs. College Education (Filtered Data)\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExplanation\nRemoving D.C. reduces the potential for this outlier to skew the visual representation of the data, allowing for a more accurate depiction of the relationship between education levels and Trump’s vote share in the other states.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#exercise-4-adding-a-regression-line",
    "href": "handson/02-handson.html#exercise-4-adding-a-regression-line",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Exercise 4: Adding a Regression Line",
    "text": "Exercise 4: Adding a Regression Line\n\nObjective\nTo better understand the relationship between education and Trump’s vote share, we’ll add a linear regression line to our scatter plot. This line will help us see the overall trend in the data.\n\n\nInstructions\nUse geom_smooth() with the method = \"lm\" argument to add a linear regression line to your scatter plot.\n\n# Add a linear regression line to the plot.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n     \n\n x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +       # Add a linear regression line\n  labs(\n    title = \"Trump Vote Share vs. College Education with Regression Line\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nThe regression line provides a clear visual summary of the direction and strength of the relationship between the percentage of college-educated individuals and Trump’s vote share. The slope of the line will indicate whether there’s a positive or negative correlation.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#exercise-5-adding-a-horizontal-reference-line",
    "href": "handson/02-handson.html#exercise-5-adding-a-horizontal-reference-line",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Exercise 5: Adding a Horizontal Reference Line",
    "text": "Exercise 5: Adding a Horizontal Reference Line\n\nObjective\nIn this exercise, we’ll add a horizontal reference line at 50% Trump vote share. This line represents a key threshold, indicating whether Trump received more or less than half of the votes in each state.\n\n\nInstructions\nUse geom_hline() to add a horizontal dashed line at y = 0.5.\n\n# Add a horizontal reference line at 50% Trump vote share.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"grey\") + # Add horizontal line at 50%\n  labs(\n    title = \"Trump Vote Share vs. College Education with Reference Line\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nThe 50% line is a critical point of reference, as it allows us to quickly see which states Trump won (above the line) and which he lost (below the line). This adds another layer of interpretation to the plot.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#exercise-6-adding-text-labels",
    "href": "handson/02-handson.html#exercise-6-adding-text-labels",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Exercise 6: Adding Text Labels",
    "text": "Exercise 6: Adding Text Labels\n\nObjective\nTo make the plot more informative, we’ll add text labels to the points. This will allow us to see which state each point represents without having to hover over or refer to another source.\n\n\nInstructions\nUse geom_text() to add state labels to the points on your scatter plot.\n\n# Add text labels to the points.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"grey\") +\n  geom_text(aes(label = state), vjust = -0.5, size = 3, show.legend = FALSE) + # Add text labels\n  labs(\n    title = \"Trump Vote Share vs. College Education with State Labels\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nBy labeling each point with its corresponding state abbreviation, we can easily identify which states exhibit particular voting and education patterns. This is especially useful for recognizing outliers or regional trends.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#exercise-7-adjusting-axis-scales",
    "href": "handson/02-handson.html#exercise-7-adjusting-axis-scales",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Exercise 7: Adjusting Axis Scales",
    "text": "Exercise 7: Adjusting Axis Scales\n\nObjective\nTo improve the readability of our plot, we’ll adjust the x and y axes to display percentages. We’ll also add a custom color scale to differentiate between states that Trump won and those he didn’t.\n\n\nInstructions\nUse scale_x_continuous() and scale_y_continuous() to format the axes as percentages, and scale_color_manual() to define custom colors for the trumpw variable.\n\n# Adjust axis scales and color scale.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare,\n      color = trumpw    # Color points by whether Trump won the state\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"grey\") +\n  geom_text(aes(label = state), vjust = -0.5, size = 3, show.legend = FALSE) +\n  scale_x_continuous(labels = scales::percent) +  # Format x-axis as percentage\n  scale_y_continuous(breaks = seq(0,1,.2), labels = scales::percent) +  # Format y-axis as percentage\n  scale_color_manual(labels = c(\"No\", \"Yes\"), values = c(\"blue\", \"red\")) + # Custom color scale\n  labs(\n    title = \"Trump Vote Share vs. College Education with Adjusted Scales\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\",\n    color = \"Did Trump win the State?\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nFormatting the axes as percentages makes the data more interpretable for viewers. The custom color scale enhances the plot by visually distinguishing states based on the election outcome, making patterns and trends easier to detect.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#exercise-8-adding-facets",
    "href": "handson/02-handson.html#exercise-8-adding-facets",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Exercise 8: Adding Facets",
    "text": "Exercise 8: Adding Facets\n\nObjective\nFinally, we’ll use facets to create separate plots for each region. This allows us to compare trends across different parts of the country more effectively.\n\n\nInstructions\nUse facet_wrap(~ region) to create a separate plot for each region.\n\n# Add facets to create separate plots by region.\nelection_filtered |&gt; \n  ggplot(\n    aes(\n      x = percoled,\n      y = trumpshare,\n      color = trumpw\n    )\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"black\", se = FALSE) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"grey\") +\n  geom_text(aes(label = state), vjust = -0.5, size = 3, show.legend = FALSE) +\n  scale_x_continuous(labels = scales::percent) +  \n  scale_y_continuous(breaks = seq(0,1,.2), labels = scales::percent) +\n  scale_color_manual(labels = c(\"No\", \"Yes\"), values = c(\"blue\", \"red\")) +\n  coord_cartesian(clip = \"off\") + # Ensure labels are not clipped\n  facet_wrap(~ region) +          # Facet by region\n  labs(\n    title = \"Trump Vote Share vs. College Education by Region\",\n    x = \"Percentage with College Education\",\n    y = \"Trump Vote Share\",\n    color = \"Did Trump win the State?\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExplanation\nFaceting allows us to see how the relationship between education and Trump’s vote share varies across different regions. This can reveal regional differences that might not be apparent when looking at the data as a whole.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "handson/02-handson.html#recap",
    "href": "handson/02-handson.html#recap",
    "title": "Tidy Data and Visualization (Hands-on Session)",
    "section": "Recap",
    "text": "Recap\nIn this session, we’ve progressively built a complex ggplot2 visualization, starting from a basic scatter plot and adding layers such as regression lines, reference lines, text labels, custom scales, and facets. Each step has added more depth to our understanding of the data, demonstrating the power and flexibility of ggplot2 for exploring relationships within data.",
    "crumbs": [
      "Hands-on",
      "Hands-on Sessions",
      "2: Data Visualization with ggplot2"
    ]
  }
]